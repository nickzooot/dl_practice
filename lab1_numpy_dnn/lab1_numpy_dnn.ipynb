{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Практикум по программированию на языке Python`\n",
    "\n",
    "## `Задание 01. Полносвязная нейронная сеть на numpy`.\n",
    "\n",
    "#### Фамилия, имя: \n",
    "\n",
    "Дата выдачи: <span style=\"color:red\">__28 февраля 17:00__</span>.\n",
    "\n",
    "Мягкий дедлайн: <span style=\"color:red\">__14 марта 23:59__</span>.\n",
    "\n",
    "Стоимость: __10 баллов__ (основная часть заданий) + __3 балла__ (дополнительные задания).\n",
    "\n",
    "<span style=\"color:red\">__В ноутбуке все клетки должны выполняться без ошибок при последовательном их выполнении.__</span>\n",
    "\n",
    "#### `Москва, 2023`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:48.909044Z",
     "start_time": "2021-03-03T14:44:48.683650Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `Теоретическая часть (3 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В этом блоке вам нужно решить 3 задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Задание 1. Градиенты для слоя Batch normalization (1.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим слой Batch normalization. Пусть на вход этого слоя был подан батч из $n$ объектов, при этом у всех объектов по 1 признаку. Представим вход BN слоя в виде $X \\in \\mathbb{R}^{n \\times 1}$.\n",
    "\n",
    "Тогда в этом слое производятся следующие вычисления:\n",
    "\n",
    "$$ \\mu = \\frac1n \\sum_{i=1}^{n} X_i $$\n",
    "\n",
    "$$ \\sigma^2 = \\frac1n \\sum_{i=1}^{n} \\left( X_i - \\mu \\right) ^2 $$\n",
    "\n",
    "$$ \\tilde{y_i} = \\frac{X_i - \\mu}{\\sqrt{\\sigma^2 + \\varepsilon}} $$\n",
    "\n",
    "$$ y_i = \\gamma \\tilde{y_i} + \\delta $$\n",
    "\n",
    "Выходом BN слоя является $y_i$, а $\\gamma$ и $\\delta$ в нем — параметры, которые подбираются во время обучения вместе с другими параметрами нейронной сети (наряду, например, с весами линейного слоя).\n",
    "\n",
    "Рассмотрим нейронную сеть, в которой есть BN слой. Предположим, что вычисления в нейронной завершаются подсчетом функции потерь $\\mathcal{L}$. Пусть мы выполнили прямой проход по нейронной сети и сейчас делаем обратный проход с помощью метода обратного распространения ошибки. Пусть BN слою пришел градиент функции потерь по выходу BN слоя ($\\nabla_{y} \\mathcal{L}$).\n",
    "\n",
    "В этом задании вам нужно записать вычисление градиента функции потерь по параметрам слоя BN $\\gamma$ и $\\delta$ ($\\nabla_{\\gamma} \\mathcal{L}$, $\\nabla_{\\delta} \\mathcal{L}$) через $\\nabla_{y} \\mathcal{L}$, а также вам нужно записать вычисление градиента функции потерь по входу слоя BN $X$ ($\\nabla_{X} \\mathcal{L}$) через $\\nabla_{y} \\mathcal{L}$.\n",
    "\n",
    "Хочу заметить, в данном задании мы рассматриваем объекты всего с 1 признаком, чтобы упростить выкладки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Ваше решение:__\n",
    "\n",
    " Пусть $y = \\left(y_1,y_2,\\ldots,y_n\\right)^T, \\tilde{y} = \\left(\\tilde{y_1},\\tilde{y_2},\\ldots,\\tilde{y_n}\\right)^T, I = \\left(1,1,\\ldots,1\\right)^T   \\in \\mathbb{R}^{n \\times 1}$, $E$ - единичная матрица  $\\in \\mathbb{R}^{n \\times n}$\n",
    "\n",
    "Тогда\n",
    "$$ \\mu = \\frac{1}{n}X^TI $$ \n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{n}\\left(X - I\\mu)^T(X-I\\mu\\right) $$\n",
    "\n",
    "$$\\tilde{y} = \\frac{X -  I\\mu}{\\sqrt{\\sigma^2 + \\varepsilon}} $$\n",
    "\n",
    "$$y = \\gamma\\tilde{y} + \\delta I $$\n",
    "\n",
    "Продифференцируем $d\\mathcal{L}$, $d\\mathcal{L} = \\nabla_y \\mathcal{L}^T dy = \\nabla_y \\mathcal{L}^T \\left(\\tilde{y}d\\gamma + \\gamma d\\tilde{y} + Id\\delta\\right)$\n",
    "\n",
    "Продифференцируем $d\\mathcal{L}$ по $\\tilde{y}, \\gamma, \\delta$. Тогда $ d\\mathcal{L} = \\frac{\\partial\\mathcal{L}}{\\partial{\\gamma}}d\\gamma + \\frac{\\partial\\mathcal{L}}{\\partial{\\delta}} d\\delta + \\nabla_X \\mathcal{L}^T dX $ , получаем\n",
    "\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial{\\gamma}} = \\tilde{y}^T \\nabla_y \\mathcal{L} $$\n",
    "\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial{\\delta}} = I^T \\nabla_y \\mathcal{L}$$\n",
    "\n",
    "\n",
    "Для того, чтобы найти $\\nabla_X \\mathcal{L}$ нужно найти $d\\tilde{y}$.\n",
    "Предварительно посчитаем $d\\mu$ и $d\\sigma^2$.\n",
    "\n",
    "$ d\\mu = \\frac{1}{n}d\\left(X^TI\\right) = \\frac{1}{n}d\\left(I^TX\\right)= \\frac{1}{n}I^T dX $\n",
    "\n",
    "$ d\\sigma^2 = \\frac{1}{n}\\left(d\\left(X-I\\mu\\right)^Td\\left(X-I\\mu\\right)\\right) = \\frac{2}{n}\\left(X-I\\mu\\right)^Td\\left(X-I\\mu\\right) = \\frac{2}{n}\\left(X-I\\mu\\right)^T\\left(dX - Id\\mu\\right)= \\frac{2}{n}\\left(X-I\\mu\\right)^T\\left(dX-\\frac{1}{n}II^TdX\\right) = \\frac{2}{n}\\left(X-I\\mu\\right)^T\\left(E-\\frac{1}{n}II^T\\right)dX $\n",
    "\n",
    "Теперь найдём $d\\tilde{y}$:\n",
    "\n",
    "$$ d\\tilde{y} = \\frac{d\\left(X-I\\mu\\right)\\sqrt{\\sigma^2 + \\varepsilon} - \\left(X-I\\mu\\right)d\\sqrt{\\sigma^2+\\varepsilon}}{\\sigma^2 + \\varepsilon} = \\\\ = \\frac{\\left(dX-Id\\mu\\right)\\sqrt{\\sigma^2 + \\varepsilon} - \\left(X-I\\mu\\right)\\frac{1}{2\\sqrt{\\sigma^2 + \\varepsilon}}d\\left(\\sigma^2 + \\varepsilon\\right)}{\\sigma^2 + \\varepsilon} = \\\\ = \\frac{\\left[\\left(E-\\frac{1}{n}II^T\\right)\\sqrt{\\sigma^2 + \\varepsilon} - \\frac{2}{n}\\frac{1}{2\\sqrt{\\sigma^2 + \\varepsilon}}\\left(X-I\\mu\\right)\\left(X-I\\mu\\right)^T\\left(E-\\frac{1}{n}II^T\\right)\\right]dX}{\\sigma^2 + \\varepsilon} = \\\\ = \\frac{\\left[\\left(\\sigma^2 + \\varepsilon\\right)E - \\frac{1}{n}\\left(X-I\\mu\\right)\\left(X-I\\mu\\right)^T\\right]\\left(E-\\frac{1}{n}II^T\\right)}{\\left(\\sigma^2 + \\varepsilon\\right)^{3/2}}dX $$\n",
    "\n",
    "\n",
    "Получаем, что\n",
    "\n",
    "$$\n",
    " \\nabla_X \\mathcal{L} = \\frac{\\left[\\left(\\sigma^2 + \\varepsilon\\right)E - \\frac{1}{n}\\left(X-I\\mu\\right)\\left(X-I\\mu\\right)^T\\right]\\left(E-\\frac{1}{n}II^T\\right)}{\\left(\\sigma^2 + \\varepsilon\\right)^{3/2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Задание 2. Вывод инициализации весов линейного слоя при использовании ReLU в качестве функции активации (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим полносвязную нейронную сеть с функцией активации $g(y)$. Пусть сеть состоит из $L$ слоев и размер входа слоя $l$ равен $n_l\\ \\ (l = \\overline{1, L})$.\n",
    "\n",
    "Обозначим за $x^l \\in \\mathbb{R}^{n_{l}}$ вход слоя $l$, за $y^l \\in \\mathbb{R}^{n_{l+1}}$ — выход слоя $l$, за $W^l \\in \\mathbb{R}^{n_{l+1} \\times n_{l}}$ — веса слоя $l$, за $b^l \\in \\mathbb{R}^{n_{l+1}}$ — вектор сдвига слоя $l$.\n",
    "\n",
    "Тогда\n",
    "$$y^l = W^l x^l + b^l,$$\n",
    "$$x^{l+1} = g(y^l).$$\n",
    "\n",
    "На паре вы выводили хорошую инициализацию для линейного слоя в случае, когда в качестве функции активации $g(y)$ в нейронной сети используется гиперболический тангенс $g(y) = \\tanh(y)$. Сейчас вам нужно сделать подобный вывод для случая, когда в сети в качестве функций активации используется $g(y) = ReLU(y) = \\max(0, y)$.\n",
    "\n",
    "Сделаем следующие предположения насчет того, как распределены веса $W^l$, вектор сдвига $b^l$, входной вектор $x^l$, выходной вектор $y^l$ линейного слоя и градиенты функции потерь $\\frac{\\partial L}{\\partial y^{l}}$ $(l = \\overline{1, L}$):\n",
    "\n",
    "1. Все компоненты в $W^l$ распределены одинаково и независимо друг от друга;\n",
    "2. Все компоненты в $y^l$ распределены одинаково и независимо друг от друга;\n",
    "3. Все компоненты в $x^l$ распределены одинаково и независимо друг от друга;\n",
    "4. Все компоненты в $\\frac{\\partial L}{\\partial y^{l}}$ распределены одинаково и независимо друг от друга;\n",
    "5. Все компоненты в $W^l$ и все компоненты в $x^l$ независимы друг от друга;\n",
    "6. Все компоненты в $W^l$ имеют четную плотность распределения (то есть симметричную относительно нуля: $p_{W^l}(-x) = p_{W^l}(x)$);\n",
    "7. Все компоненты в $W^l$ имеют конечное матожидание;\n",
    "8. Вектор $b^l$ инициализирован нулями.\n",
    "\n",
    "\n",
    "Подсказки:\n",
    "1. Из пунктов 6 и 7 следует, что все компоненты в $W^l$ имеют нулевое среднее ($\\mathbb{E} W^l_{ij} = 0\\ \\ \\forall i = \\overline{1, n_{l+1}}, j = \\overline{1, n_{l}}$) (докажите);\n",
    "2. Из пунктов 6 и 7 следует, что все компоненты в $y^l$ имеют нулевое среднее и четную плотность распределения (докажите)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Ваше решение:__\n",
    "\n",
    "   1. Докажем, что все компоненты в $W^l$ имеют нулевое среднее.\n",
    "\n",
    "   $\\mathbb{E} W^l_{ij} = \\int_{-\\infty}^{+\\infty} p_{W^l}(x)dx = \\int_{-\\infty}^{0} p_{W^l}(x)xdx + \\int_{0}^{+\\infty} p_{W^l}(x)xdx= \\{6\\} = \\int_{-\\infty}^{0} p_{W^l}(-x)xdx + \\int_{0}^{+\\infty} p_{W^l}(x)xdx = \\{y = -x\\} = -\\int_{0}^{+\\infty} p_{W^l}(x)xdx + \\int_{0}^{+\\infty} p_{W^l}(x)xdx = 0$\n",
    "\n",
    "   2. Докажем, что все компоненты в $y^l$ имеют нулевое среднее.\n",
    "\n",
    "   $\\mathbb{E} y_i^l = \\{ так\\ как\\ b^l= 0\\ \\forall l \\}= \\mathbb{E} \\sum_{j=1}^{n_l}W_{ij}^l x_j^l= \\left \\{  5\\right \\} =\\sum_{j=1}^{n_l}\\underbrace{\\mathbb{E}W_{ij}^l}_{0} \\mathbb{E}x_j^l=0 \\quad \\forall i = \\overline{1, n_{l+1}}$\n",
    "\n",
    "   3. Все компоненты в $y^l$ имеют четную плотность распределения.\n",
    "\n",
    "   $y_i^l = \\sum_{k = 1}^{n_l}W_{ik}^lx_k^l$\n",
    "\n",
    "   $p_{W_{ik}^lx_k^l}(z) = \\int_{-\\infty}^{+\\infty} p_{x_k^l}(x)p_{W_{ik}^l}(\\frac{z}{x})\\frac{1}{|x|}dx= \\int_{-\\infty}^{+\\infty} p_{x_k^l}(x)p_{W_{ik}^l}(-\\frac{z}{x})\\frac{1}{|x|}dx = p_{W_{ik}^lx_k^l}(-z)$, то есть четная функция.  Плотность суммы независимых случайных величин получается в результате последовательного применения сверток. Так как свертка четных функций - четная функция, то $p_{y_i^l}(z) = p_{y_i^l}(-z)$\n",
    "\n",
    "   4. На прямом проходе мы хотим добиться того, чтобы матожидание и дисперсия активаций оставались неизменными от слоя к слою. Тем самым мы гарантируем что активации не будут \"взрываться\" или \"испаряться\" к последним слоям сети\n",
    "\n",
    "   $\\mathbb{D}y^l = \\mathbb{D}y_i^l = \\sum_{k=1}^{n_l}\\mathbb{D}(W_{ik}^l x_k^l)=\\{так\\ как\\ W_{ik}^l x_k^l\\ независимы\\}= \\sum_{k=1}^{n_l}\\left(\\underbrace{\\mathbb{D}W_{ik}^l\\mathbb{D}x_k^l + \\mathbb{D}W_{ik}^l(\\mathbb{E}x_k^l )^2}_{\\mathbb{D}x_k^l{{\\mathbb{E}x_k^l}^2}} + \\mathbb{D}x_k^l\\underbrace{(\\mathbb{E}W_{ik}^l)^2}_{0} - \\underbrace{(\\mathbb{E}W_{ik}^l)^2}_{0}(\\mathbb{E}x_k^l )^2 \\right) = n_l\\mathbb{D}{{W_{ik}^l\\mathbb{E}{(x_k^l)}^2}}$\n",
    "\n",
    "   $$\\mathbb{E} \\left(x_k^l\\right)^2 = \\mathbb{E} \\left(g^2\\left(y_k^{l-1}\\right)\\right)^2 = \\int_{-\\infty}^{+\\infty} g^2\\left(t\\right)p_{y_k^{l-1}}\\left(t\\right)dt = \\int_{0}^{+\\infty} t^2p_{y_k^{l-1}}\\left(t\\right)dt + \\int_{-\\infty}^{0} 0\\cdot p_{y_k^{l-1}}\\left(t\\right)dt = \\int_{0}^{+\\infty} t^2p_{y_k^{l-1}}\\left(t\\right)dt = \\\\ = \\left\\{p_{y_k^{l-1}}\\left(t\\right) = p_{y_k^{l-1}}\\left(-t\\right) \\right\\}  =\\int_{0}^{+\\infty} t^2p_{y_k^{l-1}}\\left(-t\\right)dt = \\left\\{t = -u \\right\\} =\\int_{-\\infty}^{0} u^2p_{y_k^{l-1}}\\left(u\\right)du $$\n",
    "\n",
    "   Тогда $$2\\mathbb{E} \\left(g^2\\left(y_k^{l-1}\\right)\\right)^2 = \\int_{-\\infty}^{+\\infty} t^2p_{y_k^{l-1}}\\left(t\\right)dt = \\mathbb{E} \\left(y_k^{l-1}\\right)^2 = \\mathbb{E} \\left(y_k^{l-1} \\right)^2 - \\left(\\underbrace{\\mathbb{E} y_k^{l-1}}_{0}\\right)^2 = \\mathbb{D}y_k^{l-1}$$\n",
    "\n",
    "   Подставляя в первое уравнение, получаем:\n",
    "\n",
    "   $\\mathbb{D}y^l = \\frac{n_l}{2}\\mathbb{D}y_k^{l-1}\\mathbb{D}W_{ik}^l= \\frac{n_l}{2}\\mathbb{D}y^{l-1}\\mathbb{D}W^l$ \n",
    "\n",
    "   Хотим: $$\\mathbb{D}y^{l} = \\mathbb{D}y^{l-1} \\Leftrightarrow \\mathbb{D} W^l = \\frac{2}{n_l} $$\n",
    "\n",
    "   5. На обратном проходе мы хотим добиться того, чтобы матожидание и дисперсия градиентов оставались неизменными от слоя к слою. Тем самым мы гарантируем что градиенты не будут \"взрываться\" или \"испаряться\" к первым слоям сети.\n",
    "\n",
    "   $Пусть\\ \\delta_i^l = \\frac{\\partial \\mathcal{L}}{\\partial{y_i^l}} =\n",
    "   \\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1} g^{\\prime}(y_i^l)=\n",
    "   \\left[y_i^l>0\\right]\\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1} $\n",
    "   \n",
    "   Тогда\n",
    "   $$ \\mathbb{E}\\delta^l = \\mathbb{E}\\delta_i^l = \\mathbb{E}\\left[y_i^l>0\\right]\\sum_{k=1}^{n_{l+2}} \\mathbb{E}\\delta_k^{l+1} \\underbrace{\\mathbb{E}W_{ik}^{l+1}}_{0} = 0 $$\n",
    "\n",
    "   Теперь найдем дисперсию:\n",
    "   $$\\mathbb{D}\\delta^l = \\mathbb{D}\\delta_i^l = \\mathbb{D}\\left(\\left[y_i^l>0\\right]\\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1}\\right) = \\mathbb{D}[y_i^l > 0]\n",
    "   \\mathbb{D}\\left(\\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1}\\right) + \\mathbb{D}[y_i^l > 0](\\mathbb{E}\\left(\\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1}\\right))^2 + \\mathbb{D}\\left(\\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1}\\right){(\\mathbb{E}[y_i^l > 0])}^2 -\\ (\\mathbb{E}[y_i^l > 0])^2(\\mathbb{E}\\left(\\sum_{k=1}^{n_{l+2}} \\delta_k^{l+1} W_{ik}^{l+1}\\right))^2 =\n",
    "   $$ \n",
    "   $$= \\mathbb{D}[y_i^l > 0]\\sum_{k=1}^{n_{l+2}}\\underbrace{\\mathbb{D}\\left(\\delta_k^{l+1} W_{ik}^{l+1}\\right)}_{\\mathbb{D}\\delta_k^{l+1} \\mathbb{D}W_{ik}^{l+1}} + \\mathbb{D}[y_i^l > 0](\\sum_{k=1}^{n_{l+2}}\\underbrace{\\mathbb{E}\\delta_k^{l+1} \\mathbb{E}W_{ik}^{l+1}}_{0})^2 + \\sum_{k=1}^{n_{l+2}} \\underbrace{\\mathbb{D}\\left(\\delta_k^{l+1} W_{ik}^{l+1}\\right)}_{\\mathbb{D}\\delta_k^{l+1} \\mathbb{D}W_{ik}^{l+1}}(\\mathbb{E}[y_i^l > 0])^2 - \\sum_{k=1}^{n_{l+2}} (\\underbrace{\\mathbb{E}\\delta_k^{l+1} \\mathbb{E}W_{ik}^{l+1}}_{0})^2(\\mathbb{E}[y_i^l > 0])^2 = $$\n",
    "   $$= n_{l+2}\\mathbb{D}\\delta_k^{l+1} \\mathbb{D}W_{ik}^{l+1}\\mathbb{E}[y_i^l > 0]^2 = n_{l+2}\\mathbb{D}\\delta^{l+1} \\mathbb{D}W^{l+1}\\mathbb{E}[y_i^l > 0]^2$$\n",
    "\n",
    "   Сделаем вспомогательные вычисления:\n",
    "   $$\\mathbb{E}[y_i^l > 0]^2 = \\int_{-\\infty}^{+\\infty}[x>0]^2p_{y_i}^l(x)dx = \\int_{0}^{+\\infty}p_{y_i}^l(x)dx = \\int_{0}^{+\\infty}p_{y_i}^l(-x)dx = \\{t = -x\\} = \\int_{-\\infty}^{0}p_{y_i}^l(t)dt\n",
    "\\Rightarrow $$\n",
    "\n",
    "$$2\\mathbb{E}[y_i^l > 0]^2 = \\int_{-\\infty}^{+\\infty}p_{y_i}^l(x)dx = 1$$  \n",
    "\n",
    "Отсюда и из предыдущего тожества следует, что\n",
    "\n",
    "$$\\mathbb{D}\\delta^l = \\frac{n_{l+2}}{2}\\mathbb{D}\\delta^{l+1} \\mathbb{D}W^{l+1}$$\n",
    "\n",
    "Хотим:\n",
    "$$\\mathbb{D}\\delta^l  = \\mathbb{D}\\delta^{l-1} \\Leftrightarrow \\mathbb{D} W^l = \\frac{2}{n_{l+1}} $$\n",
    "\n",
    "Чтобы дисперсии активаций и градиентов сохранялись необходимо потребовать, чтобы $n_{l+1} = n_l$. На практике берут среднегармоническое полученных оценок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Задание 3. Почему функция активации` $ReLU(y) = \\max(0, y)$ `предпочтительней сигмоиды` $\\sigma(y) = \\frac{1}{1 + \\exp(-y)}$ `в нейронных сетях? (0.5 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развернутый ответ на вопрос \"Почему функция активации $ReLU(y) = \\max(0, y)$ предпочтительней сигмоиды $\\sigma(y) = \\frac{1}{1 + \\exp(-y)}$ в нейронных сетях?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Ваш ответ:__\n",
    "\n",
    "1) ReLU вычислительно более простая функция чем sigm(у нее надо считать экспоненты, а это затратно по времени), поэтому для глубоких сетей ReLU быстрее обучается  \n",
    "2) Проблема с \"насыщенными\" нейронами связана с тем, что если производная функции активации близка к нулю, то обучение будет ооооочень медленным(потому что значения весов будут ооооочень мало изменяться), а значит, если у нас ограничения на количество эпох(например), то сходимость будет очень плохая следовательно сеть будет плохо обучена. Для сетей с сигмоидой есть такая проблема, так как у сигмоиды маленький диапазон, для которого производная сигмоиды не близка к нулю, поэтому ReLU лучше( так как диапозон больше ненулевой производной), но еще лучше leaky ReLU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `Практическая часть (7 баллов)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Реализация нейронной сети (3 балла)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В этом задании вы обучите полносвязную нейронную сеть распознавать рукописные цифры (а что же еще, если не их :), [почти] самостоятельно реализовав все составляющие алгоритма обучения и предсказания.\n",
    "\n",
    "Для начала нам понадобится реализовать прямой и обратный проход через слои. Наши слои будут соответствовать следующему интерфейсу (на примере \"тождественного\" слоя):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:48.924967Z",
     "start_time": "2021-03-03T14:44:48.912996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class IdentityLayer:\n",
    "    \"\"\"\n",
    "    A building block. Each layer is capable of performing two things:\n",
    "\n",
    "    - Process input to get output:           \n",
    "    output = layer.forward(input)\n",
    "\n",
    "    - Propagate gradients through itself:    \n",
    "    grad_input = layer.backward(input, grad_output)\n",
    "\n",
    "    Some layers also have learnable parameters.\n",
    "\n",
    "    Modified code from cs.hse DL course *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Here you can initialize layer parameters (if any) \n",
    "        and auxiliary stuff. You should enumerate all parameters\n",
    "        in self.params\n",
    "        \"\"\"\n",
    "        # An identity layer does nothing\n",
    "        self.params = []\n",
    "        self.eval = False\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, input_units], \n",
    "        returns output data [batch, output_units]\n",
    "        \"\"\"\n",
    "        # An identity layer just returns whatever it gets as input.\n",
    "        self.input = input\n",
    "        return input\n",
    "\n",
    "    def backward(self, grad_output): \n",
    "        \"\"\"\n",
    "        Performs a backpropagation step through the layer, \n",
    "        with respect to the given input.\n",
    "\n",
    "        To compute loss gradients w.r.t input, \n",
    "        you need to apply chain rule (backprop):\n",
    "\n",
    "        d `loss` / d `input` = (d `loss` / d `layer`) * (d `layer` / d `input`)\n",
    "\n",
    "        Luckily, you already receive d `loss` / d `layer` in argument, \n",
    "        so you only need to multiply it by d `layer` / d `input`.\n",
    "\n",
    "        NB: Sometimes d `layer` / d `input` can be a 3D or even 4D tensor.\n",
    "        So it's better to write down the `loss` differential and extract\n",
    "        d `layer` / d `input` from it so that only 2D tensors were present.\n",
    "\n",
    "        The method returns:\n",
    "        * gradient w.r.t input (will be passed to \n",
    "          previous layer's backward method)\n",
    "        * flattened gradient w.r.t. parameters (with .ravel() \n",
    "          applied to each gradient). \n",
    "          If there are no params, return []\n",
    "        \"\"\"\n",
    "        # The gradient of an identity layer is precisely grad_output\n",
    "        input_dim = self.input.shape[1]\n",
    "\n",
    "        d_layer_d_input = np.eye(input_dim)\n",
    "\n",
    "        return np.dot(grad_output, d_layer_d_input), [] # chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Слой нелинейности ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для начала реализуем слой нелинейности $ReLU(y) = \\max(0, y)$. Параметров у слоя нет. Метод `forward` должен вернуть результат поэлементного применения $ReLU$ к входному массиву, метод `backward` — градиент функции потерь по входу слоя. В нуле будем считать производную равной 0. Обратите внимание, что при обратном проходе могут понадобиться величины, посчитанные во время прямого прохода, поэтому их стоит сохранить как атрибут класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:48.939926Z",
     "start_time": "2021-03-03T14:44:48.928957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"\n",
    "    Modified code from cs.hse DL course *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
    "        self.params = [] # ReLU has no parameters\n",
    "        self.eval = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Apply elementwise ReLU to [batch, num_units] matrix\"\"\"\n",
    "        ### your code here\n",
    "        self.output = np.maximum(input, 0)\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Compute gradient of loss w.r.t. ReLU input\n",
    "        grad_output shape: [batch, num_units]\n",
    "        output 1 shape: [batch, num_units]\n",
    "        output 2: []\n",
    "        \"\"\"\n",
    "        ### your code here\n",
    "        grad_x = self.output > 0 \n",
    "        return grad_x * grad_output, []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Relu()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Полносвязный слой`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Далее реализуем полносвязный слой без нелинейности. У слоя два параметра: матрица весов и вектор сдвига.\n",
    "\n",
    "Обратите внимание на второй аргумент: в нем надо возвращать градиент по всем параметрам в одномерном виде. Для этого надо сначала применить `.ravel()` ко всем градиентам, а затем воспользоваться `np.r_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:48.971838Z",
     "start_time": "2021-03-03T14:44:48.943913Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10, 18])"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "b = np.eye(3).ravel()\n",
    "a = np.r_[b, np.arange(4)]\n",
    "a[0] = 2\n",
    "b\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "a[:None] * b[None:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:48.987794Z",
     "start_time": "2021-03-03T14:44:48.975827Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    \"\"\"\n",
    "    Modified code from cs.hse DL course *\n",
    "    \"\"\"\n",
    "    def __init__(self, input_units, output_units):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = x W + b\n",
    "        \"\"\"\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        self.weights = np.random.randn(input_units, output_units) * 0.01\n",
    "        self.biases = np.zeros(output_units)\n",
    "        self.params = [self.weights, self.biases]\n",
    "        self.eval = False\n",
    "\n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = x W + b\n",
    "        \n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        self.output = np.dot(input, self.weights) + self.biases\n",
    "        self.input = input\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        compute gradients\n",
    "        grad_output shape: [batch, output_units]\n",
    "        output shapes: [batch, input_units], [num_params]\n",
    "        \n",
    "        hint: use function np.r_\n",
    "        np.r_[np.arange(3), np.arange(3)] = [0, 1, 2, 0, 1, 2]\n",
    "        \"\"\"\n",
    "        grad_b = np.sum(grad_output, axis=0)\n",
    "        grad_w = np.dot(self.input.T, grad_output)\n",
    "        grad_x = np.dot(grad_output, self.weights.T)\n",
    "        return grad_x, np.r_[np.ravel(grad_w), grad_b]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Dense({self.weights.shape[0]}, {self.weights.shape[1]})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Проверка градиента`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим правильность реализации с помощью функции численной проверки градиента. Функция `eval_numerical_gradient` принимает на вход callable объект `f` (функцию от одного аргумента-матрицы) и аргумент `x` и вычисляет приближенный градиент функции `f` в точке `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.003751Z",
     "start_time": "2021-03-03T14:44:48.990787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=False, h=0.00001):\n",
    "    \"\"\"\n",
    "    Evaluates gradient df/dx via finite differences:\n",
    "    df/dx ~ (f(x+h) - f(x-h)) / 2h\n",
    "    Adopted from https://github.com/ddtm/dl-course/\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
    "        if verbose:\n",
    "            print (ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Вычислите аналитический и численный градиенты по входу слоя ReLU от функции\n",
    "$$ f(y) = \\sum_i y_i, \\quad y = ReLU(x) $$\n",
    "\n",
    "Выпишите аналитический градиент в этой ячейке:\n",
    "$$f(y) = I^Tdy$$\n",
    "\n",
    "$$dy = dReLU(x) = diag([x_1 > 0],\\ldots ,[x_n > 0])dx$$\n",
    "\n",
    "$$f(y) = \\nabla_xfdx = I^Tdiag([x_1 > 0],\\ldots ,[x_n > 0])dx$$\n",
    "\n",
    "$$\\nabla_xf = ([x_1 > 0],\\ldots ,[x_n > 0])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Следующая ячейка после заполнения должна не выдавать ошибку :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.034673Z",
     "start_time": "2021-03-03T14:44:49.006744Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu = ReLU()\n",
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "\n",
    "### your code here\n",
    "relu.forward(points)\n",
    "grad_output = np.ones((10, 12))\n",
    "grads = relu.backward(grad_output)[0]\n",
    "f = lambda x: relu.forward(x).sum()\n",
    "numeric_grads = eval_numerical_gradient(f, points, verbose=False, h=0.00001)\n",
    "\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Вычислите аналитический и численный градиенты по входу полносвязного слоя от функции\n",
    "$$ f(y) = \\sum_i y_i, \\quad y = W x + b $$\n",
    "\n",
    "Выпишите аналитический градиент в этой ячейке (советуем выписать градиент через дифференциал функции $f$):\n",
    "\n",
    "$$df(y) = dI^Ty = I^Tdy = I^TWdx$$\n",
    "\n",
    "$$df(y) = \\nabla_{x}f^Tdx$$\n",
    "\n",
    "$$\\nabla_{x}f = W^TI$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Следующая ячейка после заполнения должна не выдавать ошибку :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.066624Z",
     "start_time": "2021-03-03T14:44:49.041651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear = Dense(12, 32)\n",
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "\n",
    "### your code here\n",
    "linear.forward(points)\n",
    "grad_output = np.ones((10, 32))\n",
    "grads = linear.backward(grad_output)[0]\n",
    "f = lambda x: linear.forward(x).sum()\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `Реализация softmax-слоя и функции потерь`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для решения задачи многоклассовой классификации обычно используют $softmax$ в качестве нелинейности на последнем слое, чтобы получить вероятности классов для каждого объекта:\n",
    "$$\\hat y = softmax(x)  = \\left \\{\\frac {\\exp(x^i)}{\\sum_{j=1}^K \\exp(x^j)} \\right \\}_{i=1}^K, \\quad K - \\text{число классов.}$$\n",
    "\n",
    "Здесь за $x^i$ мы обозначаем $i$-ый признак объекта $x$.\n",
    "\n",
    "В качестве функции потерь выберем отрицательный логарифм правдоподобия (по английски: negative log likelihood или NLL)\n",
    "$$L(y, \\hat y) = -\\sum_{i=1}^K y^i \\log \\hat y^i,$$\n",
    "где $y^i = 1$, если объект принадлежит $i$-му классу, и $y^i = 0$ иначе.\n",
    "\n",
    "NLL совпадает с выражением для [кросс-энтропии](https://ru.wikipedia.org/wiki/Перекрёстная_энтропия) (в качестве первого распределения берем вырожденное распределение $y$, в качестве второго — предсказанное распределение $\\hat y$). Очевидно, что эту функцию потерь также можно переписать через индексацию, если через $y$ обозначить класс данного объекта:\n",
    "$$L(y, \\hat y) = - \\log \\hat y_{y}$$\n",
    "\n",
    "В таком виде ее удобно реализовывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T13:13:02.970075Z",
     "start_time": "2021-03-03T13:13:02.961134Z"
    },
    "hidden": true
   },
   "source": [
    "Для обучения нейронной сети будем оптимизировать эту функцию потерь по параметрам нейронной сети:\n",
    "\n",
    "$$ \\frac1N \\sum_{i=1}^N L(y_i, \\hat y_i) = \\frac1N \\sum_{i=1}^N L(y_i, \\text{NN}(x_i)) \\rightarrow \\min_{w}\\,,$$\n",
    "где за $x_i$ и $y_i$ мы обозначили признаки и таргет $i$-ого объекта обучающей выборки, за $\\text{NN}$ мы обозначили нейронную сеть, которая по признакам объекта $x_i$ выдает распределение вероятностей $\\hat y_i$, за $w$ мы обозначили все веса нейронной сети, а $N$ — это число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Реализуйте слой `LogSoftmax` (у этого слоя нет параметров). Метод `forward` должен вычислять логарифм от $softmax$, а метод `backward` — пропускать градиенты. В общем случае в промежуточных вычислениях `backward` получится трехмерный тензор, однако для нашей конкретной функции потерь все вычисления можно реализовать в матричном виде.  Поэтому мы будем предполагать, что аргумент `grad_output` — это матрица, у которой в каждой строке только одно ненулевое значение (не обязательно единица)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.272035Z",
     "start_time": "2021-03-03T14:44:49.070612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "# use this function instead of np.log(np.sum(np.exp(...))) because it is more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 9])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [4, 5, 6], [7, 8, 9]])\n",
    "j = [0, 1 ,2]\n",
    "i= [0, 1 ,2]\n",
    "a[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.288035Z",
     "start_time": "2021-03-03T14:44:49.275031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LogSoftmax:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.eval = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Applies softmax to each row and then applies component-wise log\n",
    "        Input shape: [batch, num_units]\n",
    "        Output shape: [batch, num_units]\n",
    "        \"\"\"\n",
    "        self.output = input - logsumexp(input, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Propagates gradients.\n",
    "        Assumes that each row of grad_output contains only 1 \n",
    "        non-zero element\n",
    "        Input shape: [batch, num_units]\n",
    "        Output shape: [batch, num_units]\n",
    "        Do not forget to return [] as second value (grad w.r.t. params)\n",
    "        \"\"\"\n",
    "        grad_x = (grad_output - np.sum(grad_output, axis=1, keepdims=True) *\n",
    "                np.exp(self.output))\n",
    "        return grad_x, []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'LogSoftmax()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Реализуйте функцию потерь и градиенты функции потерь. Во время вычисления NLL усредняйте (а не суммируйте) значения функции потерь по батчу. Обычно так делают для того, чтобы при двух запусках обучения нейронной сети с разными размерами батча получаемые значения функции потерь у этих сетей были сравнимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.302990Z",
     "start_time": "2021-03-03T14:44:49.290985Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def NLL(activations, target):\n",
    "    \"\"\"\n",
    "    Returns negative log-likelihood of target under model represented by\n",
    "    activations (log probabilities of classes, it's just output of LogSoftmax layer).\n",
    "    `activations` has shape [batch, num_classes], `target` has shape [batch]\n",
    "    Output shape: 1 (scalar).\n",
    "    \"\"\"\n",
    "    cols = list(range(activations.shape[0]))\n",
    "    return -np.mean(activations[cols, target])\n",
    "\n",
    "\n",
    "\n",
    "def grad_NLL(activations, target):\n",
    "    \"\"\"\n",
    "    Returns gradient of negative log-likelihood w.r.t. activations.\n",
    "    each arg has shape [batch, num_classes]\n",
    "    output shape: [batch, num-classes]\n",
    "    \"\"\"\n",
    "    ### your code here\n",
    "    grad_a = np.zeros(activations.shape)\n",
    "    cols = list(range(activations.shape[0]))\n",
    "    grad_a[cols, target] = - 1 / (activations.shape[0])\n",
    "    return grad_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Наконец, выполните проверку `LogSoftmax`-слоя, используя функцию потерь и ее градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.350863Z",
     "start_time": "2021-03-03T14:44:49.305945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsm = LogSoftmax()\n",
    "target = np.arange(10)\n",
    "points = np.linspace(-1, 1, 10 * 12).reshape([10, 12])\n",
    "\n",
    "grad_NLL_ = grad_NLL(lsm.forward(points), target)\n",
    "grads = lsm.backward(grad_NLL_)[0]\n",
    "f = lambda x: NLL(lsm.forward(x), target)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Загрузка данных`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Мы реализаовали все архитектурные составляющие нашей нейронной сети. Осталось загрузить данные и обучить модель. Мы будем работать с датасетом `digits`, каждый объект в котором — это 8x8 изображение рукописной цифры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:49.872521Z",
     "start_time": "2021-03-03T14:44:49.354818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:51.700670Z",
     "start_time": "2021-03-03T14:44:49.876510Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:51.873771Z",
     "start_time": "2021-03-03T14:44:51.703667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:51.889252Z",
     "start_time": "2021-03-03T14:44:51.877326Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Разделим данные на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:51.952606Z",
     "start_time": "2021-03-03T14:44:51.892280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:51.968609Z",
     "start_time": "2021-03-03T14:44:51.955642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.000485Z",
     "start_time": "2021-03-03T14:44:51.971599Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1347, 64), (450, 64))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Сборка и обучение нейронной сети (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В нашей реализации мы представляем нейронную сеть в виде списка ее слоев. Например, следующая функция конструирует нейронную сеть заданной ширины (то есть с заданным размером скрытых слоев) и глубины (то есть с заданным количеством слоев) с заданным размером входа и выхода, а также с заданной функцией активации между линейными слоями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.016442Z",
     "start_time": "2021-03-03T14:44:52.003513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_network(input_size, hidden_layers_size, output_size, n_layers=3, activation_class=ReLU):\n",
    "    network = []\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        # Compute sizes of current linear layer\n",
    "        layer_in = input_size if layer_idx == 0 else hidden_layers_size\n",
    "        layer_out = output_size if layer_idx == n_layers - 1 else hidden_layers_size\n",
    "        \n",
    "        # Add linear layer to the network\n",
    "        network.append(Dense(layer_in, layer_out))\n",
    "\n",
    "        # Add activation after each layer except the last one\n",
    "        if layer_idx != n_layers - 1:\n",
    "            network.append(activation_class())\n",
    "\n",
    "    # Add LogSoftmax layer to the network\n",
    "    network.append(LogSoftmax())\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.048395Z",
     "start_time": "2021-03-03T14:44:52.020431Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dense(64, 32), Relu(), Dense(32, 32), Relu(), Dense(32, 10), LogSoftmax()]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_layers_size = 32\n",
    "output_size = 10\n",
    "\n",
    "network = make_network(input_size, hidden_layers_size, output_size, 3, ReLU)\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Реализуйте функцию, которая выполнет прямой проход по нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.063319Z",
     "start_time": "2021-03-03T14:44:52.051386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def forward(network, X):\n",
    "    \"\"\"\n",
    "    Perform forward pass through the network.\n",
    "    \n",
    "    network: list of layers\n",
    "    X: raw data\n",
    "    X shape: [batch, features_num]\n",
    "\n",
    "    output: \n",
    "    output shape: [batch, out_features_num]\n",
    "    \"\"\"\n",
    "    for layer in network:\n",
    "        X = layer.forward(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Для проверки, хорошо ли сеть обучилась, нам понадобится вычислять долю правильных ответов (accuracy) на данной выборке. Для этого реализуйте функцию, которая делает предсказания на каждом объекте (логично в качестве предсказания на очередном объекте выдавать тот класс, для которого предсказанный логарифм вероятности максимален):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.063319Z",
     "start_time": "2021-03-03T14:44:52.051386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(network, X):\n",
    "    \"\"\"\n",
    "    Returns predictions for each object in X.\n",
    "    \n",
    "    network: list of layers\n",
    "    X: raw data\n",
    "    X shape: [batch, features_num]\n",
    "\n",
    "    output: array of classes, each from 0 to 9\n",
    "    output shape: [batch]\n",
    "    \"\"\"\n",
    "    pred = forward(network, X)\n",
    "    return np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Мы будем обучать параметры нейросети с помощью готовой функции оптимизации из модуля `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.079311Z",
     "start_time": "2021-03-03T14:44:52.070308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.111226Z",
     "start_time": "2021-03-03T14:44:52.085292Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function minimize in module scipy.optimize._minimize:\n",
      "\n",
      "minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)\n",
      "    Minimization of scalar function of one or more variables.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        The objective function to be minimized.\n",
      "    \n",
      "            ``fun(x, *args) -> float``\n",
      "    \n",
      "        where ``x`` is an 1-D array with shape (n,) and ``args``\n",
      "        is a tuple of the fixed parameters needed to completely\n",
      "        specify the function.\n",
      "    x0 : ndarray, shape (n,)\n",
      "        Initial guess. Array of real elements of size (n,),\n",
      "        where 'n' is the number of independent variables.\n",
      "    args : tuple, optional\n",
      "        Extra arguments passed to the objective function and its\n",
      "        derivatives (`fun`, `jac` and `hess` functions).\n",
      "    method : str or callable, optional\n",
      "        Type of solver.  Should be one of\n",
      "    \n",
      "            - 'Nelder-Mead' :ref:`(see here) <optimize.minimize-neldermead>`\n",
      "            - 'Powell'      :ref:`(see here) <optimize.minimize-powell>`\n",
      "            - 'CG'          :ref:`(see here) <optimize.minimize-cg>`\n",
      "            - 'BFGS'        :ref:`(see here) <optimize.minimize-bfgs>`\n",
      "            - 'Newton-CG'   :ref:`(see here) <optimize.minimize-newtoncg>`\n",
      "            - 'L-BFGS-B'    :ref:`(see here) <optimize.minimize-lbfgsb>`\n",
      "            - 'TNC'         :ref:`(see here) <optimize.minimize-tnc>`\n",
      "            - 'COBYLA'      :ref:`(see here) <optimize.minimize-cobyla>`\n",
      "            - 'SLSQP'       :ref:`(see here) <optimize.minimize-slsqp>`\n",
      "            - 'trust-constr':ref:`(see here) <optimize.minimize-trustconstr>`\n",
      "            - 'dogleg'      :ref:`(see here) <optimize.minimize-dogleg>`\n",
      "            - 'trust-ncg'   :ref:`(see here) <optimize.minimize-trustncg>`\n",
      "            - 'trust-exact' :ref:`(see here) <optimize.minimize-trustexact>`\n",
      "            - 'trust-krylov' :ref:`(see here) <optimize.minimize-trustkrylov>`\n",
      "            - custom - a callable object (added in version 0.14.0),\n",
      "              see below for description.\n",
      "    \n",
      "        If not given, chosen to be one of ``BFGS``, ``L-BFGS-B``, ``SLSQP``,\n",
      "        depending if the problem has constraints or bounds.\n",
      "    jac : {callable,  '2-point', '3-point', 'cs', bool}, optional\n",
      "        Method for computing the gradient vector. Only for CG, BFGS,\n",
      "        Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov,\n",
      "        trust-exact and trust-constr.\n",
      "        If it is a callable, it should be a function that returns the gradient\n",
      "        vector:\n",
      "    \n",
      "            ``jac(x, *args) -> array_like, shape (n,)``\n",
      "    \n",
      "        where ``x`` is an array with shape (n,) and ``args`` is a tuple with\n",
      "        the fixed parameters. If `jac` is a Boolean and is True, `fun` is\n",
      "        assumed to return a tuple ``(f, g)`` containing the objective\n",
      "        function and the gradient.\n",
      "        Methods 'Newton-CG', 'trust-ncg', 'dogleg', 'trust-exact', and\n",
      "        'trust-krylov' require that either a callable be supplied, or that\n",
      "        `fun` return the objective and gradient.\n",
      "        If None or False, the gradient will be estimated using 2-point finite\n",
      "        difference estimation with an absolute step size.\n",
      "        Alternatively, the keywords  {'2-point', '3-point', 'cs'} can be used\n",
      "        to select a finite difference scheme for numerical estimation of the\n",
      "        gradient with a relative step size. These finite difference schemes\n",
      "        obey any specified `bounds`.\n",
      "    hess : {callable, '2-point', '3-point', 'cs', HessianUpdateStrategy}, optional\n",
      "        Method for computing the Hessian matrix. Only for Newton-CG, dogleg,\n",
      "        trust-ncg, trust-krylov, trust-exact and trust-constr. If it is\n",
      "        callable, it should return the Hessian matrix:\n",
      "    \n",
      "            ``hess(x, *args) -> {LinearOperator, spmatrix, array}, (n, n)``\n",
      "    \n",
      "        where x is a (n,) ndarray and `args` is a tuple with the fixed\n",
      "        parameters. LinearOperator and sparse matrix returns are only allowed\n",
      "        for 'trust-constr' method. Alternatively, the keywords\n",
      "        {'2-point', '3-point', 'cs'} select a finite difference scheme\n",
      "        for numerical estimation. Or, objects implementing the\n",
      "        `HessianUpdateStrategy` interface can be used to approximate\n",
      "        the Hessian. Available quasi-Newton methods implementing\n",
      "        this interface are:\n",
      "    \n",
      "            - `BFGS`;\n",
      "            - `SR1`.\n",
      "    \n",
      "        Whenever the gradient is estimated via finite-differences,\n",
      "        the Hessian cannot be estimated with options\n",
      "        {'2-point', '3-point', 'cs'} and needs to be\n",
      "        estimated using one of the quasi-Newton strategies.\n",
      "        'trust-exact' cannot use a finite-difference scheme, and must be used\n",
      "        with a callable returning an (n, n) array.\n",
      "    hessp : callable, optional\n",
      "        Hessian of objective function times an arbitrary vector p. Only for\n",
      "        Newton-CG, trust-ncg, trust-krylov, trust-constr.\n",
      "        Only one of `hessp` or `hess` needs to be given.  If `hess` is\n",
      "        provided, then `hessp` will be ignored.  `hessp` must compute the\n",
      "        Hessian times an arbitrary vector:\n",
      "    \n",
      "            ``hessp(x, p, *args) ->  ndarray shape (n,)``\n",
      "    \n",
      "        where x is a (n,) ndarray, p is an arbitrary vector with\n",
      "        dimension (n,) and `args` is a tuple with the fixed\n",
      "        parameters.\n",
      "    bounds : sequence or `Bounds`, optional\n",
      "        Bounds on variables for Nelder-Mead, L-BFGS-B, TNC, SLSQP, Powell, and\n",
      "        trust-constr methods. There are two ways to specify the bounds:\n",
      "    \n",
      "            1. Instance of `Bounds` class.\n",
      "            2. Sequence of ``(min, max)`` pairs for each element in `x`. None\n",
      "               is used to specify no bound.\n",
      "    \n",
      "    constraints : {Constraint, dict} or List of {Constraint, dict}, optional\n",
      "        Constraints definition (only for COBYLA, SLSQP and trust-constr).\n",
      "    \n",
      "        Constraints for 'trust-constr' are defined as a single object or a\n",
      "        list of objects specifying constraints to the optimization problem.\n",
      "        Available constraints are:\n",
      "    \n",
      "            - `LinearConstraint`\n",
      "            - `NonlinearConstraint`\n",
      "    \n",
      "        Constraints for COBYLA, SLSQP are defined as a list of dictionaries.\n",
      "        Each dictionary with fields:\n",
      "    \n",
      "            type : str\n",
      "                Constraint type: 'eq' for equality, 'ineq' for inequality.\n",
      "            fun : callable\n",
      "                The function defining the constraint.\n",
      "            jac : callable, optional\n",
      "                The Jacobian of `fun` (only for SLSQP).\n",
      "            args : sequence, optional\n",
      "                Extra arguments to be passed to the function and Jacobian.\n",
      "    \n",
      "        Equality constraint means that the constraint function result is to\n",
      "        be zero whereas inequality means that it is to be non-negative.\n",
      "        Note that COBYLA only supports inequality constraints.\n",
      "    tol : float, optional\n",
      "        Tolerance for termination. When `tol` is specified, the selected\n",
      "        minimization algorithm sets some relevant solver-specific tolerance(s)\n",
      "        equal to `tol`. For detailed control, use solver-specific\n",
      "        options.\n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform. Depending on the\n",
      "                method each iteration may use several function evaluations.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options()`.\n",
      "    callback : callable, optional\n",
      "        Called after each iteration. For 'trust-constr' it is a callable with\n",
      "        the signature:\n",
      "    \n",
      "            ``callback(xk, OptimizeResult state) -> bool``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector. and ``state``\n",
      "        is an `OptimizeResult` object, with the same fields\n",
      "        as the ones from the return. If callback returns True\n",
      "        the algorithm execution is terminated.\n",
      "        For all the other methods, the signature is:\n",
      "    \n",
      "            ``callback(xk)``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        The optimization result represented as a ``OptimizeResult`` object.\n",
      "        Important attributes are: ``x`` the solution array, ``success`` a\n",
      "        Boolean flag indicating if the optimizer exited successfully and\n",
      "        ``message`` which describes the cause of the termination. See\n",
      "        `OptimizeResult` for a description of other attributes.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    minimize_scalar : Interface to minimization algorithms for scalar\n",
      "        univariate functions\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method is *BFGS*.\n",
      "    \n",
      "    **Unconstrained minimization**\n",
      "    \n",
      "    Method :ref:`CG <optimize.minimize-cg>` uses a nonlinear conjugate\n",
      "    gradient algorithm by Polak and Ribiere, a variant of the\n",
      "    Fletcher-Reeves method described in [5]_ pp.120-122. Only the\n",
      "    first derivatives are used.\n",
      "    \n",
      "    Method :ref:`BFGS <optimize.minimize-bfgs>` uses the quasi-Newton\n",
      "    method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) [5]_\n",
      "    pp. 136. It uses the first derivatives only. BFGS has proven good\n",
      "    performance even for non-smooth optimizations. This method also\n",
      "    returns an approximation of the Hessian inverse, stored as\n",
      "    `hess_inv` in the OptimizeResult object.\n",
      "    \n",
      "    Method :ref:`Newton-CG <optimize.minimize-newtoncg>` uses a\n",
      "    Newton-CG algorithm [5]_ pp. 168 (also known as the truncated\n",
      "    Newton method). It uses a CG method to the compute the search\n",
      "    direction. See also *TNC* method for a box-constrained\n",
      "    minimization with a similar algorithm. Suitable for large-scale\n",
      "    problems.\n",
      "    \n",
      "    Method :ref:`dogleg <optimize.minimize-dogleg>` uses the dog-leg\n",
      "    trust-region algorithm [5]_ for unconstrained minimization. This\n",
      "    algorithm requires the gradient and Hessian; furthermore the\n",
      "    Hessian is required to be positive definite.\n",
      "    \n",
      "    Method :ref:`trust-ncg <optimize.minimize-trustncg>` uses the\n",
      "    Newton conjugate gradient trust-region algorithm [5]_ for\n",
      "    unconstrained minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-krylov <optimize.minimize-trustkrylov>` uses\n",
      "    the Newton GLTR trust-region algorithm [14]_, [15]_ for unconstrained\n",
      "    minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    On indefinite problems it requires usually less iterations than the\n",
      "    `trust-ncg` method and is recommended for medium and large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-exact <optimize.minimize-trustexact>`\n",
      "    is a trust-region method for unconstrained minimization in which\n",
      "    quadratic subproblems are solved almost exactly [13]_. This\n",
      "    algorithm requires the gradient and the Hessian (which is\n",
      "    *not* required to be positive definite). It is, in many\n",
      "    situations, the Newton method to converge in fewer iteraction\n",
      "    and the most recommended for small and medium-size problems.\n",
      "    \n",
      "    **Bound-Constrained minimization**\n",
      "    \n",
      "    Method :ref:`Nelder-Mead <optimize.minimize-neldermead>` uses the\n",
      "    Simplex algorithm [1]_, [2]_. This algorithm is robust in many\n",
      "    applications. However, if numerical computation of derivative can be\n",
      "    trusted, other algorithms using the first and/or second derivatives\n",
      "    information might be preferred for their better performance in\n",
      "    general.\n",
      "    \n",
      "    Method :ref:`L-BFGS-B <optimize.minimize-lbfgsb>` uses the L-BFGS-B\n",
      "    algorithm [6]_, [7]_ for bound constrained minimization.\n",
      "    \n",
      "    Method :ref:`Powell <optimize.minimize-powell>` is a modification\n",
      "    of Powell's method [3]_, [4]_ which is a conjugate direction\n",
      "    method. It performs sequential one-dimensional minimizations along\n",
      "    each vector of the directions set (`direc` field in `options` and\n",
      "    `info`), which is updated at each iteration of the main\n",
      "    minimization loop. The function need not be differentiable, and no\n",
      "    derivatives are taken. If bounds are not provided, then an\n",
      "    unbounded line search will be used. If bounds are provided and\n",
      "    the initial guess is within the bounds, then every function\n",
      "    evaluation throughout the minimization procedure will be within\n",
      "    the bounds. If bounds are provided, the initial guess is outside\n",
      "    the bounds, and `direc` is full rank (default has full rank), then\n",
      "    some function evaluations during the first iteration may be\n",
      "    outside the bounds, but every function evaluation after the first\n",
      "    iteration will be within the bounds. If `direc` is not full rank,\n",
      "    then some parameters may not be optimized and the solution is not\n",
      "    guaranteed to be within the bounds.\n",
      "    \n",
      "    Method :ref:`TNC <optimize.minimize-tnc>` uses a truncated Newton\n",
      "    algorithm [5]_, [8]_ to minimize a function with variables subject\n",
      "    to bounds. This algorithm uses gradient information; it is also\n",
      "    called Newton Conjugate-Gradient. It differs from the *Newton-CG*\n",
      "    method described above as it wraps a C implementation and allows\n",
      "    each variable to be given upper and lower bounds.\n",
      "    \n",
      "    **Constrained Minimization**\n",
      "    \n",
      "    Method :ref:`COBYLA <optimize.minimize-cobyla>` uses the\n",
      "    Constrained Optimization BY Linear Approximation (COBYLA) method\n",
      "    [9]_, [10]_, [11]_. The algorithm is based on linear\n",
      "    approximations to the objective function and each constraint. The\n",
      "    method wraps a FORTRAN implementation of the algorithm. The\n",
      "    constraints functions 'fun' may return either a single number\n",
      "    or an array or list of numbers.\n",
      "    \n",
      "    Method :ref:`SLSQP <optimize.minimize-slsqp>` uses Sequential\n",
      "    Least SQuares Programming to minimize a function of several\n",
      "    variables with any combination of bounds, equality and inequality\n",
      "    constraints. The method wraps the SLSQP Optimization subroutine\n",
      "    originally implemented by Dieter Kraft [12]_. Note that the\n",
      "    wrapper handles infinite values in bounds by converting them into\n",
      "    large floating values.\n",
      "    \n",
      "    Method :ref:`trust-constr <optimize.minimize-trustconstr>` is a\n",
      "    trust-region algorithm for constrained optimization. It swiches\n",
      "    between two implementations depending on the problem definition.\n",
      "    It is the most versatile constrained minimization algorithm\n",
      "    implemented in SciPy and the most appropriate for large-scale problems.\n",
      "    For equality constrained problems it is an implementation of Byrd-Omojokun\n",
      "    Trust-Region SQP method described in [17]_ and in [5]_, p. 549. When\n",
      "    inequality constraints  are imposed as well, it swiches to the trust-region\n",
      "    interior point  method described in [16]_. This interior point algorithm,\n",
      "    in turn, solves inequality constraints by introducing slack variables\n",
      "    and solving a sequence of equality-constrained barrier problems\n",
      "    for progressively smaller values of the barrier parameter.\n",
      "    The previously described equality constrained SQP method is\n",
      "    used to solve the subproblems with increasing levels of accuracy\n",
      "    as the iterate gets closer to a solution.\n",
      "    \n",
      "    **Finite-Difference Options**\n",
      "    \n",
      "    For Method :ref:`trust-constr <optimize.minimize-trustconstr>`\n",
      "    the gradient and the Hessian may be approximated using\n",
      "    three finite-difference schemes: {'2-point', '3-point', 'cs'}.\n",
      "    The scheme 'cs' is, potentially, the most accurate but it\n",
      "    requires the function to correctly handles complex inputs and to\n",
      "    be differentiable in the complex plane. The scheme '3-point' is more\n",
      "    accurate than '2-point' but requires twice as many operations.\n",
      "    \n",
      "    **Custom minimizers**\n",
      "    \n",
      "    It may be useful to pass a custom minimization method, for example\n",
      "    when using a frontend to this method such as `scipy.optimize.basinhopping`\n",
      "    or a different library.  You can simply pass a callable as the ``method``\n",
      "    parameter.\n",
      "    \n",
      "    The callable is called as ``method(fun, x0, args, **kwargs, **options)``\n",
      "    where ``kwargs`` corresponds to any other parameters passed to `minimize`\n",
      "    (such as `callback`, `hess`, etc.), except the `options` dict, which has\n",
      "    its contents also passed as `method` parameters pair by pair.  Also, if\n",
      "    `jac` has been passed as a bool type, `jac` and `fun` are mangled so that\n",
      "    `fun` returns just the function values and `jac` is converted to a function\n",
      "    returning the Jacobian.  The method shall return an `OptimizeResult`\n",
      "    object.\n",
      "    \n",
      "    The provided `method` callable must be able to accept (and possibly ignore)\n",
      "    arbitrary parameters; the set of parameters accepted by `minimize` may\n",
      "    expand in future versions and then these parameters will be passed to\n",
      "    the method.  You can find an example in the scipy.optimize tutorial.\n",
      "    \n",
      "    .. versionadded:: 0.11.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Nelder, J A, and R Mead. 1965. A Simplex Method for Function\n",
      "        Minimization. The Computer Journal 7: 308-13.\n",
      "    .. [2] Wright M H. 1996. Direct search methods: Once scorned, now\n",
      "        respectable, in Numerical Analysis 1995: Proceedings of the 1995\n",
      "        Dundee Biennial Conference in Numerical Analysis (Eds. D F\n",
      "        Griffiths and G A Watson). Addison Wesley Longman, Harlow, UK.\n",
      "        191-208.\n",
      "    .. [3] Powell, M J D. 1964. An efficient method for finding the minimum of\n",
      "       a function of several variables without calculating derivatives. The\n",
      "       Computer Journal 7: 155-162.\n",
      "    .. [4] Press W, S A Teukolsky, W T Vetterling and B P Flannery.\n",
      "       Numerical Recipes (any edition), Cambridge University Press.\n",
      "    .. [5] Nocedal, J, and S J Wright. 2006. Numerical Optimization.\n",
      "       Springer New York.\n",
      "    .. [6] Byrd, R H and P Lu and J. Nocedal. 1995. A Limited Memory\n",
      "       Algorithm for Bound Constrained Optimization. SIAM Journal on\n",
      "       Scientific and Statistical Computing 16 (5): 1190-1208.\n",
      "    .. [7] Zhu, C and R H Byrd and J Nocedal. 1997. L-BFGS-B: Algorithm\n",
      "       778: L-BFGS-B, FORTRAN routines for large scale bound constrained\n",
      "       optimization. ACM Transactions on Mathematical Software 23 (4):\n",
      "       550-560.\n",
      "    .. [8] Nash, S G. Newton-Type Minimization Via the Lanczos Method.\n",
      "       1984. SIAM Journal of Numerical Analysis 21: 770-778.\n",
      "    .. [9] Powell, M J D. A direct search optimization method that models\n",
      "       the objective and constraint functions by linear interpolation.\n",
      "       1994. Advances in Optimization and Numerical Analysis, eds. S. Gomez\n",
      "       and J-P Hennart, Kluwer Academic (Dordrecht), 51-67.\n",
      "    .. [10] Powell M J D. Direct search algorithms for optimization\n",
      "       calculations. 1998. Acta Numerica 7: 287-336.\n",
      "    .. [11] Powell M J D. A view of algorithms for optimization without\n",
      "       derivatives. 2007.Cambridge University Technical Report DAMTP\n",
      "       2007/NA03\n",
      "    .. [12] Kraft, D. A software package for sequential quadratic\n",
      "       programming. 1988. Tech. Rep. DFVLR-FB 88-28, DLR German Aerospace\n",
      "       Center -- Institute for Flight Mechanics, Koln, Germany.\n",
      "    .. [13] Conn, A. R., Gould, N. I., and Toint, P. L.\n",
      "       Trust region methods. 2000. Siam. pp. 169-200.\n",
      "    .. [14] F. Lenders, C. Kirches, A. Potschka: \"trlib: A vector-free\n",
      "       implementation of the GLTR method for iterative solution of\n",
      "       the trust region problem\", :arxiv:`1611.04718`\n",
      "    .. [15] N. Gould, S. Lucidi, M. Roma, P. Toint: \"Solving the\n",
      "       Trust-Region Subproblem using the Lanczos Method\",\n",
      "       SIAM J. Optim., 9(2), 504--525, (1999).\n",
      "    .. [16] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. 1999.\n",
      "        An interior point algorithm for large-scale nonlinear  programming.\n",
      "        SIAM Journal on Optimization 9.4: 877-900.\n",
      "    .. [17] Lalee, Marucha, Jorge Nocedal, and Todd Plantega. 1998. On the\n",
      "        implementation of an algorithm for large-scale equality constrained\n",
      "        optimization. SIAM Journal on Optimization 8.3: 682-706.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Let us consider the problem of minimizing the Rosenbrock function. This\n",
      "    function (and its respective derivatives) is implemented in `rosen`\n",
      "    (resp. `rosen_der`, `rosen_hess`) in the `scipy.optimize`.\n",
      "    \n",
      "    >>> from scipy.optimize import minimize, rosen, rosen_der\n",
      "    \n",
      "    A simple application of the *Nelder-Mead* method is:\n",
      "    \n",
      "    >>> x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
      "    >>> res = minimize(rosen, x0, method='Nelder-Mead', tol=1e-6)\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    \n",
      "    Now using the *BFGS* algorithm, using the first derivative and a few\n",
      "    options:\n",
      "    \n",
      "    >>> res = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n",
      "    ...                options={'gtol': 1e-6, 'disp': True})\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.000000\n",
      "             Iterations: 26\n",
      "             Function evaluations: 31\n",
      "             Gradient evaluations: 31\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    >>> print(res.message)\n",
      "    Optimization terminated successfully.\n",
      "    >>> res.hess_inv\n",
      "    array([[ 0.00749589,  0.01255155,  0.02396251,  0.04750988,  0.09495377],  # may vary\n",
      "           [ 0.01255155,  0.02510441,  0.04794055,  0.09502834,  0.18996269],\n",
      "           [ 0.02396251,  0.04794055,  0.09631614,  0.19092151,  0.38165151],\n",
      "           [ 0.04750988,  0.09502834,  0.19092151,  0.38341252,  0.7664427 ],\n",
      "           [ 0.09495377,  0.18996269,  0.38165151,  0.7664427,   1.53713523]])\n",
      "    \n",
      "    \n",
      "    Next, consider a minimization problem with several constraints (namely\n",
      "    Example 16.4 from [5]_). The objective function is:\n",
      "    \n",
      "    >>> fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
      "    \n",
      "    There are three constraints defined as:\n",
      "    \n",
      "    >>> cons = ({'type': 'ineq', 'fun': lambda x:  x[0] - 2 * x[1] + 2},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] + 2 * x[1] + 2})\n",
      "    \n",
      "    And variables must be positive, hence the following bounds:\n",
      "    \n",
      "    >>> bnds = ((0, None), (0, None))\n",
      "    \n",
      "    The optimization problem is solved using the SLSQP method as:\n",
      "    \n",
      "    >>> res = minimize(fun, (2, 0), method='SLSQP', bounds=bnds,\n",
      "    ...                constraints=cons)\n",
      "    \n",
      "    It should converge to the theoretical solution (1.4 ,1.7).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(minimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Эта функция имеет стандартный интерфейс: нужно передать callable объект, который вычисляет значение и градиент целевой функции, а также точку старта оптимизации — начальное приближение (одномерный `numpy`-массив). Поэтому нам понадобятся функции для сбора и задания всех весов нашей нейросети (именно для них мы всегда записывали параметры слоя в список `layer.params`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.127145Z",
     "start_time": "2021-03-03T14:44:52.114180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_weights(network):\n",
    "    weights = []\n",
    "    for layer in network:\n",
    "        for param in layer.params:\n",
    "            weights += param.ravel().tolist()\n",
    "    return np.array(weights)\n",
    "\n",
    "\n",
    "def set_weights(weights, network):\n",
    "    i = 0\n",
    "    for layer in network:\n",
    "        for param in layer.params:\n",
    "            l = param.size\n",
    "            param[:] = weights[i:i+l].reshape(param.shape)\n",
    "            i += l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Вам нужно реализовать ту самую функцию, которую мы будем передавать в `minimize`. Эта функция должна брать на вход текущую точку (вектор всех параметров), а также список дополнительных параметров (мы будем передавать через них нашу сеть и обучающие данные) и возвращать значение критерия качества (NLL) и его градиент по параметрам модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.143103Z",
     "start_time": "2021-03-03T14:44:52.131134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_grad(weights, args):\n",
    "    \"\"\"\n",
    "    takes current weights and computes cross-entropy and gradients\n",
    "    weights shape: [num_parameters]\n",
    "    output 1: loss (scalar)\n",
    "    output 2: gradint w.r.t. weights, shape: [num_parameters]\n",
    "    \n",
    "    hint: firstly perform forward pass through the whole network\n",
    "    then compute loss and its gradients\n",
    "    then perform backward pass, transmitting first baskward output\n",
    "    to the previos layer and saving second baskward output in a list\n",
    "    finally flatten all the gradients in this list\n",
    "    (in the order from the first to the last layer)\n",
    "    \n",
    "    Do not forget to set weights of the network!\n",
    "    \"\"\"\n",
    "    network, X, y = args\n",
    "    set_weights(weights, network)\n",
    "    pred = forward(network, X)\n",
    "    loss = NLL(pred, y)\n",
    "    grad_y = grad_NLL(pred, y)\n",
    "    grad_params = []\n",
    "    for layer in network[::-1]:\n",
    "        grad_y, grad_layer_params = layer.backward(grad_y)\n",
    "        grad_params.append(grad_layer_params)\n",
    "    return loss, np.concatenate(grad_params[::-1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь мы готовы обучать нашу нейросеть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:52.175017Z",
     "start_time": "2021-03-03T14:44:52.148090Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights = get_weights(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.078366Z",
     "start_time": "2021-03-03T14:44:52.179006Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = minimize(\n",
    "    compute_loss_grad, weights,       # fun and start point\n",
    "    args=[network, X_train, y_train], # args passed to fun\n",
    "    method=\"L-BFGS-B\",                # optimization method\n",
    "    jac=True                          # says that gradient is computed in fun\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.093332Z",
     "start_time": "2021-03-03T14:44:53.081402Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fun', 'jac', 'nfev', 'njev', 'nit', 'status', 'message', 'x', 'success', 'hess_inv'])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.109290Z",
     "start_time": "2021-03-03T14:44:53.096325Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"nit\"] # number of iterations (should be >> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.125246Z",
     "start_time": "2021-03-03T14:44:53.112286Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"success\"] # should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.140244Z",
     "start_time": "2021-03-03T14:44:53.128239Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00223742, -0.0165439 ,  0.00377023, ..., -0.74982586,\n",
       "       -1.81001384, -0.39686915])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"x\"] # leraned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Выведите качество на обучении (`X_train`, `y_train`) и на контроле (`X_test`, `y_test`). Не забудьте установить веса!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.172124Z",
     "start_time": "2021-03-03T14:44:53.144212Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: 1.0\n",
      "Accuracy on test: 0.96\n"
     ]
    }
   ],
   "source": [
    "### your code here\n",
    "set_weights(res['x'], network)\n",
    "print(\"Accuracy on train:\", np.mean(predict(network, X_train) == y_train))\n",
    "print(\"Accuracy on test:\", np.mean(predict(network, X_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "У `minimize` есть также аргумент `callback` — в нее можно передать функцию, которая будет вызываться после каждой итерации оптимизации. Такую функцию удобно оформить в виде метода класса, который будет сохранять качество на обучении контроле после каждой итерации. Реализуйте этот метод в классе `Callback`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:53.188082Z",
     "start_time": "2021-03-03T14:44:53.175117Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def __init__(self, network, X_train, y_train, X_test, y_test, print=False):\n",
    "        self.network = network\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.print = print\n",
    "        self.train_acc = []\n",
    "        self.test_acc = []\n",
    "        \n",
    "    def call(self, weights):\n",
    "        \"\"\"\n",
    "        Computes quality on train and test set with given weights\n",
    "        and saves to self.train_acc and self.test_acc.\n",
    "        If self.print is True, also prints these 2 values\n",
    "        \"\"\"\n",
    "        set_weights(weights, self.network)\n",
    "        self.train_acc.append(np.mean(\n",
    "            predict(self.network, self.X_train) == self.y_train))\n",
    "        self.test_acc.append(np.mean(\n",
    "            predict(self.network, self.X_test) == self.y_test))\n",
    "\n",
    "        if self.print:\n",
    "            print(f\"Accuracy on train {self.train_acc[-1]:.4f} ||\",\n",
    "                   f\"test {self.test_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:54.497924Z",
     "start_time": "2021-03-03T14:44:53.191074Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train 0.1381 || test 0.1044\n",
      "Accuracy on train 0.1084 || test 0.0822\n",
      "Accuracy on train 0.1076 || test 0.0822\n",
      "Accuracy on train 0.1158 || test 0.0889\n",
      "Accuracy on train 0.1463 || test 0.1111\n",
      "Accuracy on train 0.2613 || test 0.2444\n",
      "Accuracy on train 0.3630 || test 0.3600\n",
      "Accuracy on train 0.4165 || test 0.4289\n",
      "Accuracy on train 0.5219 || test 0.5044\n",
      "Accuracy on train 0.6199 || test 0.6000\n",
      "Accuracy on train 0.6533 || test 0.6667\n",
      "Accuracy on train 0.6875 || test 0.6911\n",
      "Accuracy on train 0.7142 || test 0.7267\n",
      "Accuracy on train 0.7327 || test 0.7178\n",
      "Accuracy on train 0.7854 || test 0.7267\n",
      "Accuracy on train 0.7899 || test 0.7600\n",
      "Accuracy on train 0.8122 || test 0.7689\n",
      "Accuracy on train 0.8218 || test 0.7889\n",
      "Accuracy on train 0.8196 || test 0.8044\n",
      "Accuracy on train 0.8330 || test 0.8222\n",
      "Accuracy on train 0.8515 || test 0.8422\n",
      "Accuracy on train 0.8597 || test 0.8489\n",
      "Accuracy on train 0.8797 || test 0.8556\n",
      "Accuracy on train 0.8916 || test 0.8778\n",
      "Accuracy on train 0.8938 || test 0.8867\n",
      "Accuracy on train 0.9072 || test 0.8867\n",
      "Accuracy on train 0.9146 || test 0.8933\n",
      "Accuracy on train 0.9161 || test 0.8911\n",
      "Accuracy on train 0.9154 || test 0.8978\n",
      "Accuracy on train 0.9295 || test 0.9044\n",
      "Accuracy on train 0.9332 || test 0.9133\n",
      "Accuracy on train 0.9391 || test 0.9178\n",
      "Accuracy on train 0.9391 || test 0.9222\n",
      "Accuracy on train 0.9421 || test 0.9222\n",
      "Accuracy on train 0.9465 || test 0.9244\n",
      "Accuracy on train 0.9532 || test 0.9244\n",
      "Accuracy on train 0.9569 || test 0.9333\n",
      "Accuracy on train 0.9681 || test 0.9311\n",
      "Accuracy on train 0.9659 || test 0.9333\n",
      "Accuracy on train 0.9681 || test 0.9289\n",
      "Accuracy on train 0.9688 || test 0.9333\n",
      "Accuracy on train 0.9733 || test 0.9333\n",
      "Accuracy on train 0.9755 || test 0.9333\n",
      "Accuracy on train 0.9792 || test 0.9311\n",
      "Accuracy on train 0.9792 || test 0.9289\n",
      "Accuracy on train 0.9807 || test 0.9289\n",
      "Accuracy on train 0.9792 || test 0.9378\n",
      "Accuracy on train 0.9822 || test 0.9378\n",
      "Accuracy on train 0.9829 || test 0.9356\n",
      "Accuracy on train 0.9874 || test 0.9422\n",
      "Accuracy on train 0.9889 || test 0.9444\n",
      "Accuracy on train 0.9903 || test 0.9422\n",
      "Accuracy on train 0.9918 || test 0.9444\n",
      "Accuracy on train 0.9933 || test 0.9444\n",
      "Accuracy on train 0.9933 || test 0.9467\n",
      "Accuracy on train 0.9948 || test 0.9489\n",
      "Accuracy on train 0.9948 || test 0.9467\n",
      "Accuracy on train 0.9970 || test 0.9467\n",
      "Accuracy on train 0.9963 || test 0.9467\n",
      "Accuracy on train 0.9970 || test 0.9422\n",
      "Accuracy on train 0.9978 || test 0.9400\n",
      "Accuracy on train 0.9993 || test 0.9400\n",
      "Accuracy on train 0.9993 || test 0.9378\n",
      "Accuracy on train 1.0000 || test 0.9378\n",
      "Accuracy on train 1.0000 || test 0.9378\n",
      "Accuracy on train 1.0000 || test 0.9378\n",
      "Accuracy on train 1.0000 || test 0.9378\n",
      "Accuracy on train 1.0000 || test 0.9400\n",
      "Accuracy on train 1.0000 || test 0.9400\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9444\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9489\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9467\n",
      "Accuracy on train 1.0000 || test 0.9533\n",
      "Accuracy on train 1.0000 || test 0.9489\n",
      "Accuracy on train 1.0000 || test 0.9578\n",
      "Accuracy on train 1.0000 || test 0.9578\n",
      "Accuracy on train 1.0000 || test 0.9600\n",
      "Accuracy on train 1.0000 || test 0.9600\n",
      "Accuracy on train 1.0000 || test 0.9578\n",
      "Accuracy on train 1.0000 || test 0.9556\n",
      "Accuracy on train 1.0000 || test 0.9556\n",
      "Accuracy on train 1.0000 || test 0.9578\n",
      "Accuracy on train 1.0000 || test 0.9578\n",
      "Accuracy on train 1.0000 || test 0.9600\n",
      "Accuracy on train 1.0000 || test 0.9600\n",
      "Accuracy on train 1.0000 || test 0.9600\n",
      "Accuracy on train 1.0000 || test 0.9600\n",
      "Accuracy on train 1.0000 || test 0.9600\n"
     ]
    }
   ],
   "source": [
    "cb = Callback(network, X_train, y_train, X_test, y_test, print=True)\n",
    "\n",
    "res = minimize(\n",
    "    compute_loss_grad, weights,  \n",
    "    args=[network, X_train, y_train], \n",
    "    method=\"L-BFGS-B\",\n",
    "    jac=True,\n",
    "    callback=cb.call\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Изобразите на графике кривую качества на обучени и контроле по итерациям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:54.816117Z",
     "start_time": "2021-03-03T14:44:54.500922Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.plot(cb.train_acc, label=\"train acc\")\n",
    "ax.plot(cb.test_acc, label=\"test acc\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Эксперименты с числом слоев (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ясно, что из-за случайного начального приближения с каждым запуском обучения мы будем получать различное качество. Попробуем обучить нашу нейросеть с разным числом слоев несколько раз.\n",
    "\n",
    "Заполните матрицы `accs_train` и `accs_test`. В позиции `[i, j]` должна стоять величина доли правильных ответов сети с $i+1$ полносвязными слоями при $j$-м запуске (все запуски идентичны)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:44:54.832074Z",
     "start_time": "2021-03-03T14:44:54.819071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:56.444624Z",
     "start_time": "2021-03-03T14:44:54.836024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### your code here\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        network = make_network( \n",
    "            input_size, hidden_layers_size, output_size, n_layers=i + 1,\n",
    "            activation_class=ReLU)\n",
    "\n",
    "        res = minimize(\n",
    "            compute_loss_grad, get_weights(network),       \n",
    "            args=[network, X_train, y_train], \n",
    "            method=\"L-BFGS-B\",                \n",
    "            jac=True)\n",
    "        \n",
    "        set_weights(res['x'], network)\n",
    "\n",
    "        accs_train[i, j] = np.mean(predict(network, X_train) == y_train)\n",
    "        accs_test[i, j] = np.mean(predict(network, X_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.060827Z",
     "start_time": "2021-03-03T14:45:56.447467Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "axes[0].boxplot(accs_train.T, showfliers=False)\n",
    "axes[1].boxplot(accs_test.T, showfliers=False)\n",
    "\n",
    "axes[0].set_xlabel(\"Number of layers\")\n",
    "axes[1].set_xlabel(\"Number of layers\")\n",
    "\n",
    "axes[0].set_ylabel(\"Train accuracy\")\n",
    "axes[1].set_ylabel(\"Test accuracy\")\n",
    "\n",
    "axes[0].set_title(\"Train quality in 5 runs\")\n",
    "axes[1].set_title(\"Test quality in 5 runs\")\n",
    "\n",
    "axes[0].grid(True)\n",
    "axes[1].grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как изменяются качество на обучении и контроле и устойчивость процесса обучения при увеличении числа слоев?\n",
    "* Можно ли сказать, что логистическая регрессия (линейная модель) дает качество хуже, чем нелинейная модель?\n",
    "\n",
    "__Ответы:__\n",
    "1.  a) На обучении качество константное и равно 1   \n",
    "    b) На контроле качество растет при увеличении слоев до 3 включая, а с использованием 4 и 5 слоев падает, что вероятно связано с тем, что модель сильно подгоняется под обучающую выборку  \n",
    "    с) Аналогичные в b) рассуждения можно применить и в отношении устойчивости(разброса) модели. С 1 до 4 слоев, в целом, модель устойчива, а с использованием 5 слоев модель опять же очень сильно подгоняется под конкретную выборку, поэтому, когда ей подается иная выборка, она становится плохой по accuracy.\n",
    "2. И да, и нет. Все зависит от количества слоев в нейронке. Если используем 2, 3 слоя, то видно, что медиана выше медианы для логистической регрессии. Если 4, 5, то логистическая регрессия, во-первых, устойчивее, а во-вторых медиана ее accuracy выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Эксперименты c различными инициализациями весов (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Как уже было сказано, начальная инициализация весов нейронной сети может сильно влиять на процесс ее обучения и, как следствие, на ее качество.\n",
    "\n",
    "В этом пункте вам предлагается попробовать обучить несколько нейронных сетей с различными инициализациями слоев.\n",
    "\n",
    "Для этого необходимо реализовать функцию, инициализирующую веса линейных слоёв нашей нейронной сети. Добавьте в функционал данного метода возможность инициализировать его веса с помощью инициализации Kaiming (используется, если в нейронной сети в качестве функций активации используется ReLU) и инициализации Xavier (используется, если в нейронной сети в качестве функций активации используется Tanh или Sigmoid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.075786Z",
     "start_time": "2021-03-03T14:45:57.063819Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def initialize_network(network, initialization):\n",
    "    for layer in network:\n",
    "        if isinstance(layer, Dense):\n",
    "            input_units, output_units = layer.weights.shape\n",
    "            if initialization == 'Kaiming':\n",
    "                ### your code here\n",
    "                layer.weights = np.random.normal(0, np.sqrt(2 / input_units), (input_units, output_units))\n",
    "                pass\n",
    "            elif initialization == 'Xavier':\n",
    "                layer.weights = np.random.normal(0, np.sqrt(2 / (input_units + output_units)), (input_units, output_units))\n",
    "                pass\n",
    "            else:\n",
    "                # Initialize weights with small random numbers from normal distribution.\n",
    "                # In this case `initialization` represents a standard deviation\n",
    "                # for normal distribution.\n",
    "                layer.weights = np.random.randn(input_units, output_units) * initialization\n",
    "            layer.biases = np.zeros_like(layer.biases)\n",
    "            \n",
    "            layer.params = [layer.weights, layer.biases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь попробуйте для каждой из 3 инициализаций обучить нейронную сеть несколько раз. Попробуйте проделать данную операцию при зафиксированном числе слоев равным 3, 4 и 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `3 слоя`\n",
    "\n",
    "Зафиксируйте в сети число слоев равное трем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Заполните матрицы `accs_train` и `accs_test`. В позиции `[i, j]` должна стоять величина доли правильных ответов сети при $j$-м запуске (все запуски идентичны) с инициализацией Kaiming при $i = 3$, с инициализацией Xavier при $i = 4$ и с инициализацией из нормального распределения с фиксированными параметрами при $0 \\leqslant i \\leqslant 2$ (попробуйте здесь 3 разных параметра для стандартного отклонения для нормального распределения, например: `1e-3`, `1e-2`, `1e-1`). Заметьте, что при большом числе слоев слишком низкое стандартное отклонение может не давать нейронной сети нормально обучиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.091744Z",
     "start_time": "2021-03-03T14:45:57.079777Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init_vars = [1e-3, 1e-2, 1e-1, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.107701Z",
     "start_time": "2021-03-03T14:45:57.094737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:27.904407Z",
     "start_time": "2021-03-03T14:45:57.111690Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### your code here\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        network = make_network( \n",
    "            input_size, hidden_layers_size, output_size, n_layers=3,\n",
    "            activation_class=ReLU)\n",
    "\n",
    "        initialize_network(network, init_vars[i])\n",
    "        \n",
    "        res = minimize(\n",
    "            compute_loss_grad, get_weights(network),       \n",
    "            args=[network, X_train, y_train], \n",
    "            method=\"L-BFGS-B\",                \n",
    "            jac=True)\n",
    "        \n",
    "        set_weights(res['x'], network)\n",
    "\n",
    "        accs_train[i, j] = np.mean(predict(network, X_train) == y_train)\n",
    "        accs_test[i, j] = np.mean(predict(network, X_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:28.632502Z",
     "start_time": "2021-03-03T14:46:27.907401Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_train.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Train quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Train accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `4 слоя`\n",
    "\n",
    "Выполните тут тот же код, что и в предыдущем пункте, но только уже с 4 слоями в сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.091744Z",
     "start_time": "2021-03-03T14:45:57.079777Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init_vars = [5e-3, 1e-2, 1e-1, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.107701Z",
     "start_time": "2021-03-03T14:45:57.094737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:27.904407Z",
     "start_time": "2021-03-03T14:45:57.111690Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        network = make_network( \n",
    "            input_size, hidden_layers_size, output_size, n_layers=4,\n",
    "            activation_class=ReLU)\n",
    "\n",
    "        initialize_network(network, init_vars[i])\n",
    "        \n",
    "        res = minimize(\n",
    "            compute_loss_grad, get_weights(network),       \n",
    "            args=[network, X_train, y_train], \n",
    "            method=\"L-BFGS-B\",                \n",
    "            jac=True)\n",
    "        \n",
    "        set_weights(res['x'], network)\n",
    "\n",
    "        accs_train[i, j] = np.mean(predict(network, X_train) == y_train)\n",
    "        accs_test[i, j] = np.mean(predict(network, X_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:28.632502Z",
     "start_time": "2021-03-03T14:46:27.907401Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_train.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Train quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Train accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `5 слоев`\n",
    "\n",
    "Выполните тут тот же код, что и в предыдущем пункте, но только уже с 5 слоями в сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.091744Z",
     "start_time": "2021-03-03T14:45:57.079777Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init_vars = [1e-2, 1e-1, 1e0, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.107701Z",
     "start_time": "2021-03-03T14:45:57.094737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((5, 5))\n",
    "accs_test = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:27.904407Z",
     "start_time": "2021-03-03T14:45:57.111690Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### your code here\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        network = make_network( \n",
    "            input_size, hidden_layers_size, output_size, n_layers=5,\n",
    "            activation_class=ReLU)\n",
    "\n",
    "        initialize_network(network, init_vars[i])\n",
    "        \n",
    "        res = minimize(\n",
    "            compute_loss_grad, get_weights(network),       \n",
    "            args=[network, X_train, y_train], \n",
    "            method=\"L-BFGS-B\",                \n",
    "            jac=True)\n",
    "        \n",
    "        set_weights(res['x'], network)\n",
    "\n",
    "        accs_train[i, j] = np.mean(predict(network, X_train) == y_train)\n",
    "        accs_test[i, j] = np.mean(predict(network, X_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:28.632502Z",
     "start_time": "2021-03-03T14:46:27.907401Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAFgCAYAAACmDI9oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfEUlEQVR4nO3de5hlVX3m8e9rNwgKQhO0jYA2JqiDxBsNOKNJSp0o6GSIiRPFRIMjdFBI4pOYyJNMAmguRkw0RrRFg8QEJVFJJAYlQa3gNdxEEAXtgEADilwUC+TS8Js/zi5ZXVRXnWpq1znd/f08Tz199t5rr/M7pxbFW6vW2TtVhSRJkqSBh4y6AEmSJGmcGJAlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWoYkCVJkqSGAVmSNiHJJ5L82qjraCVZlaSSLO+2F63GJGuT/OFi9CVJW7J4HWRJW5MkU83mw4C7gHu77V+vqtOWvqrFk2QVcBWwXVVtmHHscOCIqnr2COo6FXg5cHeze5equnf2MyRpfDmDLGmrUlU7TX8B1wA/3+z7UTienoHVonpL+/4PG479XkgaNwZkSduEJBNJ1id5Q5JvA+9PsiLJx5N8N8mt3eM9m3MmkxzRPT48yeeSvLVre1WSQ+Z4vqcnuSjJD5L8Q5LTk/xx29eM9pXkJ7vHL0ry5SS3Jbk2yfFzPM9kkiOS/DdgLfDfk0wl+V6SA5J8pw2gSX4pycWb6OvUpsbp9+t3ktyY5IYkr5r3jR7CJr4X870npyY5Kcm/du/pfyb5ie5Ykrytq/P7SS5Jst9i1Cpp22RAlrQteTSwG/A4YA2Dn4Hv77YfC/wQeOcc5x8EXAHsDrwF+JskmdkoyfbAPwN/1z3fh4FfWkCdtwOvBHYFXgS8JskvzHVCVX0dOAr4Yjd7u2tVnQ/cDPxc0/RXu7qG8WhgF2AP4NXASUlWzNH+tUluSXJhkvle78zvxTAOA04AVgDrgD/p9j8f+BngCQzes5cyeN2StFkMyJK2JfcBx1XVXVX1w6q6uao+WlV3VNUPGASun53j/Kur6r3d0oG/BX4cWDlLu2cC2wFvr6p7quojwPnDFllVk1V1aVXdV1WXAB+ap665/C2DUEyS3YAXAB8c8tx7gDd2r+EsYAp44ibavgPYB3gU8IfAqUmeNUffG30vhqznjKo6r1t7fRrwtKbOnYEnMfhszder6oYh+5SkBzAgS9qWfLeq7pzeSPKwJO9JcnWS24BzgV2TLNvE+d+eflBVd3QPd5ql3WOA62rjT0FfPWyRSQ5K8plu6cf3GcwM7z7s+TP8PfDzSXYCfhn47ALC480zPgh4B7O/Xqrqou4Xjg1dmD4N+MU5+t7oezGkbzePf1RLVX2awcz/ScB3kpyc5BEL7FuSfsSALGlbMvOyPb/DYEb0oKp6BIM/0wM8YNnEAt0A7DFj+cVjm8e3M7jCxuDJkkfPOP+DwJnAXlW1C4O1xcPU9IDLElXVdcAXgRcDr2D45RUPVjF3zTNrne89mfvJqt5RVfsDT2aw1OJ3F3K+JLUMyJK2ZTszWHf8vW75wXGL1O8XgQ3AbyZZnuQXgQOb418BnpzkaUl2AI6fpa5bqurOJAcyuHzaML4D7NmtgW59APg94KeAf1rYSxlOkpck2SnJQ5I8n8GyjjMX0MV878lcz31AN+u+HYOgfSf3X9pPkhbMgCxpW/Z2YEfgJuBLwCcXo9OqupvB8oLDgVsZfGjsjOb4N4A3AucA3wQ+N6OL1wJvTPID4I+AfxzyqT8NXAZ8O8lNzf5/YvBhuH+qqtsX+nqG9FvAdcD3gBOBI6tqctiTh3hP5vII4L0M3uurGXxA760LOF+SNuKNQiRpCXQ30lhfVf9vRM//XwxulHLOKJ5fkrYkziBL0lauu+RaMZhhliTNw7sXSdJWLMkksC/wiqq6b8TlSNIWwSUWkiRJUsMlFpIkSVJji1tisfvuu9eqVatGXcbI3X777Tz84Q8fdRkaI44JtRwPajke1HI83O/CCy+8qaoeOXP/FheQV61axQUXXDDqMkZucnKSiYmJUZehMeKYUMvxoJbjQS3Hw/2SzHqXU5dYSJIkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktToLSAnOSXJjUm+uonjSfKOJOuSXJLkGX3VIkmSJA2rzxnkU4GD5zh+CLBP97UGeHePtUiSJElD6S0gV9W5wC1zNDkU+EANfAnYNcmP91WPJEmSNIxRrkHeA7i22V7f7ZMkSZJGZvkInzuz7KtZGyZrGCzDYOXKlUxOTvZY1vwmJg8d6fMDTABMjrYGgMmJj426hLHgmLifY2I8TE1NjfxnpQb8+XA/fz44HmYa1zGRqlkz6eJ0nqwCPl5V+81y7D3AZFV9qNu+Apioqhvm6nP16tV1wQUX9FHuFmVycpKJiYlRl6Ex4phQy/GgluNBLcfD/ZJcWFWrZ+4f5RKLM4FXdlezeCbw/fnCsSRJktS33pZYJPkQg1n83ZOsB44DtgOoqrXAWcALgXXAHcCr+qpFkiRJGlZvAbmqDpvneAFH9/X8kiRJ0ubwTnqSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNXoNyEkOTnJFknVJjp3l+C5J/iXJV5JcluRVfdYjSZIkzae3gJxkGXAScAiwL3BYkn1nNDsa+FpVPRWYAP4iyfZ91SRJkiTNp88Z5AOBdVV1ZVXdDZwOHDqjTQE7JwmwE3ALsKHHmiRJkqQ5Le+x7z2Aa5vt9cBBM9q8EzgTuB7YGXhpVd03s6Mka4A1ACtXrmRycrKPercoU1NTvg/aiGNCLceDWo4HtRwP8+szIGeWfTVj+wXAxcBzgZ8A/j3JZ6vqto1OqjoZOBlg9erVNTExsejFbmkmJyfxfVDLMaGW40Etx4Najof59bnEYj2wV7O9J4OZ4targDNqYB1wFfCkHmuSJEmS5tRnQD4f2CfJ3t0H717GYDlF6xrgeQBJVgJPBK7ssSZJkiRpTr0tsaiqDUmOAc4GlgGnVNVlSY7qjq8F3gScmuRSBksy3lBVN/VVkyRJkjSfPtcgU1VnAWfN2Le2eXw98Pw+a5AkSZIWwjvpSZIkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEmNeQNykguSHJ1kxVIUJEmSJI3SMDPILwMeA5yf5PQkL0iSnuuSJEmSRmLegFxV66rqD4AnAB8ETgGuSXJCkt36LlCSJElaSkOtQU7yFOAvgBOBjwIvAW4DPt1faZIkSdLSWz5fgyQXAt8D/gY4tqru6g79Z5Jn9VibJEmStOTmDcjA/6mqK2c7UFW/uMj1SJIkSSM1zBKLI5LsOr2RZEWSP+6vJEmSJGl0hgnIh1TV96Y3qupW4IW9VSRJkiSN0DABeVmSh05vJNkReOgc7SVJkqQt1jBrkP8e+FSS9wMF/F/gb3utSpIkSRqReQNyVb0lyaXA84AAb6qqs3uvTJIkSRqBYWaQqapPAJ/ouRZJkiRp5OZdg5zkmUnOTzKV5O4k9ya5bSmKkyRJkpbaMB/SeydwGPBNYEfgCOCv+yxKkiRJGpVhl1isS7Ksqu4F3p/kCz3XJUmSJI3EMAH5jiTbAxcneQtwA/DwfsuSJEmSRmOYJRav6NodA9wO7AX8Up9FSZIkSaMyZ0BOsgz4k6q6s6puq6oTquq3q2rdMJ0nOTjJFUnWJTl2E20mklyc5LIk/7EZr0GSJElaNHMusaiqe5M8Msn2VXX3QjruwvVJwM8B64Hzk5xZVV9r2uwKvAs4uKquSfKoBb8CSZIkaRENswb5W8Dnk5zJYIkFAFX1l/OcdyCwrqquBEhyOnAo8LWmzcuBM6rqmq7PG4cvXZIkSVp8wwTk67uvhwA7L6DvPYBrm+31wEEz2jwB2C7JZNf3X1XVB2Z2lGQNsAZg5cqVTE5OLqCMrdPU1JTvgzbimFDL8aCW40Etx8P8hrnV9Amb2Xdm626W59+fwW2sdwS+mORLVfWNGTWcDJwMsHr16pqYmNjMkrYek5OT+D6o5ZhQy/GgluNBLcfD/OYNyEk+wwODLVX13HlOXc/gihfT9mQwEz2zzU1VdTtwe5JzgacC30CSJEkagWGWWLy+ebwDg0u8bRjivPOBfZLsDVwHvIzBmuPWx4B3JlkObM9gCcbbhuhbkiRJ6sUwSywunLHr88Ncjq2qNiQ5BjgbWAacUlWXJTmqO762qr6e5JPAJcB9wPuq6qsLfhWSJEnSIhlmicVuzeZDGKwZfvQwnVfVWcBZM/atnbF9InDiMP1JkiRJfRtmicWFDNYgh8HSiquAV/dZlCRJkjQqwyyx2HspCpEkSZLGwZy3mgZIcnR3x7vp7RVJXttrVZIkSdKIzBuQgSOr6nvTG1V1K3BkbxVJkiRJIzRMQH5Ikh/d9CPJMgaXZJMkSZK2OsN8SO9s4B+TrGXwYb2jgE/2WpUkSZI0IsME5DcAa4DXMLiSxb8B7+uzKEmSJGlUhgnIOwLvnb5+cbfE4qHAHX0WJkmSJI3CMGuQP8UgJE/bETinn3IkSZKk0RomIO9QVVPTG93jh/VXkiRJkjQ6wwTk25M8Y3ojyf7AD/srSZIkSRqdYdYgvw74cJLru+0fB17aW0WSJEnSCA1zq+nzkzwJeCKDq1hcXlX39F6ZJEmSNALDzCDDIBzvC+wAPD0JVfWB/sqSJEmSRmPegJzkOGCCQUA+CzgE+BxgQJYkSdJWZ5gP6b0EeB7w7ap6FfBUBtdBliRJkrY6wwTkH1bVfcCGJI8AbgQe329ZkiRJ0mgMswb5giS7Au8FLgSmgPP6LEqSJEkalWGuYvHa7uHaJJ8EHlFVl/RbliRJkjQaw17FAoCq+lZPdUiSJEljYZg1yJIkSdI2w4AsSZIkNYZaYpFkGbCybV9V1/RVlCRJkjQqw9wo5DeA44DvAPd1uwt4So91SZIkSSMxzAzybwFPrKqb+y5GkiRJGrVh1iBfC3y/70IkSZKkcTDMDPKVwGSSfwXumt5ZVX/ZW1WSJEnSiAwTkK/pvrbvviRJkqSt1jB30jthKQqRJEmSxsEmA3KSt1fV65L8C4OrVmykqv53r5VJkiRJIzDXDPLfdf++dSkKkSRJksbBJgNyVV3Y/fsfS1eOJEmSNFrD3ChkH+DPgH2BHab3V9Xje6xLkiRJGolhroP8fuDdwAbgOcAHuH/5hSRJkrRVGSYg71hVnwJSVVdX1fHAc/stS5IkSRqNYa6DfGeShwDfTHIMcB3wqH7LkiRJkkZjmBnk1wEPA34T2B/4VeDXeqxJkiRJGpk5Z5CTLAN+uap+F5gCXrUkVUmSJEkjsskZ5CTLq+peYP8kWcKaJEmSpJGZawb5POAZwJeBjyX5MHD79MGqOqPn2iRJkqQlN8yH9HYDbmZw5YoC0v1rQJYkSdJWZ66A/Kgkvw18lfuD8bTqtSpJkiRpROYKyMuAndg4GE8zIEuSJGmrNFdAvqGq3rhklUiSJEljYK7rIHvlCkmSJG1z5grIz1uyKiRJkqQxscmAXFW3LGUhkiRJ0jgY5lbTkiRJ0jbDgCxJkiQ1DMiSJElSo9eAnOTgJFckWZfk2DnaHZDk3iQv6bMeSZIkaT69BeQky4CTgEOAfYHDkuy7iXZ/DpzdVy2SJEnSsPqcQT4QWFdVV1bV3cDpwKGztPsN4KPAjT3WIkmSJA1lrjvpPVh7ANc22+uBg9oGSfYAXgw8FzhgUx0lWQOsAVi5ciWTk5OLXesWZ2pqyvdBG3FMqOV4UMvxoJbjYX59BuTZ7sRXM7bfDryhqu5NNn3jvqo6GTgZYPXq1TUxMbFIJW65Jicn8X1QyzGhluNBLceDWo6H+fUZkNcDezXbewLXz2izGji9C8e7Ay9MsqGq/rnHuiRJkqRN6jMgnw/sk2Rv4DrgZcDL2wZVtff04ySnAh83HEuSJGmUegvIVbUhyTEMrk6xDDilqi5LclR3fG1fzy1JkiRtrj5nkKmqs4CzZuybNRhX1eF91iJJkiQNwzvpSZIkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1Fg+6gIkaWuz2267ceutt466jJFbsWIFt9xyy6jLkKQFMyBL0iK79dZbqaqR1jA5OcnExMRIa0gy0ueXpM3lEgtJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKmxfNQFSNLWpo57BBy/y0hrmACYHGkJg/dBkrZAvQbkJAcDfwUsA95XVW+ecfxXgDd0m1PAa6rqK33WJEl9ywm3UVUjrWFycpKJiYmR1pCEOn6kJUjSZultiUWSZcBJwCHAvsBhSfad0ewq4Ger6inAm4CT+6pHkiRJGkafa5APBNZV1ZVVdTdwOnBo26CqvlBVt3abXwL27LEeSZIkaV59LrHYA7i22V4PHDRH+1cDn5jtQJI1wBqAlStXMjk5uUglbrmmpqZ8H7QRx8R4GfX3YlzGwzjUoPEZDxoPjof59RmQM8u+WRflJXkOg4D87NmOV9XJdMsvVq9eXaNeVzcOxmF9ocaLY2K8jPp7MS7jYRxq0PiMB40Hx8P8+gzI64G9mu09getnNkryFOB9wCFVdXOP9UiSJEnz6nMN8vnAPkn2TrI98DLgzLZBkscCZwCvqKpv9FiLJEmSNJTeZpCrakOSY4CzGVzm7ZSquizJUd3xtcAfAT8GvCsJwIaqWt1XTZIkSdJ8er0OclWdBZw1Y9/a5vERwBF91iBJkiQthLealiRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKmxfNQFSNLWKMmoSxi5FStWjLoESdosBmRJWmRVNeoSSDIWdUjSlsiALEljZrFmnx9sPwZsSdsq1yBL0pipqgf99ZnPfOZB9yFJ2yoDsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1EhVjbqGBUnyXeDqUdcxBnYHbhp1ERorjgm1HA9qOR7Ucjzc73FV9ciZO7e4gKyBJBdU1epR16Hx4ZhQy/GgluNBLcfD/FxiIUmSJDUMyJIkSVLDgLzlOnnUBWjsOCbUcjyo5XhQy/EwD9cgS5IkSQ1nkCVJkqSGAVmSJElqGJAlSRpDSaaaxy9M8s0kj52j/VFJXrnA5/jCg6lRo5NkryRXJdmt217RbT9ugf08JslH+qlyy+UaZEmSxlCSqaraKcnzGHyo6vlV9V+jrkvjI8nvAT9ZVWuSvAf4VlX9Wc/Puayq7u3zOcaBM8hboCQHJ7kiybokxy60XZJTktyY5KtLU7GW0gLGh+NgGzDs93nYcaOlleSngfcCL5oOx0mOTHJ+kq8k+WiSh3X7j0/y+u7xZJK3JTk3ydeTHJDkjG4W+o+b/qe6fye6cz6S5PIkpyVJd+yF3b7PJXlHko8v9fugTXob8MwkrwOeDfxFkp2SfCrJRUkuTXIoQJI/T/La6RO78fI7SVZN/3xIsizJid34uiTJr3f7J5J8JskHgUuX/FWOgAF5C5NkGXAScAiwL3BYkn0X2O5U4OAlKVhLatjx0TkVx8G24FTm+T4vcNxo6TwU+BjwC1V1ebP/jKo6oKqeCnwdePUmzr+7qn4GWNv1czSwH3B4kh+bpf3TgdcxGAOPB56VZAfgPcAhVfVs4AG35NXoVNU9wO8yCMqvq6q7gTuBF1fVM4DnMAjNAU4HXtqc/svAh2d0+Wrg+1V1AHAAcGSSvbtjBwJ/UFXbxM8GA/ISSvLU7rf5ryW5L0klOWGB3RwIrKuqK7v/EE4HDl1Iu6o6F7jlQbwU9WCJx4fjYMwt0ngY9vs89LjRkroH+AIPDMD7JflskkuBXwGevInzz+z+vRS4rKpuqKq7gCuBvWZpf15Vra+q+4CLgVXAk4Arq+qqrs2HNvfFqDeHADcw+OUHIMCfJrkEOAfYA1hZVV8GHtWtOX4qcGtVXTOjr+cDr0xyMfCfwI8B+3THzmvGwVZv+agL2FZ0v4X/A/DKqjovyZuAHYDjmzafBXae5fTXV9U53eM9gGubY+uBg2Y5Z9h2GgMjGB8aY4s4HobluBlP9zGY5Tsnye9X1Z92+09lMKv8lSSHAxObOP+upp+7mv33Mfv//9s293ZtslmVa0kkeRrwc8Azgc8lOR14AYOZ/v2r6p4k32Lw8wPgI8BLgEcz+EX4AV0Cv1FVZ894ngng9sV/BePLgLx0/idwUVWd121fAhxczackq+qnh+hnth9Ws33Scth2Gg9LPT403hZrPAzLcTOmquqOJP8L+GyS71TV3zD4xeiGJNsxmEG+rscSLgcen2RVVX2Ljf9ErxHqlk28m8HSimuSnAi8FTgPuLELx88B2qtanM5gTfvuwM/O0u3ZwGuSfLo7/wn0O77GlgF56ezHxgvbnwFc1DYYckZoPRv/aWxP4PpZzhm2ncbDUo8PjbfFGg/DctyMsaq6JcnBwLlJbgL+kMGfv69mME5mGweL9dw/7D7Y9cnuuc+b7xwtmSOBa6rq37vtdwGHM7jiycuSXMBgqcyP1q9X1WVJdgauq6obZunzfQyW1lzUBfDvAr/QU/1jzcu8LZEkRwLPrarDut/I/gX4H1V18wL7WQ58A3geg9/qzgdeXlWXLaRdklXAx6tqPzRySz0+mvarcByMncUaD01/q5jj+7zQcaNtS5KdqmqqC0wnAd+sqreNui6pT35Ib+l8CNipu5TKycBhm/M/u6raABzD4M8gXwf+sQm9ZyV5zBDtPgR8EXhikvVJNvUJaC2dJR0f3bbjYHwtyniATX+fh/15ITG4ksHFwGXALgyuaiFt1ZxBliRJkhrOIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiT1KMnUEG3el2Tf7vHvzzj2hWGfI8ljknxkM2rctbsZxPT2ZvUjSVsLL/MmST1KMlVVO/XVfnPPmXH+KrxhjCT9iDPIkrQEkkwkmUzykSSXJzmtuzMZ3f7VSd4M7Jjk4iSndcemZ4d3SvKpJBcluTTJobM8x6ru5iLTs9IXd1/fTXLcHH28GfiJru2JM/rZIcn7u/ZfTvKcbv/hSc5I8skk30zylt7fRElaIstHXYAkbUOeDjwZuB74PPAs4HPTB6vq2CTHVNXTZjn3TuDFVXVbkt2BLyU5szbxZ8CqOgIgyeMY3CHv1E31ARwL7Df9vN2M8rSju/5+KsmTgH/rbn8N8LTuNd0FXJHkr6vq2oW9JZI0fpxBlqSlc15Vra+q+4CLgVULODfAnya5BDgH2ANYOecJyQ7Ah4FjqurqzekDeDbwdwBVdTlwNTAdkD9VVd+vqjuBrwGPW8DrkaSx5QyyJC2du5rH97Kwn8G/AjwS2L+q7knyLWCHec5ZC5xRVec8iD4yx7EH83okaWw5gyxJ4+WeJNvNsn8X4MYu2D6HeWZrkxwN7FxVbx6ijx8AO2+iq3MZBGu6pRWPBa4Y+tVI0hbIgCxJ4+Vk4JLpD+k1TgNWJ7mAQWC9fJ5+Xg/8VPNBvaM21UdV3Qx8PslXk5w4o593AcuSXAr8A3B4Vd2FJG3FvMybJEmS1HAGWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWr8f4lDt5x8vsgQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_train.T, labels=init_vars_for_plot, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Train quality in 5 runs\")\n",
    "ax.set_xlabel(\"Initialization\")\n",
    "ax.set_ylabel(\"Train accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как отличаются качество на обучении и контроле и устойчивость процесса обучения при различных инициализациях?\n",
    "* Какие инициализации помогают обучать более глубокие сети?\n",
    "\n",
    "__Ответы:__\n",
    "1.  a) На обучении качество константное и равно 1 почти везде кроме случая с 5 слоями и с $\\sigma=1.0$  нормальное распределение  \n",
    "    b) При 3-х слоях все инициализации дают примерно одно и тоже значение лосса кроме случая при $\\sigma = 0.001$(тут медиана accuracy отличается от остальных примерно на 0.01). Причем устойчивость во всех случаях примерно одна. При 4-х слоях видно, что решения с нормальным распределением с $\\sigma$ не очень устойчивые и дают хуже результаты чем, если  использовать Kaiming и Xavier, которые к томе же еще и более устойчивые. При 5 слоях в целом все инициализации примерно дают один результат и по качеству и по разбросу, исключением будет только выбор нормального распредления с $\\sigma=1.0$   \n",
    "2. Лучшим вариантом будет Kaiming и Xavier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь сравним скорость обучения при различных инициализациях. Создайте два списка списков `accs_test_on_iterations`, `accs_train_on_iterations` в каждом из которых в позиции `[i]` (см. описание `i` в предыдущем пункте) будет лежать список из значений `accuracy` на тестовой и обучающей выборках соотвественно, полученных во время обучения модели. Количество слоев в сети зафиксируйте равным 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:45:57.091744Z",
     "start_time": "2021-03-03T14:45:57.079777Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init_vars = [1e-3, 1e-2, 1e-1, 'Kaiming', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:28.647453Z",
     "start_time": "2021-03-03T14:46:28.635495Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accs_test_on_iterations = []\n",
    "accs_train_on_iterations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:34.433662Z",
     "start_time": "2021-03-03T14:46:28.650417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### your code here\n",
    "for init_var in init_vars:\n",
    "    network = make_network( \n",
    "                input_size, hidden_layers_size, output_size, n_layers=4,\n",
    "                activation_class=ReLU)\n",
    "\n",
    "    initialize_network(network, init_var)\n",
    "\n",
    "    cb = Callback(network, X_train, y_train, X_test, y_test)    \n",
    "    res = minimize(\n",
    "        compute_loss_grad, get_weights(network),       \n",
    "        args=[network, X_train, y_train], \n",
    "        method=\"L-BFGS-B\",                \n",
    "        jac=True,\n",
    "        callback=cb.call)\n",
    "    accs_test_on_iterations.append(cb.test_acc)\n",
    "    accs_train_on_iterations.append(cb.train_acc)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:34.875348Z",
     "start_time": "2021-03-03T14:46:34.436663Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "init_vars_for_plot = [(x if isinstance(x, str) else fr\"$\\sigma = {x}$\") for x in init_vars]\n",
    "\n",
    "for idx, label in enumerate(init_vars_for_plot):\n",
    "    ax.plot(accs_test_on_iterations[idx], label=label)\n",
    "\n",
    "ax.set_title(\"Test quality for different initializations\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:37:15.087902Z",
     "start_time": "2021-03-03T14:37:15.065996Z"
    },
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как меняется скорость обучения в зависимости от выбранной инициализации?\n",
    "\n",
    "__Ответы:__\n",
    "\n",
    "Видно, что быстрее всех учится модель с инициализаицей Kaiming и Xavier. Если использовать нормальное распределение с $\\sigma = 0.001$, то модель вообще не может обучиться и очень быстро останавливается процесс минимизации. При нормальном распределении с $\\sigma = 0.01$ модель сходится, но ей для этого требуется больше чем удвоенное количество эпох, затраченных Kaiming и Xavier. При дальнейшем увеличении $\\sigma$ ($\\sigma = 0.1$) видно, что количество эпох необходимое для сходимости уменьшается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `Эксперименты c различными функциями активации (1 балл)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим теперь, с какой функцией активации нейронная сеть будет обучаться лучше.\n",
    "\n",
    "В этом пункте вам предлагается попробовать обучить несколько нейронных сетей с различными функциями активации.\n",
    "\n",
    "Для этого нам нужно реализовать еще 2 слоя: для функций активации `Tanh` и `Sigmoid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:34.891308Z",
     "start_time": "2021-03-03T14:46:34.878379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \"\"\"\n",
    "    tanh(y) = (e^y - e^(-y)) / (e^y + e^(-y))\n",
    "    Используйте функцию np.tanh для подсчета гиперболического тангенса.\n",
    "    Вы можете сами реализовать подсчет tanh, но тогда вам нужно устойчиво его вычислять.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params = [] # Tanh has no parameters\n",
    "        self.eval = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply elementwise Tanh to [batch, num_units] matrix\n",
    "        \"\"\"\n",
    "        self.output = np.tanh(input)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. Tanh input\n",
    "        grad_output shape: [batch, num_units]\n",
    "        output 1 shape: [batch, num_units]\n",
    "        output 2: []\n",
    "        \"\"\"\n",
    "        grad_x = grad_output * (1 - self.output ** 2)\n",
    "        return grad_x, []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Tanh()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:34.907337Z",
     "start_time": "2021-03-03T14:46:34.894300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "    \n",
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    sigmoid(y) = 1 / (1 + e^(-y))\n",
    "    Используйте функцию expit для подсчета сигмоиды.\n",
    "    Вы можете сами реализовать подсчет сигмоиды, но тогда вам нужно устойчиво ее вычислять.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params = [] # Sigmoid has no parameters\n",
    "        self.eval = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply elementwise Sigmoid to [batch, num_units] matrix\n",
    "        \"\"\"\n",
    "        self.output = expit(input)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of loss w.r.t. Sigmoid input\n",
    "        grad_output shape: [batch, num_units]\n",
    "        output 1 shape: [batch, num_units]\n",
    "        output 2: []\n",
    "        \"\"\"\n",
    "        ### your code here\n",
    "        grad_x = grad_output * ((1 - self.output) * self.output)\n",
    "        return grad_x, []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Sigmoid()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь попробуйте для каждой из 3 функций активации обучить нейронную сеть несколько раз. Число слоев зафиксируйте равным 3. В случае `Tanh` и `Sigmoid` используйте инициализацию `Xavier`, а в случае `ReLU` используйте инициализацию `Kaiming`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Заполните матрицы `accs_train` и `accs_test`. В позиции `[i, j]` должна стоять величина доли правильных ответов сети при $j$-м запуске (все запуски идентичны) с функцией активации $ReLU$ при $i = 0$, с функцией активации $Tanh$ при $i = 1$ и с функцией активации $Sigmoid$ при $i = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:34.922732Z",
     "start_time": "2021-03-03T14:46:34.910271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "act_func_vars = [ReLU, Tanh, Sigmoid]\n",
    "init_for_act_funcs = ['Kaiming', 'Xavier', 'Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:46:34.938935Z",
     "start_time": "2021-03-03T14:46:34.925724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accs_train = np.zeros((3, 5))\n",
    "accs_test = np.zeros((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:47:04.514986Z",
     "start_time": "2021-03-03T14:46:34.941104Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        network = make_network( \n",
    "                        input_size, hidden_layers_size, output_size, n_layers=3,\n",
    "                        activation_class=act_func_vars[i])\n",
    "\n",
    "        initialize_network(network, init_for_act_funcs[i])\n",
    "\n",
    "        res = minimize(\n",
    "            compute_loss_grad, get_weights(network),       \n",
    "            args=[network, X_train, y_train], \n",
    "            method=\"L-BFGS-B\",                \n",
    "            jac=True)\n",
    "        \n",
    "        set_weights(res['x'], network)\n",
    "\n",
    "        accs_train[i, j] = np.mean(predict(network, X_train) == y_train)\n",
    "        accs_test[i, j] = np.mean(predict(network, X_test) == y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_func_vars = ['ReLU', 'Tanh', 'Sigmoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Построим боксплоты полученного качества (горизонтальная линия в каждом столбце — среднее, прямоугольник показывает разброс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T14:47:04.783320Z",
     "start_time": "2021-03-03T14:47:04.517701Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=act_func_vars, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Activation function\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_train.T, labels=act_func_vars, showfliers=False)\n",
    "\n",
    "ax.set_title(\"Train quality in 5 runs\")\n",
    "ax.set_xlabel(\"Activation function\")\n",
    "ax.set_ylabel(\"Train accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дайте развёрнутый ответ на вопросы (в этой же ячейке):\n",
    "* Как отличаются качество на обучении и контроле и устойчивость процесса обучения при различных функциях активации?\n",
    "\n",
    "__Ответы:__\n",
    "\n",
    "1. На обучении  медиана зачений accuracy равна 1 для Tanh и ReLU, при этом можно заметить, что у Sigmoid медиана почти такая же ($\\approx 0.9993$), но при этом есть небольшая неустойчивость.\n",
    "2. По accuracy лучше всего себя показалa ReLU, разброс у всех примерно один и тот же"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\* Несколько фрагментов кода в задании написаны на основе материалов [курса по глубинному обучению на ФКН НИУ ВШЭ](://www.hse.ru/ba/ami/courses/205504078.html)https"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `Бонусная часть`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `Реализация метода оптимизации (1 балл)`\n",
    "\n",
    "Реализуйте сами метод оптимизации (аналог функции `minimize`) для рассмотренной выше архитектуры. В качестве метода оптимизации используйте SGD + momentum. Продемонстрируйте правильную работу метода оптимизации, сравните его работу с LBFGS-B. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(X_train, y_train, batch_size):\n",
    "    batches = []\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    idxs = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train[idxs[i:i + batch_size], :]\n",
    "        y_batch = y_train[idxs[i:i + batch_size]]\n",
    "        batches.append((X_batch, y_batch))\n",
    "    return batches\n",
    "\n",
    "def sgd_momentum(network, X_train, y_train, X_test, y_test,  batch_size, lr, alpha, epoch=100, verbose=False):\n",
    "    weights = get_weights(network)\n",
    "    v = 0\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for _ in range(epoch):\n",
    "        batches = make_batches(X_train, y_train, batch_size)\n",
    "        for X_batch, y_batch in batches:\n",
    "            _, grad = compute_loss_grad(weights, (network, X_batch, y_batch))\n",
    "            v = alpha * v + (1 - alpha) * grad\n",
    "            weights -= lr * v\n",
    "        for layer in network:\n",
    "            layer.eval = True\n",
    "        train_acc.append(np.mean(predict(network, X_train) == y_train))\n",
    "        test_acc.append(np.mean(predict(network, X_test) == y_test))\n",
    "        if verbose:\n",
    "            print(f\"Accuracy on train {train_acc[-1]:.4f} ||\",\n",
    "                   f\"test {test_acc[-1]:.4f}\")\n",
    "        for layer in network:\n",
    "            layer.eval = False\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = make_network(input_size, hidden_layers_size, output_size, n_layers=3,\n",
    "                        activation_class=ReLU)\n",
    "\n",
    "initialize_network(network, 'Kaiming')\n",
    "\n",
    "train_acc, test_acc = sgd_momentum(network, X_train, y_train, X_test, \n",
    "                                   y_test, batch_size=100, lr=0.05, alpha=0.5, epoch=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"709.51pt\" height=\"350.103594pt\" viewBox=\"0 0 709.51 350.103594\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-03-12T18:03:48.371339</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 350.103594 \nL 709.51 350.103594 \nL 709.51 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 47.105 308.369375 \nL 702.31 308.369375 \nL 702.31 21.789375 \nL 47.105 21.789375 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 76.887045 308.369375 \nL 76.887045 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #262626\" transform=\"translate(73.82853 325.742969)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 176.492549 308.369375 \nL 176.492549 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <g style=\"fill: #262626\" transform=\"translate(170.375517 325.742969)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-35\" d=\"M 266 1200 \nL 856 1250 \nQ 922 819 1161 601 \nQ 1400 384 1738 384 \nQ 2144 384 2425 690 \nQ 2706 997 2706 1503 \nQ 2706 1984 2436 2262 \nQ 2166 2541 1728 2541 \nQ 1456 2541 1237 2417 \nQ 1019 2294 894 2097 \nL 366 2166 \nL 809 4519 \nL 3088 4519 \nL 3088 3981 \nL 1259 3981 \nL 1013 2750 \nQ 1425 3038 1878 3038 \nQ 2478 3038 2890 2622 \nQ 3303 2206 3303 1553 \nQ 3303 931 2941 478 \nQ 2500 -78 1738 -78 \nQ 1113 -78 717 272 \nQ 322 622 266 1200 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-35\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 276.098052 308.369375 \nL 276.098052 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <g style=\"fill: #262626\" transform=\"translate(266.922505 325.742969)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 375.703555 308.369375 \nL 375.703555 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g style=\"fill: #262626\" transform=\"translate(366.528008 325.742969)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 475.309058 308.369375 \nL 475.309058 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <g style=\"fill: #262626\" transform=\"translate(466.133511 325.742969)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 574.914561 308.369375 \nL 574.914561 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g style=\"fill: #262626\" transform=\"translate(565.739015 325.742969)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <path d=\"M 674.520065 308.369375 \nL 674.520065 21.789375 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <g style=\"fill: #262626\" transform=\"translate(665.344518 325.742969)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-33\" d=\"M 269 1209 \nL 831 1284 \nQ 928 806 1161 595 \nQ 1394 384 1728 384 \nQ 2125 384 2398 659 \nQ 2672 934 2672 1341 \nQ 2672 1728 2419 1979 \nQ 2166 2231 1775 2231 \nQ 1616 2231 1378 2169 \nL 1441 2663 \nQ 1497 2656 1531 2656 \nQ 1891 2656 2178 2843 \nQ 2466 3031 2466 3422 \nQ 2466 3731 2256 3934 \nQ 2047 4138 1716 4138 \nQ 1388 4138 1169 3931 \nQ 950 3725 888 3313 \nL 325 3413 \nQ 428 3978 793 4289 \nQ 1159 4600 1703 4600 \nQ 2078 4600 2393 4439 \nQ 2709 4278 2876 4000 \nQ 3044 3722 3044 3409 \nQ 3044 3113 2884 2869 \nQ 2725 2625 2413 2481 \nQ 2819 2388 3044 2092 \nQ 3269 1797 3269 1353 \nQ 3269 753 2831 336 \nQ 2394 -81 1725 -81 \nQ 1122 -81 723 278 \nQ 325 638 269 1209 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-33\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epochs -->\n     <g style=\"fill: #262626\" transform=\"translate(354.695625 340.518594)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"ArialMT-45\" d=\"M 506 0 \nL 506 4581 \nL 3819 4581 \nL 3819 4041 \nL 1113 4041 \nL 1113 2638 \nL 3647 2638 \nL 3647 2100 \nL 1113 2100 \nL 1113 541 \nL 3925 541 \nL 3925 0 \nL 506 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-70\" d=\"M 422 -1272 \nL 422 3319 \nL 934 3319 \nL 934 2888 \nQ 1116 3141 1344 3267 \nQ 1572 3394 1897 3394 \nQ 2322 3394 2647 3175 \nQ 2972 2956 3137 2557 \nQ 3303 2159 3303 1684 \nQ 3303 1175 3120 767 \nQ 2938 359 2589 142 \nQ 2241 -75 1856 -75 \nQ 1575 -75 1351 44 \nQ 1128 163 984 344 \nL 984 -1272 \nL 422 -1272 \nz\nM 931 1641 \nQ 931 1000 1190 694 \nQ 1450 388 1819 388 \nQ 2194 388 2461 705 \nQ 2728 1022 2728 1688 \nQ 2728 2322 2467 2637 \nQ 2206 2953 1844 2953 \nQ 1484 2953 1207 2617 \nQ 931 2281 931 1641 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-6f\" d=\"M 213 1659 \nQ 213 2581 725 3025 \nQ 1153 3394 1769 3394 \nQ 2453 3394 2887 2945 \nQ 3322 2497 3322 1706 \nQ 3322 1066 3130 698 \nQ 2938 331 2570 128 \nQ 2203 -75 1769 -75 \nQ 1072 -75 642 372 \nQ 213 819 213 1659 \nz\nM 791 1659 \nQ 791 1022 1069 705 \nQ 1347 388 1769 388 \nQ 2188 388 2466 706 \nQ 2744 1025 2744 1678 \nQ 2744 2294 2464 2611 \nQ 2184 2928 1769 2928 \nQ 1347 2928 1069 2612 \nQ 791 2297 791 1659 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-63\" d=\"M 2588 1216 \nL 3141 1144 \nQ 3050 572 2676 248 \nQ 2303 -75 1759 -75 \nQ 1078 -75 664 370 \nQ 250 816 250 1647 \nQ 250 2184 428 2587 \nQ 606 2991 970 3192 \nQ 1334 3394 1763 3394 \nQ 2303 3394 2647 3120 \nQ 2991 2847 3088 2344 \nL 2541 2259 \nQ 2463 2594 2264 2762 \nQ 2066 2931 1784 2931 \nQ 1359 2931 1093 2626 \nQ 828 2322 828 1663 \nQ 828 994 1084 691 \nQ 1341 388 1753 388 \nQ 2084 388 2306 591 \nQ 2528 794 2588 1216 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-68\" d=\"M 422 0 \nL 422 4581 \nL 984 4581 \nL 984 2938 \nQ 1378 3394 1978 3394 \nQ 2347 3394 2619 3248 \nQ 2891 3103 3008 2847 \nQ 3125 2591 3125 2103 \nL 3125 0 \nL 2563 0 \nL 2563 2103 \nQ 2563 2525 2380 2717 \nQ 2197 2909 1863 2909 \nQ 1613 2909 1392 2779 \nQ 1172 2650 1078 2428 \nQ 984 2206 984 1816 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-73\" d=\"M 197 991 \nL 753 1078 \nQ 800 744 1014 566 \nQ 1228 388 1613 388 \nQ 2000 388 2187 545 \nQ 2375 703 2375 916 \nQ 2375 1106 2209 1216 \nQ 2094 1291 1634 1406 \nQ 1016 1563 777 1677 \nQ 538 1791 414 1992 \nQ 291 2194 291 2438 \nQ 291 2659 392 2848 \nQ 494 3038 669 3163 \nQ 800 3259 1026 3326 \nQ 1253 3394 1513 3394 \nQ 1903 3394 2198 3281 \nQ 2494 3169 2634 2976 \nQ 2775 2784 2828 2463 \nL 2278 2388 \nQ 2241 2644 2061 2787 \nQ 1881 2931 1553 2931 \nQ 1166 2931 1000 2803 \nQ 834 2675 834 2503 \nQ 834 2394 903 2306 \nQ 972 2216 1119 2156 \nQ 1203 2125 1616 2013 \nQ 2213 1853 2448 1751 \nQ 2684 1650 2818 1456 \nQ 2953 1263 2953 975 \nQ 2953 694 2789 445 \nQ 2625 197 2315 61 \nQ 2006 -75 1616 -75 \nQ 969 -75 630 194 \nQ 291 463 197 991 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-45\"/>\n      <use xlink:href=\"#ArialMT-70\" x=\"66.699219\"/>\n      <use xlink:href=\"#ArialMT-6f\" x=\"122.314453\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"177.929688\"/>\n      <use xlink:href=\"#ArialMT-68\" x=\"227.929688\"/>\n      <use xlink:href=\"#ArialMT-73\" x=\"283.544922\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <path d=\"M 47.105 295.004978 \nL 702.31 295.004978 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 298.941775)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <path d=\"M 47.105 262.481323 \nL 702.31 262.481323 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.3 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 266.41812)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <path d=\"M 47.105 229.957668 \nL 702.31 229.957668 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 233.894465)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <path d=\"M 47.105 197.434013 \nL 702.31 197.434013 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 201.37081)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <path d=\"M 47.105 164.910358 \nL 702.31 164.910358 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 168.847155)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <path d=\"M 47.105 132.386703 \nL 702.31 132.386703 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.7 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 136.3235)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-37\" d=\"M 303 3981 \nL 303 4522 \nL 3269 4522 \nL 3269 4084 \nQ 2831 3619 2401 2847 \nQ 1972 2075 1738 1259 \nQ 1569 684 1522 0 \nL 944 0 \nQ 953 541 1156 1306 \nQ 1359 2072 1739 2783 \nQ 2119 3494 2547 3981 \nL 303 3981 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <path d=\"M 47.105 99.863048 \nL 702.31 99.863048 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 103.799845)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-38\" d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 47.105 67.339394 \nL 702.31 67.339394 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.9 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 71.27619)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-39\" d=\"M 350 1059 \nL 891 1109 \nQ 959 728 1153 556 \nQ 1347 384 1650 384 \nQ 1909 384 2104 503 \nQ 2300 622 2425 820 \nQ 2550 1019 2634 1356 \nQ 2719 1694 2719 2044 \nQ 2719 2081 2716 2156 \nQ 2547 1888 2255 1720 \nQ 1963 1553 1622 1553 \nQ 1053 1553 659 1965 \nQ 266 2378 266 3053 \nQ 266 3750 677 4175 \nQ 1088 4600 1706 4600 \nQ 2153 4600 2523 4359 \nQ 2894 4119 3086 3673 \nQ 3278 3228 3278 2384 \nQ 3278 1506 3087 986 \nQ 2897 466 2520 194 \nQ 2144 -78 1638 -78 \nQ 1100 -78 759 220 \nQ 419 519 350 1059 \nz\nM 2653 3081 \nQ 2653 3566 2395 3850 \nQ 2138 4134 1775 4134 \nQ 1400 4134 1122 3828 \nQ 844 3522 844 3034 \nQ 844 2597 1108 2323 \nQ 1372 2050 1759 2050 \nQ 2150 2050 2401 2323 \nQ 2653 2597 2653 3081 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_16\">\n      <path d=\"M 47.105 34.815739 \nL 702.31 34.815739 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 38.752536)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- Accuracy -->\n     <g style=\"fill: #262626\" transform=\"translate(15.789375 189.7525)rotate(-90)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"ArialMT-41\" d=\"M -9 0 \nL 1750 4581 \nL 2403 4581 \nL 4278 0 \nL 3588 0 \nL 3053 1388 \nL 1138 1388 \nL 634 0 \nL -9 0 \nz\nM 1313 1881 \nL 2866 1881 \nL 2388 3150 \nQ 2169 3728 2063 4100 \nQ 1975 3659 1816 3225 \nL 1313 1881 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-75\" d=\"M 2597 0 \nL 2597 488 \nQ 2209 -75 1544 -75 \nQ 1250 -75 995 37 \nQ 741 150 617 320 \nQ 494 491 444 738 \nQ 409 903 409 1263 \nL 409 3319 \nL 972 3319 \nL 972 1478 \nQ 972 1038 1006 884 \nQ 1059 663 1231 536 \nQ 1403 409 1656 409 \nQ 1909 409 2131 539 \nQ 2353 669 2445 892 \nQ 2538 1116 2538 1541 \nL 2538 3319 \nL 3100 3319 \nL 3100 0 \nL 2597 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-72\" d=\"M 416 0 \nL 416 3319 \nL 922 3319 \nL 922 2816 \nQ 1116 3169 1280 3281 \nQ 1444 3394 1641 3394 \nQ 1925 3394 2219 3213 \nL 2025 2691 \nQ 1819 2813 1613 2813 \nQ 1428 2813 1281 2702 \nQ 1134 2591 1072 2394 \nQ 978 2094 978 1738 \nL 978 0 \nL 416 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-61\" d=\"M 2588 409 \nQ 2275 144 1986 34 \nQ 1697 -75 1366 -75 \nQ 819 -75 525 192 \nQ 231 459 231 875 \nQ 231 1119 342 1320 \nQ 453 1522 633 1644 \nQ 813 1766 1038 1828 \nQ 1203 1872 1538 1913 \nQ 2219 1994 2541 2106 \nQ 2544 2222 2544 2253 \nQ 2544 2597 2384 2738 \nQ 2169 2928 1744 2928 \nQ 1347 2928 1158 2789 \nQ 969 2650 878 2297 \nL 328 2372 \nQ 403 2725 575 2942 \nQ 747 3159 1072 3276 \nQ 1397 3394 1825 3394 \nQ 2250 3394 2515 3294 \nQ 2781 3194 2906 3042 \nQ 3031 2891 3081 2659 \nQ 3109 2516 3109 2141 \nL 3109 1391 \nQ 3109 606 3145 398 \nQ 3181 191 3288 0 \nL 2700 0 \nQ 2613 175 2588 409 \nz\nM 2541 1666 \nQ 2234 1541 1622 1453 \nQ 1275 1403 1131 1340 \nQ 988 1278 909 1158 \nQ 831 1038 831 891 \nQ 831 666 1001 516 \nQ 1172 366 1500 366 \nQ 1825 366 2078 508 \nQ 2331 650 2450 897 \nQ 2541 1088 2541 1459 \nL 2541 1666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-79\" d=\"M 397 -1278 \nL 334 -750 \nQ 519 -800 656 -800 \nQ 844 -800 956 -737 \nQ 1069 -675 1141 -563 \nQ 1194 -478 1313 -144 \nQ 1328 -97 1363 -6 \nL 103 3319 \nL 709 3319 \nL 1400 1397 \nQ 1534 1031 1641 628 \nQ 1738 1016 1872 1384 \nL 2581 3319 \nL 3144 3319 \nL 1881 -56 \nQ 1678 -603 1566 -809 \nQ 1416 -1088 1222 -1217 \nQ 1028 -1347 759 -1347 \nQ 597 -1347 397 -1278 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-41\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"66.699219\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"116.699219\"/>\n      <use xlink:href=\"#ArialMT-75\" x=\"166.699219\"/>\n      <use xlink:href=\"#ArialMT-72\" x=\"222.314453\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"255.615234\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"311.230469\"/>\n      <use xlink:href=\"#ArialMT-79\" x=\"361.230469\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 76.887045 295.343011 \nL 78.879156 238.360216 \nL 84.855486 135.259988 \nL 86.847596 105.802781 \nL 90.831816 80.933171 \nL 92.823926 76.828478 \nL 94.816036 71.516522 \nL 96.808146 61.616969 \nL 98.800256 59.685349 \nL 100.792366 54.131941 \nL 102.784476 52.683225 \nL 104.776586 56.305013 \nL 106.768696 51.475963 \nL 108.760806 48.095627 \nL 110.752917 47.854175 \nL 112.745027 48.578532 \nL 114.737137 46.40546 \nL 116.729247 47.37127 \nL 118.721357 48.578532 \nL 120.713467 44.47384 \nL 122.705577 50.751605 \nL 124.697687 45.681102 \nL 126.689797 44.956745 \nL 128.681907 41.576409 \nL 130.674017 41.817862 \nL 132.666127 39.886242 \nL 134.658237 40.369147 \nL 136.650347 39.403337 \nL 138.642457 40.852052 \nL 140.634567 40.127694 \nL 142.626678 45.43965 \nL 144.618788 38.920432 \nL 146.610898 39.403337 \nL 148.603008 38.196074 \nL 150.595118 38.437526 \nL 152.587228 39.161884 \nL 154.579338 38.437526 \nL 156.571448 37.230264 \nL 158.563558 37.713169 \nL 160.555668 38.437526 \nL 162.547778 37.230264 \nL 164.539888 37.230264 \nL 166.531998 36.505906 \nL 168.524108 36.264454 \nL 170.516218 38.196074 \nL 172.508329 36.264454 \nL 174.500439 36.264454 \nL 176.492549 36.505906 \nL 178.484659 36.023001 \nL 180.476769 35.781549 \nL 182.468879 36.264454 \nL 184.460989 36.505906 \nL 186.453099 35.781549 \nL 188.445209 35.540096 \nL 190.437319 36.505906 \nL 192.429429 35.540096 \nL 194.421539 35.298644 \nL 196.413649 35.781549 \nL 198.405759 35.781549 \nL 200.397869 35.540096 \nL 202.389979 35.540096 \nL 204.38209 36.023001 \nL 206.3742 35.298644 \nL 208.36631 35.057191 \nL 210.35842 35.057191 \nL 212.35053 34.815739 \nL 214.34264 35.057191 \nL 218.32686 35.057191 \nL 220.31897 34.815739 \nL 672.527955 34.815739 \nL 672.527955 34.815739 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 76.887045 291.391238 \nL 78.879156 230.680416 \nL 80.871266 197.434013 \nL 82.863376 162.019367 \nL 84.855486 128.772964 \nL 86.847596 105.645032 \nL 88.839706 95.526561 \nL 90.831816 81.071603 \nL 92.823926 78.90336 \nL 94.816036 73.121377 \nL 98.800256 65.893898 \nL 100.792366 63.725654 \nL 102.784476 63.002906 \nL 104.776586 63.002906 \nL 106.768696 60.834663 \nL 108.760806 55.775427 \nL 110.752917 60.111915 \nL 112.745027 56.498175 \nL 114.737137 56.498175 \nL 116.729247 55.775427 \nL 118.721357 56.498175 \nL 120.713467 52.161688 \nL 122.705577 57.220923 \nL 124.697687 53.607184 \nL 126.689797 54.329932 \nL 128.681907 51.43894 \nL 130.674017 53.607184 \nL 132.666127 51.43894 \nL 134.658237 52.161688 \nL 136.650347 49.993444 \nL 138.642457 49.270696 \nL 140.634567 55.775427 \nL 142.626678 50.716192 \nL 144.618788 47.825201 \nL 146.610898 48.547948 \nL 148.603008 48.547948 \nL 150.595118 49.270696 \nL 152.587228 49.270696 \nL 154.579338 50.716192 \nL 156.571448 48.547948 \nL 158.563558 48.547948 \nL 160.555668 49.270696 \nL 162.547778 47.825201 \nL 166.531998 49.270696 \nL 168.524108 49.270696 \nL 170.516218 50.716192 \nL 172.508329 47.825201 \nL 174.500439 47.825201 \nL 176.492549 49.993444 \nL 178.484659 48.547948 \nL 180.476769 50.716192 \nL 182.468879 49.993444 \nL 184.460989 45.656957 \nL 186.453099 48.547948 \nL 188.445209 47.825201 \nL 190.437319 48.547948 \nL 192.429429 47.102453 \nL 194.421539 48.547948 \nL 196.413649 47.102453 \nL 198.405759 47.825201 \nL 200.397869 47.102453 \nL 204.38209 47.102453 \nL 206.3742 48.547948 \nL 208.36631 45.656957 \nL 210.35842 47.825201 \nL 212.35053 46.379705 \nL 222.31108 46.379705 \nL 224.30319 47.102453 \nL 226.2953 46.379705 \nL 228.28741 47.102453 \nL 230.27952 46.379705 \nL 232.27163 47.102453 \nL 234.26374 47.102453 \nL 236.255851 46.379705 \nL 238.247961 47.102453 \nL 240.240071 45.656957 \nL 242.232181 46.379705 \nL 250.200621 46.379705 \nL 252.192731 45.656957 \nL 254.184841 46.379705 \nL 256.176951 45.656957 \nL 258.169061 46.379705 \nL 262.153281 46.379705 \nL 264.145391 47.102453 \nL 266.137502 44.211461 \nL 268.129612 46.379705 \nL 270.121722 44.934209 \nL 272.113832 46.379705 \nL 274.105942 45.656957 \nL 276.098052 44.211461 \nL 278.090162 44.934209 \nL 280.082272 47.102453 \nL 282.074382 45.656957 \nL 284.066492 46.379705 \nL 286.058602 45.656957 \nL 288.050712 45.656957 \nL 290.042822 46.379705 \nL 292.034932 46.379705 \nL 294.027042 44.934209 \nL 296.019152 46.379705 \nL 298.011263 45.656957 \nL 300.003373 45.656957 \nL 301.995483 46.379705 \nL 303.987593 46.379705 \nL 305.979703 45.656957 \nL 307.971813 47.102453 \nL 311.956033 45.656957 \nL 313.948143 45.656957 \nL 315.940253 46.379705 \nL 319.924473 44.934209 \nL 323.908693 46.379705 \nL 325.900803 46.379705 \nL 329.885024 44.934209 \nL 333.869244 44.934209 \nL 335.861354 44.211461 \nL 337.853464 45.656957 \nL 343.829794 45.656957 \nL 345.821904 46.379705 \nL 347.814014 44.934209 \nL 349.806124 44.934209 \nL 351.798234 45.656957 \nL 353.790344 44.211461 \nL 355.782454 45.656957 \nL 359.766675 44.211461 \nL 361.758785 44.934209 \nL 363.750895 44.934209 \nL 365.743005 45.656957 \nL 367.735115 45.656957 \nL 369.727225 44.934209 \nL 373.711445 46.379705 \nL 375.703555 44.934209 \nL 377.695665 44.934209 \nL 379.687775 45.656957 \nL 381.679885 44.934209 \nL 383.671995 45.656957 \nL 385.664105 45.656957 \nL 389.648325 44.211461 \nL 391.640436 46.379705 \nL 393.632546 45.656957 \nL 395.624656 44.211461 \nL 397.616766 45.656957 \nL 399.608876 44.934209 \nL 401.600986 45.656957 \nL 403.593096 44.934209 \nL 409.569426 44.934209 \nL 411.561536 46.379705 \nL 413.553646 45.656957 \nL 415.545756 44.211461 \nL 417.537866 45.656957 \nL 419.529976 44.934209 \nL 421.522087 46.379705 \nL 423.514197 44.934209 \nL 425.506307 45.656957 \nL 427.498417 45.656957 \nL 429.490527 44.211461 \nL 431.482637 45.656957 \nL 433.474747 44.211461 \nL 435.466857 44.934209 \nL 437.458967 44.934209 \nL 439.451077 45.656957 \nL 441.443187 44.211461 \nL 443.435297 44.934209 \nL 449.411627 44.934209 \nL 451.403737 45.656957 \nL 455.387958 44.211461 \nL 457.380068 46.379705 \nL 459.372178 44.211461 \nL 463.356398 45.656957 \nL 465.348508 45.656957 \nL 467.340618 44.934209 \nL 471.324838 44.934209 \nL 473.316948 45.656957 \nL 475.309058 45.656957 \nL 479.293278 44.211461 \nL 481.285388 44.934209 \nL 483.277498 44.934209 \nL 485.269609 44.211461 \nL 489.253829 45.656957 \nL 491.245939 45.656957 \nL 493.238049 44.211461 \nL 495.230159 44.934209 \nL 497.222269 44.211461 \nL 499.214379 44.934209 \nL 503.198599 44.934209 \nL 505.190709 45.656957 \nL 507.182819 44.934209 \nL 515.15126 44.934209 \nL 517.14337 44.211461 \nL 519.13548 44.934209 \nL 521.12759 44.934209 \nL 523.1197 44.211461 \nL 525.11181 44.934209 \nL 541.04869 44.934209 \nL 543.0408 44.211461 \nL 545.03291 44.934209 \nL 547.025021 44.934209 \nL 549.017131 44.211461 \nL 551.009241 45.656957 \nL 553.001351 44.934209 \nL 554.993461 44.934209 \nL 556.985571 44.211461 \nL 558.977681 44.934209 \nL 560.969791 44.934209 \nL 562.961901 44.211461 \nL 564.954011 44.211461 \nL 566.946121 44.934209 \nL 568.938231 44.211461 \nL 570.930341 44.934209 \nL 572.922451 44.934209 \nL 574.914561 44.211461 \nL 576.906671 44.934209 \nL 596.827772 44.934209 \nL 598.819882 44.211461 \nL 600.811992 44.934209 \nL 602.804102 44.211461 \nL 604.796212 44.934209 \nL 622.725203 44.934209 \nL 624.717313 44.211461 \nL 626.709423 44.934209 \nL 632.685753 44.934209 \nL 634.677863 44.211461 \nL 636.669973 44.934209 \nL 648.622634 44.934209 \nL 650.614744 44.211461 \nL 652.606854 44.934209 \nL 658.583184 44.934209 \nL 660.575294 44.211461 \nL 662.567404 44.211461 \nL 664.559514 44.934209 \nL 670.535844 44.934209 \nL 672.527955 44.211461 \nL 672.527955 44.211461 \n\" clip-path=\"url(#p52cde391a5)\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 47.105 308.369375 \nL 47.105 21.789375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 702.31 308.369375 \nL 702.31 21.789375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 47.105 308.369375 \nL 702.31 308.369375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 47.105 21.789375 \nL 702.31 21.789375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_19\">\n    <!-- SGD + momentum -->\n    <g style=\"fill: #262626\" transform=\"translate(324.860625 15.789375)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"ArialMT-53\" d=\"M 288 1472 \nL 859 1522 \nQ 900 1178 1048 958 \nQ 1197 738 1509 602 \nQ 1822 466 2213 466 \nQ 2559 466 2825 569 \nQ 3091 672 3220 851 \nQ 3350 1031 3350 1244 \nQ 3350 1459 3225 1620 \nQ 3100 1781 2813 1891 \nQ 2628 1963 1997 2114 \nQ 1366 2266 1113 2400 \nQ 784 2572 623 2826 \nQ 463 3081 463 3397 \nQ 463 3744 659 4045 \nQ 856 4347 1234 4503 \nQ 1613 4659 2075 4659 \nQ 2584 4659 2973 4495 \nQ 3363 4331 3572 4012 \nQ 3781 3694 3797 3291 \nL 3216 3247 \nQ 3169 3681 2898 3903 \nQ 2628 4125 2100 4125 \nQ 1550 4125 1298 3923 \nQ 1047 3722 1047 3438 \nQ 1047 3191 1225 3031 \nQ 1400 2872 2139 2705 \nQ 2878 2538 3153 2413 \nQ 3553 2228 3743 1945 \nQ 3934 1663 3934 1294 \nQ 3934 928 3725 604 \nQ 3516 281 3123 101 \nQ 2731 -78 2241 -78 \nQ 1619 -78 1198 103 \nQ 778 284 539 648 \nQ 300 1013 288 1472 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-47\" d=\"M 2638 1797 \nL 2638 2334 \nL 4578 2338 \nL 4578 638 \nQ 4131 281 3656 101 \nQ 3181 -78 2681 -78 \nQ 2006 -78 1454 211 \nQ 903 500 622 1047 \nQ 341 1594 341 2269 \nQ 341 2938 620 3517 \nQ 900 4097 1425 4378 \nQ 1950 4659 2634 4659 \nQ 3131 4659 3532 4498 \nQ 3934 4338 4162 4050 \nQ 4391 3763 4509 3300 \nL 3963 3150 \nQ 3859 3500 3706 3700 \nQ 3553 3900 3268 4020 \nQ 2984 4141 2638 4141 \nQ 2222 4141 1919 4014 \nQ 1616 3888 1430 3681 \nQ 1244 3475 1141 3228 \nQ 966 2803 966 2306 \nQ 966 1694 1177 1281 \nQ 1388 869 1791 669 \nQ 2194 469 2647 469 \nQ 3041 469 3416 620 \nQ 3791 772 3984 944 \nL 3984 1797 \nL 2638 1797 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-44\" d=\"M 494 0 \nL 494 4581 \nL 2072 4581 \nQ 2606 4581 2888 4516 \nQ 3281 4425 3559 4188 \nQ 3922 3881 4101 3404 \nQ 4281 2928 4281 2316 \nQ 4281 1794 4159 1391 \nQ 4038 988 3847 723 \nQ 3656 459 3429 307 \nQ 3203 156 2883 78 \nQ 2563 0 2147 0 \nL 494 0 \nz\nM 1100 541 \nL 2078 541 \nQ 2531 541 2789 625 \nQ 3047 709 3200 863 \nQ 3416 1078 3536 1442 \nQ 3656 1806 3656 2325 \nQ 3656 3044 3420 3430 \nQ 3184 3816 2847 3947 \nQ 2603 4041 2063 4041 \nL 1100 4041 \nL 1100 541 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-2b\" d=\"M 1603 741 \nL 1603 1997 \nL 356 1997 \nL 356 2522 \nL 1603 2522 \nL 1603 3769 \nL 2134 3769 \nL 2134 2522 \nL 3381 2522 \nL 3381 1997 \nL 2134 1997 \nL 2134 741 \nL 1603 741 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6d\" d=\"M 422 0 \nL 422 3319 \nL 925 3319 \nL 925 2853 \nQ 1081 3097 1340 3245 \nQ 1600 3394 1931 3394 \nQ 2300 3394 2536 3241 \nQ 2772 3088 2869 2813 \nQ 3263 3394 3894 3394 \nQ 4388 3394 4653 3120 \nQ 4919 2847 4919 2278 \nL 4919 0 \nL 4359 0 \nL 4359 2091 \nQ 4359 2428 4304 2576 \nQ 4250 2725 4106 2815 \nQ 3963 2906 3769 2906 \nQ 3419 2906 3187 2673 \nQ 2956 2441 2956 1928 \nL 2956 0 \nL 2394 0 \nL 2394 2156 \nQ 2394 2531 2256 2718 \nQ 2119 2906 1806 2906 \nQ 1569 2906 1367 2781 \nQ 1166 2656 1075 2415 \nQ 984 2175 984 1722 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-65\" d=\"M 2694 1069 \nL 3275 997 \nQ 3138 488 2766 206 \nQ 2394 -75 1816 -75 \nQ 1088 -75 661 373 \nQ 234 822 234 1631 \nQ 234 2469 665 2931 \nQ 1097 3394 1784 3394 \nQ 2450 3394 2872 2941 \nQ 3294 2488 3294 1666 \nQ 3294 1616 3291 1516 \nL 816 1516 \nQ 847 969 1125 678 \nQ 1403 388 1819 388 \nQ 2128 388 2347 550 \nQ 2566 713 2694 1069 \nz\nM 847 1978 \nL 2700 1978 \nQ 2663 2397 2488 2606 \nQ 2219 2931 1791 2931 \nQ 1403 2931 1139 2672 \nQ 875 2413 847 1978 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6e\" d=\"M 422 0 \nL 422 3319 \nL 928 3319 \nL 928 2847 \nQ 1294 3394 1984 3394 \nQ 2284 3394 2536 3286 \nQ 2788 3178 2913 3003 \nQ 3038 2828 3088 2588 \nQ 3119 2431 3119 2041 \nL 3119 0 \nL 2556 0 \nL 2556 2019 \nQ 2556 2363 2490 2533 \nQ 2425 2703 2258 2804 \nQ 2091 2906 1866 2906 \nQ 1506 2906 1245 2678 \nQ 984 2450 984 1813 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-74\" d=\"M 1650 503 \nL 1731 6 \nQ 1494 -44 1306 -44 \nQ 1000 -44 831 53 \nQ 663 150 594 308 \nQ 525 466 525 972 \nL 525 2881 \nL 113 2881 \nL 113 3319 \nL 525 3319 \nL 525 4141 \nL 1084 4478 \nL 1084 3319 \nL 1650 3319 \nL 1650 2881 \nL 1084 2881 \nL 1084 941 \nQ 1084 700 1114 631 \nQ 1144 563 1211 522 \nQ 1278 481 1403 481 \nQ 1497 481 1650 503 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#ArialMT-53\"/>\n     <use xlink:href=\"#ArialMT-47\" x=\"66.699219\"/>\n     <use xlink:href=\"#ArialMT-44\" x=\"144.482422\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"216.699219\"/>\n     <use xlink:href=\"#ArialMT-2b\" x=\"244.482422\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"302.880859\"/>\n     <use xlink:href=\"#ArialMT-6d\" x=\"330.664062\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"413.964844\"/>\n     <use xlink:href=\"#ArialMT-6d\" x=\"469.580078\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"552.880859\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"608.496094\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"664.111328\"/>\n     <use xlink:href=\"#ArialMT-75\" x=\"691.894531\"/>\n     <use xlink:href=\"#ArialMT-6d\" x=\"747.509766\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 617.840312 302.869375 \nL 694.61 302.869375 \nQ 696.81 302.869375 696.81 300.669375 \nL 696.81 270.649687 \nQ 696.81 268.449687 694.61 268.449687 \nL 617.840312 268.449687 \nQ 615.640312 268.449687 615.640312 270.649687 \nL 615.640312 300.669375 \nQ 615.640312 302.869375 617.840312 302.869375 \nz\n\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 620.040312 276.873281 \nL 631.040312 276.873281 \nL 642.040312 276.873281 \n\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- train acc -->\n     <g style=\"fill: #262626\" transform=\"translate(650.840312 280.723281)scale(0.11 -0.11)\">\n      <defs>\n       <path id=\"ArialMT-69\" d=\"M 425 3934 \nL 425 4581 \nL 988 4581 \nL 988 3934 \nL 425 3934 \nz\nM 425 0 \nL 425 3319 \nL 988 3319 \nL 988 0 \nL 425 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-74\"/>\n      <use xlink:href=\"#ArialMT-72\" x=\"27.783203\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"61.083984\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"116.699219\"/>\n      <use xlink:href=\"#ArialMT-6e\" x=\"138.916016\"/>\n      <use xlink:href=\"#ArialMT-20\" x=\"194.53125\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"222.314453\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"277.929688\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"327.929688\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 620.040312 292.433125 \nL 631.040312 292.433125 \nL 642.040312 292.433125 \n\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n    </g>\n    <g id=\"text_21\">\n     <!-- test acc -->\n     <g style=\"fill: #262626\" transform=\"translate(650.840312 296.283125)scale(0.11 -0.11)\">\n      <use xlink:href=\"#ArialMT-74\"/>\n      <use xlink:href=\"#ArialMT-65\" x=\"27.783203\"/>\n      <use xlink:href=\"#ArialMT-73\" x=\"83.398438\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"133.398438\"/>\n      <use xlink:href=\"#ArialMT-20\" x=\"161.181641\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"188.964844\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"244.580078\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"294.580078\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p52cde391a5\">\n   <rect x=\"47.105\" y=\"21.789375\" width=\"655.205\" height=\"286.58\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.plot(train_acc, label=\"train acc\")\n",
    "ax.plot(test_acc, label=\"test acc\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title('SGD + momentum')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что accuracy на трейне стремится к нулю, а значит алгоритм сходится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc 1.0\n",
      "test acc 0.9711111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"train acc\", train_acc[-1])\n",
    "print(\"test acc\", test_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc 1.0\n",
      "test acc 0.9488888888888889\n"
     ]
    }
   ],
   "source": [
    "network = make_network( \n",
    "        input_size, hidden_layers_size, output_size, n_layers=3,\n",
    "        activation_class=ReLU)\n",
    "\n",
    "initialize_network(network, 'Kaiming')\n",
    "\n",
    "res = minimize(\n",
    "    compute_loss_grad, get_weights(network),       \n",
    "    args=[network, X_train, y_train], \n",
    "    method=\"L-BFGS-B\",                \n",
    "    jac=True)\n",
    "\n",
    "set_weights(res['x'], network)\n",
    "\n",
    "acc_train = np.mean(predict(network, X_train) == y_train)\n",
    "acc_test = np.mean(predict(network, X_test) == y_test)\n",
    "print(\"train acc\", acc_train)\n",
    "print(\"test acc\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: SGD + momentum работает сильно лучше чем L-BFGS-B(на тесте 0.971 против 0.948)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `Dropout (1 балл)`\n",
    "\n",
    "Реализуйте слой Dropout. Сравните обучение сети из большого числа слоёв при использовании Dropout и без его использования (предварительно подберите адекватный параметр $p$). Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOut:\n",
    "    def __init__(self, prob):\n",
    "        self.params = [] # drop-out has no parameters\n",
    "        self.prob = prob # probability of success\n",
    "        self.eval = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        if not self.eval:\n",
    "            y = np.random.binomial(1, self.prob, input.shape)\n",
    "            self.mask = y / self.prob\n",
    "            return input * self.mask \n",
    "        return input\n",
    "    def backward(self, grad_output):\n",
    "\n",
    "        ### your code here\n",
    "        grad_x = grad_output * self.mask\n",
    "        return grad_x, []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'DropOut({self.prob})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def __init__(self, network, X_train, y_train, X_test, y_test, print=False):\n",
    "        self.network = network\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.print = print\n",
    "        self.train_acc = []\n",
    "        self.test_acc = []\n",
    "        \n",
    "    def call(self, weights):\n",
    "        \"\"\"\n",
    "        Computes quality on train and test set with given weights\n",
    "        and saves to self.train_acc and self.test_acc.\n",
    "        If self.print is True, also prints these 2 values\n",
    "        \"\"\"\n",
    "        set_weights(weights, self.network)\n",
    "        for layer in self.network:\n",
    "            layer.eval = True\n",
    "        self.test_acc.append(np.mean(\n",
    "            predict(self.network, self.X_test) == self.y_test))\n",
    "        self.train_acc.append(np.mean(\n",
    "            predict(self.network, self.X_train) == self.y_train))\n",
    "        for layer in self.network:\n",
    "            layer.eval = False\n",
    "\n",
    "        if self.print:\n",
    "            print(f\"Accuracy on train {self.train_acc[-1]:.4f} ||\",\n",
    "                   f\"test {self.test_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "       0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "       0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "       0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "       0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "       0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "       0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "       0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "       0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "       0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "       0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "       0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "       0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "       0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "       0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "       0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "       0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "       0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "       0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "       0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "       0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "       0.9921875, 1.       ])"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = np.linspace(0, 1, 129)[1:]\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = []\n",
    "accs_test = []\n",
    "for prob in probs:\n",
    "    network = make_network( \n",
    "        input_size, hidden_layers_size,\n",
    "        output_size, n_layers=6, activation_class=ReLU)\n",
    "\n",
    "    cb = Callback(network, X_train, y_train, X_test, y_test, print=False)\n",
    "    network_with_dropout = []\n",
    "    for layer in network:\n",
    "        network_with_dropout.append(layer)\n",
    "        if isinstance(layer, ReLU):\n",
    "            network_with_dropout.append(DropOut(prob))\n",
    "    initialize_network(network_with_dropout, 'Kaiming')\n",
    "            \n",
    "    res = minimize(\n",
    "        compute_loss_grad, get_weights(network_with_dropout),       \n",
    "        args=[network_with_dropout, X_train, y_train], \n",
    "        method=\"L-BFGS-B\",                \n",
    "        jac=True,\n",
    "        callback=cb.call)\n",
    "    \n",
    "    set_weights(res['x'], network_with_dropout)\n",
    "\n",
    "    accs_train.append(cb.train_acc[-1])\n",
    "    accs_test.append(cb.test_acc[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"709.51pt\" height=\"350.296719pt\" viewBox=\"0 0 709.51 350.296719\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-03-12T20:02:16.165811</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 350.296719 \nL 709.51 350.296719 \nL 709.51 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 47.105 308.421875 \nL 702.31 308.421875 \nL 702.31 21.935625 \nL 47.105 21.935625 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 72.19696 308.421875 \nL 72.19696 21.935625 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(64.55196 325.795469)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 192.263159 308.421875 \nL 192.263159 21.935625 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(184.618159 325.795469)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 312.329358 308.421875 \nL 312.329358 21.935625 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(304.684358 325.795469)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 432.395557 308.421875 \nL 432.395557 21.935625 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(424.750557 325.795469)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 552.461756 308.421875 \nL 552.461756 21.935625 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(544.816756 325.795469)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-38\" d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 672.527955 308.421875 \nL 672.527955 21.935625 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(664.882955 325.795469)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- probability -->\n     <g style=\"fill: #262626\" transform=\"translate(347.360625 340.571094)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"ArialMT-70\" d=\"M 422 -1272 \nL 422 3319 \nL 934 3319 \nL 934 2888 \nQ 1116 3141 1344 3267 \nQ 1572 3394 1897 3394 \nQ 2322 3394 2647 3175 \nQ 2972 2956 3137 2557 \nQ 3303 2159 3303 1684 \nQ 3303 1175 3120 767 \nQ 2938 359 2589 142 \nQ 2241 -75 1856 -75 \nQ 1575 -75 1351 44 \nQ 1128 163 984 344 \nL 984 -1272 \nL 422 -1272 \nz\nM 931 1641 \nQ 931 1000 1190 694 \nQ 1450 388 1819 388 \nQ 2194 388 2461 705 \nQ 2728 1022 2728 1688 \nQ 2728 2322 2467 2637 \nQ 2206 2953 1844 2953 \nQ 1484 2953 1207 2617 \nQ 931 2281 931 1641 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-72\" d=\"M 416 0 \nL 416 3319 \nL 922 3319 \nL 922 2816 \nQ 1116 3169 1280 3281 \nQ 1444 3394 1641 3394 \nQ 1925 3394 2219 3213 \nL 2025 2691 \nQ 1819 2813 1613 2813 \nQ 1428 2813 1281 2702 \nQ 1134 2591 1072 2394 \nQ 978 2094 978 1738 \nL 978 0 \nL 416 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-6f\" d=\"M 213 1659 \nQ 213 2581 725 3025 \nQ 1153 3394 1769 3394 \nQ 2453 3394 2887 2945 \nQ 3322 2497 3322 1706 \nQ 3322 1066 3130 698 \nQ 2938 331 2570 128 \nQ 2203 -75 1769 -75 \nQ 1072 -75 642 372 \nQ 213 819 213 1659 \nz\nM 791 1659 \nQ 791 1022 1069 705 \nQ 1347 388 1769 388 \nQ 2188 388 2466 706 \nQ 2744 1025 2744 1678 \nQ 2744 2294 2464 2611 \nQ 2184 2928 1769 2928 \nQ 1347 2928 1069 2612 \nQ 791 2297 791 1659 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-62\" d=\"M 941 0 \nL 419 0 \nL 419 4581 \nL 981 4581 \nL 981 2947 \nQ 1338 3394 1891 3394 \nQ 2197 3394 2470 3270 \nQ 2744 3147 2920 2923 \nQ 3097 2700 3197 2384 \nQ 3297 2069 3297 1709 \nQ 3297 856 2875 390 \nQ 2453 -75 1863 -75 \nQ 1275 -75 941 416 \nL 941 0 \nz\nM 934 1684 \nQ 934 1088 1097 822 \nQ 1363 388 1816 388 \nQ 2184 388 2453 708 \nQ 2722 1028 2722 1663 \nQ 2722 2313 2464 2622 \nQ 2206 2931 1841 2931 \nQ 1472 2931 1203 2611 \nQ 934 2291 934 1684 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-61\" d=\"M 2588 409 \nQ 2275 144 1986 34 \nQ 1697 -75 1366 -75 \nQ 819 -75 525 192 \nQ 231 459 231 875 \nQ 231 1119 342 1320 \nQ 453 1522 633 1644 \nQ 813 1766 1038 1828 \nQ 1203 1872 1538 1913 \nQ 2219 1994 2541 2106 \nQ 2544 2222 2544 2253 \nQ 2544 2597 2384 2738 \nQ 2169 2928 1744 2928 \nQ 1347 2928 1158 2789 \nQ 969 2650 878 2297 \nL 328 2372 \nQ 403 2725 575 2942 \nQ 747 3159 1072 3276 \nQ 1397 3394 1825 3394 \nQ 2250 3394 2515 3294 \nQ 2781 3194 2906 3042 \nQ 3031 2891 3081 2659 \nQ 3109 2516 3109 2141 \nL 3109 1391 \nQ 3109 606 3145 398 \nQ 3181 191 3288 0 \nL 2700 0 \nQ 2613 175 2588 409 \nz\nM 2541 1666 \nQ 2234 1541 1622 1453 \nQ 1275 1403 1131 1340 \nQ 988 1278 909 1158 \nQ 831 1038 831 891 \nQ 831 666 1001 516 \nQ 1172 366 1500 366 \nQ 1825 366 2078 508 \nQ 2331 650 2450 897 \nQ 2541 1088 2541 1459 \nL 2541 1666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-69\" d=\"M 425 3934 \nL 425 4581 \nL 988 4581 \nL 988 3934 \nL 425 3934 \nz\nM 425 0 \nL 425 3319 \nL 988 3319 \nL 988 0 \nL 425 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-6c\" d=\"M 409 0 \nL 409 4581 \nL 972 4581 \nL 972 0 \nL 409 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-74\" d=\"M 1650 503 \nL 1731 6 \nQ 1494 -44 1306 -44 \nQ 1000 -44 831 53 \nQ 663 150 594 308 \nQ 525 466 525 972 \nL 525 2881 \nL 113 2881 \nL 113 3319 \nL 525 3319 \nL 525 4141 \nL 1084 4478 \nL 1084 3319 \nL 1650 3319 \nL 1650 2881 \nL 1084 2881 \nL 1084 941 \nQ 1084 700 1114 631 \nQ 1144 563 1211 522 \nQ 1278 481 1403 481 \nQ 1497 481 1650 503 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-79\" d=\"M 397 -1278 \nL 334 -750 \nQ 519 -800 656 -800 \nQ 844 -800 956 -737 \nQ 1069 -675 1141 -563 \nQ 1194 -478 1313 -144 \nQ 1328 -97 1363 -6 \nL 103 3319 \nL 709 3319 \nL 1400 1397 \nQ 1534 1031 1641 628 \nQ 1738 1016 1872 1384 \nL 2581 3319 \nL 3144 3319 \nL 1881 -56 \nQ 1678 -603 1566 -809 \nQ 1416 -1088 1222 -1217 \nQ 1028 -1347 759 -1347 \nQ 597 -1347 397 -1278 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-70\"/>\n      <use xlink:href=\"#ArialMT-72\" x=\"55.615234\"/>\n      <use xlink:href=\"#ArialMT-6f\" x=\"88.916016\"/>\n      <use xlink:href=\"#ArialMT-62\" x=\"144.53125\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"200.146484\"/>\n      <use xlink:href=\"#ArialMT-62\" x=\"255.761719\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"311.376953\"/>\n      <use xlink:href=\"#ArialMT-6c\" x=\"333.59375\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"355.810547\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"378.027344\"/>\n      <use xlink:href=\"#ArialMT-79\" x=\"405.810547\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 47.105 259.839417 \nL 702.31 259.839417 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 263.776213)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 47.105 203.618994 \nL 702.31 203.618994 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 207.555791)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 47.105 147.398572 \nL 702.31 147.398572 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 151.335369)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 47.105 91.17815 \nL 702.31 91.17815 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 95.114946)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 47.105 34.957727 \nL 702.31 34.957727 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 38.894524)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- Accuracy -->\n     <g style=\"fill: #262626\" transform=\"translate(15.789375 189.851875)rotate(-90)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"ArialMT-41\" d=\"M -9 0 \nL 1750 4581 \nL 2403 4581 \nL 4278 0 \nL 3588 0 \nL 3053 1388 \nL 1138 1388 \nL 634 0 \nL -9 0 \nz\nM 1313 1881 \nL 2866 1881 \nL 2388 3150 \nQ 2169 3728 2063 4100 \nQ 1975 3659 1816 3225 \nL 1313 1881 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-63\" d=\"M 2588 1216 \nL 3141 1144 \nQ 3050 572 2676 248 \nQ 2303 -75 1759 -75 \nQ 1078 -75 664 370 \nQ 250 816 250 1647 \nQ 250 2184 428 2587 \nQ 606 2991 970 3192 \nQ 1334 3394 1763 3394 \nQ 2303 3394 2647 3120 \nQ 2991 2847 3088 2344 \nL 2541 2259 \nQ 2463 2594 2264 2762 \nQ 2066 2931 1784 2931 \nQ 1359 2931 1093 2626 \nQ 828 2322 828 1663 \nQ 828 994 1084 691 \nQ 1341 388 1753 388 \nQ 2084 388 2306 591 \nQ 2528 794 2588 1216 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-75\" d=\"M 2597 0 \nL 2597 488 \nQ 2209 -75 1544 -75 \nQ 1250 -75 995 37 \nQ 741 150 617 320 \nQ 494 491 444 738 \nQ 409 903 409 1263 \nL 409 3319 \nL 972 3319 \nL 972 1478 \nQ 972 1038 1006 884 \nQ 1059 663 1231 536 \nQ 1403 409 1656 409 \nQ 1909 409 2131 539 \nQ 2353 669 2445 892 \nQ 2538 1116 2538 1541 \nL 2538 3319 \nL 3100 3319 \nL 3100 0 \nL 2597 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-41\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"66.699219\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"116.699219\"/>\n      <use xlink:href=\"#ArialMT-75\" x=\"166.699219\"/>\n      <use xlink:href=\"#ArialMT-72\" x=\"222.314453\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"255.615234\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"311.230469\"/>\n      <use xlink:href=\"#ArialMT-79\" x=\"361.230469\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 76.887045 286.634896 \nL 81.577131 286.217521 \nL 86.267217 267.64433 \nL 90.957303 295.399773 \nL 95.647389 284.339333 \nL 100.337475 292.895522 \nL 105.027561 283.087208 \nL 109.717647 292.686835 \nL 114.407733 272.235456 \nL 119.097819 289.139147 \nL 123.787904 283.504583 \nL 128.47799 271.192019 \nL 133.168076 285.800146 \nL 137.858162 289.973897 \nL 142.548248 286.008834 \nL 147.238334 285.174083 \nL 151.92842 290.808647 \nL 156.618506 287.678334 \nL 161.308592 285.382771 \nL 165.998678 280.165583 \nL 170.688763 286.426209 \nL 175.378849 278.70477 \nL 180.068935 284.130646 \nL 184.759021 286.843584 \nL 189.449107 287.052271 \nL 194.139193 286.217521 \nL 198.829279 286.008834 \nL 203.519365 287.678334 \nL 208.209451 286.426209 \nL 212.899537 287.887021 \nL 217.589622 286.634896 \nL 222.279708 286.217521 \nL 226.969794 286.426209 \nL 231.65988 286.426209 \nL 241.040052 286.008834 \nL 245.730138 286.217521 \nL 250.420224 285.800146 \nL 255.11031 286.634896 \nL 259.800395 286.426209 \nL 264.490481 284.339333 \nL 269.180567 286.426209 \nL 273.870653 286.634896 \nL 278.560739 289.139147 \nL 283.250825 285.800146 \nL 287.940911 286.217521 \nL 297.321083 284.965396 \nL 302.011169 287.887021 \nL 306.701254 287.052271 \nL 311.39134 286.008834 \nL 316.081426 285.382771 \nL 320.771512 286.426209 \nL 325.461598 286.217521 \nL 330.151684 286.217521 \nL 334.84177 287.469646 \nL 339.531856 283.087208 \nL 344.221942 286.217521 \nL 348.912028 285.800146 \nL 353.602113 286.843584 \nL 358.292199 287.052271 \nL 362.982285 286.426209 \nL 367.672371 284.756708 \nL 372.362457 286.426209 \nL 377.052543 286.217521 \nL 381.742629 274.948394 \nL 386.432715 283.921958 \nL 391.122801 283.921958 \nL 395.812887 285.382771 \nL 400.502972 286.008834 \nL 405.193058 286.008834 \nL 409.883144 275.783144 \nL 414.57323 282.669833 \nL 419.263316 283.713271 \nL 423.953402 286.008834 \nL 428.643488 281.000333 \nL 433.333574 286.843584 \nL 438.02366 281.835083 \nL 442.713746 252.618828 \nL 447.403831 275.157082 \nL 452.093917 256.166516 \nL 456.784003 282.669833 \nL 461.474089 266.80958 \nL 466.164175 271.609394 \nL 470.854261 274.531019 \nL 475.544347 224.863385 \nL 480.234433 235.715137 \nL 484.924519 262.63583 \nL 489.614605 250.323265 \nL 494.30469 260.548954 \nL 498.994776 215.681134 \nL 503.684862 234.045637 \nL 508.374948 178.117377 \nL 513.065034 264.722705 \nL 517.75512 186.256191 \nL 522.445206 261.801079 \nL 527.135292 161.422374 \nL 531.825378 213.176883 \nL 536.515463 158.918124 \nL 541.205549 143.266559 \nL 545.895635 207.124945 \nL 555.275807 104.241989 \nL 559.965893 150.570622 \nL 564.655979 233.836949 \nL 569.346065 131.371369 \nL 574.036151 132.832182 \nL 578.726237 140.344933 \nL 583.416322 152.240123 \nL 588.106408 124.275993 \nL 592.796494 91.51205 \nL 597.48658 65.634795 \nL 602.176666 146.605559 \nL 606.866752 99.024801 \nL 611.556838 140.344933 \nL 616.246924 77.11261 \nL 620.93701 75.651797 \nL 625.627096 44.557354 \nL 630.317181 67.095608 \nL 635.007267 57.078606 \nL 639.697353 88.590424 \nL 644.387439 88.799112 \nL 649.077525 48.31373 \nL 658.457697 51.65273 \nL 663.147783 57.078606 \nL 667.837869 58.330731 \nL 672.527955 34.957727 \nL 672.527955 34.957727 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 76.887045 292.946999 \nL 81.577131 284.2016 \nL 86.267217 274.206858 \nL 90.957303 294.196341 \nL 95.647389 282.952257 \nL 100.337475 292.946999 \nL 105.027561 283.576928 \nL 109.717647 284.826271 \nL 114.407733 277.330215 \nL 119.097819 287.324956 \nL 123.787904 291.072984 \nL 128.47799 281.702914 \nL 133.168076 285.450942 \nL 137.858162 286.075614 \nL 142.548248 290.448313 \nL 147.238334 289.823642 \nL 151.92842 291.697656 \nL 156.618506 287.324956 \nL 161.308592 293.57167 \nL 165.998678 282.327585 \nL 170.688763 291.697656 \nL 175.378849 287.949628 \nL 180.068935 287.949628 \nL 184.759021 286.700285 \nL 189.449107 292.946999 \nL 194.139193 291.697656 \nL 198.829279 289.823642 \nL 203.519365 294.821013 \nL 208.209451 292.322327 \nL 212.899537 285.450942 \nL 217.589622 292.946999 \nL 222.279708 288.574299 \nL 226.969794 286.700285 \nL 231.65988 293.57167 \nL 236.349966 293.57167 \nL 241.040052 287.949628 \nL 245.730138 293.57167 \nL 250.420224 293.57167 \nL 255.11031 286.700285 \nL 259.800395 292.322327 \nL 264.490481 292.946999 \nL 273.870653 291.697656 \nL 278.560739 282.952257 \nL 283.250825 287.949628 \nL 287.940911 294.196341 \nL 292.630997 289.823642 \nL 297.321083 290.448313 \nL 302.011169 284.2016 \nL 306.701254 292.322327 \nL 311.39134 292.322327 \nL 316.081426 289.823642 \nL 320.771512 291.072984 \nL 325.461598 287.949628 \nL 330.151684 291.697656 \nL 334.84177 288.574299 \nL 339.531856 283.576928 \nL 344.221942 291.697656 \nL 348.912028 291.697656 \nL 353.602113 289.19897 \nL 358.292199 291.697656 \nL 362.982285 290.448313 \nL 367.672371 291.072984 \nL 372.362457 285.450942 \nL 377.052543 291.697656 \nL 381.742629 276.705543 \nL 386.432715 290.448313 \nL 395.812887 290.448313 \nL 400.502972 287.949628 \nL 405.193058 289.823642 \nL 409.883144 281.702914 \nL 414.57323 279.8289 \nL 419.263316 288.574299 \nL 423.953402 286.700285 \nL 428.643488 286.075614 \nL 433.333574 286.075614 \nL 438.02366 276.080872 \nL 442.713746 259.214745 \nL 447.403831 284.2016 \nL 452.093917 264.836787 \nL 456.784003 289.823642 \nL 461.474089 269.209487 \nL 466.164175 275.4562 \nL 470.854261 279.8289 \nL 475.544347 236.101905 \nL 480.234433 241.723947 \nL 484.924519 274.831529 \nL 489.614605 247.970661 \nL 494.30469 257.965402 \nL 498.994776 223.608478 \nL 503.684862 242.348618 \nL 508.374948 191.125567 \nL 513.065034 264.212116 \nL 517.75512 196.747609 \nL 522.445206 262.338102 \nL 527.135292 168.012727 \nL 531.825378 229.23052 \nL 536.515463 176.133454 \nL 541.205549 158.642656 \nL 545.895635 221.109792 \nL 550.585721 165.514041 \nL 555.275807 102.422234 \nL 559.965893 163.015356 \nL 564.655979 234.852562 \nL 569.346065 141.151858 \nL 574.036151 139.277844 \nL 583.416322 164.264699 \nL 588.106408 134.905145 \nL 592.796494 99.923549 \nL 597.48658 79.309394 \nL 602.176666 149.272586 \nL 606.866752 107.419605 \nL 611.556838 149.272586 \nL 616.246924 86.80545 \nL 620.93701 84.306765 \nL 625.627096 53.697868 \nL 630.317181 70.563995 \nL 635.007267 62.443267 \nL 639.697353 100.54822 \nL 644.387439 108.668948 \nL 649.077525 59.31991 \nL 653.767611 53.697868 \nL 658.457697 49.94984 \nL 663.147783 73.687352 \nL 667.837869 76.186037 \nL 672.527955 43.703126 \nL 672.527955 43.703126 \n\" clip-path=\"url(#p0838f13415)\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 47.105 308.421875 \nL 47.105 21.935625 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 702.31 308.421875 \nL 702.31 21.935625 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 47.105 308.421875 \nL 702.31 308.421875 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 47.105 21.935625 \nL 702.31 21.935625 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_14\">\n    <!-- Deep neural network with different probabilities for drop-out -->\n    <g style=\"fill: #262626\" transform=\"translate(217.40625 15.935625)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"ArialMT-44\" d=\"M 494 0 \nL 494 4581 \nL 2072 4581 \nQ 2606 4581 2888 4516 \nQ 3281 4425 3559 4188 \nQ 3922 3881 4101 3404 \nQ 4281 2928 4281 2316 \nQ 4281 1794 4159 1391 \nQ 4038 988 3847 723 \nQ 3656 459 3429 307 \nQ 3203 156 2883 78 \nQ 2563 0 2147 0 \nL 494 0 \nz\nM 1100 541 \nL 2078 541 \nQ 2531 541 2789 625 \nQ 3047 709 3200 863 \nQ 3416 1078 3536 1442 \nQ 3656 1806 3656 2325 \nQ 3656 3044 3420 3430 \nQ 3184 3816 2847 3947 \nQ 2603 4041 2063 4041 \nL 1100 4041 \nL 1100 541 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-65\" d=\"M 2694 1069 \nL 3275 997 \nQ 3138 488 2766 206 \nQ 2394 -75 1816 -75 \nQ 1088 -75 661 373 \nQ 234 822 234 1631 \nQ 234 2469 665 2931 \nQ 1097 3394 1784 3394 \nQ 2450 3394 2872 2941 \nQ 3294 2488 3294 1666 \nQ 3294 1616 3291 1516 \nL 816 1516 \nQ 847 969 1125 678 \nQ 1403 388 1819 388 \nQ 2128 388 2347 550 \nQ 2566 713 2694 1069 \nz\nM 847 1978 \nL 2700 1978 \nQ 2663 2397 2488 2606 \nQ 2219 2931 1791 2931 \nQ 1403 2931 1139 2672 \nQ 875 2413 847 1978 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6e\" d=\"M 422 0 \nL 422 3319 \nL 928 3319 \nL 928 2847 \nQ 1294 3394 1984 3394 \nQ 2284 3394 2536 3286 \nQ 2788 3178 2913 3003 \nQ 3038 2828 3088 2588 \nQ 3119 2431 3119 2041 \nL 3119 0 \nL 2556 0 \nL 2556 2019 \nQ 2556 2363 2490 2533 \nQ 2425 2703 2258 2804 \nQ 2091 2906 1866 2906 \nQ 1506 2906 1245 2678 \nQ 984 2450 984 1813 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-77\" d=\"M 1034 0 \nL 19 3319 \nL 600 3319 \nL 1128 1403 \nL 1325 691 \nQ 1338 744 1497 1375 \nL 2025 3319 \nL 2603 3319 \nL 3100 1394 \nL 3266 759 \nL 3456 1400 \nL 4025 3319 \nL 4572 3319 \nL 3534 0 \nL 2950 0 \nL 2422 1988 \nL 2294 2553 \nL 1622 0 \nL 1034 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6b\" d=\"M 425 0 \nL 425 4581 \nL 988 4581 \nL 988 1969 \nL 2319 3319 \nL 3047 3319 \nL 1778 2088 \nL 3175 0 \nL 2481 0 \nL 1384 1697 \nL 988 1316 \nL 988 0 \nL 425 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-68\" d=\"M 422 0 \nL 422 4581 \nL 984 4581 \nL 984 2938 \nQ 1378 3394 1978 3394 \nQ 2347 3394 2619 3248 \nQ 2891 3103 3008 2847 \nQ 3125 2591 3125 2103 \nL 3125 0 \nL 2563 0 \nL 2563 2103 \nQ 2563 2525 2380 2717 \nQ 2197 2909 1863 2909 \nQ 1613 2909 1392 2779 \nQ 1172 2650 1078 2428 \nQ 984 2206 984 1816 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-64\" d=\"M 2575 0 \nL 2575 419 \nQ 2259 -75 1647 -75 \nQ 1250 -75 917 144 \nQ 584 363 401 755 \nQ 219 1147 219 1656 \nQ 219 2153 384 2558 \nQ 550 2963 881 3178 \nQ 1213 3394 1622 3394 \nQ 1922 3394 2156 3267 \nQ 2391 3141 2538 2938 \nL 2538 4581 \nL 3097 4581 \nL 3097 0 \nL 2575 0 \nz\nM 797 1656 \nQ 797 1019 1065 703 \nQ 1334 388 1700 388 \nQ 2069 388 2326 689 \nQ 2584 991 2584 1609 \nQ 2584 2291 2321 2609 \nQ 2059 2928 1675 2928 \nQ 1300 2928 1048 2622 \nQ 797 2316 797 1656 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-66\" d=\"M 556 0 \nL 556 2881 \nL 59 2881 \nL 59 3319 \nL 556 3319 \nL 556 3672 \nQ 556 4006 616 4169 \nQ 697 4388 901 4523 \nQ 1106 4659 1475 4659 \nQ 1713 4659 2000 4603 \nL 1916 4113 \nQ 1741 4144 1584 4144 \nQ 1328 4144 1222 4034 \nQ 1116 3925 1116 3625 \nL 1116 3319 \nL 1763 3319 \nL 1763 2881 \nL 1116 2881 \nL 1116 0 \nL 556 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-73\" d=\"M 197 991 \nL 753 1078 \nQ 800 744 1014 566 \nQ 1228 388 1613 388 \nQ 2000 388 2187 545 \nQ 2375 703 2375 916 \nQ 2375 1106 2209 1216 \nQ 2094 1291 1634 1406 \nQ 1016 1563 777 1677 \nQ 538 1791 414 1992 \nQ 291 2194 291 2438 \nQ 291 2659 392 2848 \nQ 494 3038 669 3163 \nQ 800 3259 1026 3326 \nQ 1253 3394 1513 3394 \nQ 1903 3394 2198 3281 \nQ 2494 3169 2634 2976 \nQ 2775 2784 2828 2463 \nL 2278 2388 \nQ 2241 2644 2061 2787 \nQ 1881 2931 1553 2931 \nQ 1166 2931 1000 2803 \nQ 834 2675 834 2503 \nQ 834 2394 903 2306 \nQ 972 2216 1119 2156 \nQ 1203 2125 1616 2013 \nQ 2213 1853 2448 1751 \nQ 2684 1650 2818 1456 \nQ 2953 1263 2953 975 \nQ 2953 694 2789 445 \nQ 2625 197 2315 61 \nQ 2006 -75 1616 -75 \nQ 969 -75 630 194 \nQ 291 463 197 991 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-2d\" d=\"M 203 1375 \nL 203 1941 \nL 1931 1941 \nL 1931 1375 \nL 203 1375 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#ArialMT-44\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"72.216797\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"127.832031\"/>\n     <use xlink:href=\"#ArialMT-70\" x=\"183.447266\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"239.0625\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"266.845703\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"322.460938\"/>\n     <use xlink:href=\"#ArialMT-75\" x=\"378.076172\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"433.691406\"/>\n     <use xlink:href=\"#ArialMT-61\" x=\"466.992188\"/>\n     <use xlink:href=\"#ArialMT-6c\" x=\"522.607422\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"544.824219\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"572.607422\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"628.222656\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"683.837891\"/>\n     <use xlink:href=\"#ArialMT-77\" x=\"711.621094\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"783.837891\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"839.453125\"/>\n     <use xlink:href=\"#ArialMT-6b\" x=\"872.753906\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"922.753906\"/>\n     <use xlink:href=\"#ArialMT-77\" x=\"950.537109\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"1022.753906\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"1044.970703\"/>\n     <use xlink:href=\"#ArialMT-68\" x=\"1072.753906\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"1128.369141\"/>\n     <use xlink:href=\"#ArialMT-64\" x=\"1156.152344\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"1211.767578\"/>\n     <use xlink:href=\"#ArialMT-66\" x=\"1233.984375\"/>\n     <use xlink:href=\"#ArialMT-66\" x=\"1260.017578\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"1287.800781\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"1343.416016\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"1376.716797\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"1432.332031\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"1487.947266\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"1515.730469\"/>\n     <use xlink:href=\"#ArialMT-70\" x=\"1543.513672\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"1599.128906\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"1632.429688\"/>\n     <use xlink:href=\"#ArialMT-62\" x=\"1688.044922\"/>\n     <use xlink:href=\"#ArialMT-61\" x=\"1743.660156\"/>\n     <use xlink:href=\"#ArialMT-62\" x=\"1799.275391\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"1854.890625\"/>\n     <use xlink:href=\"#ArialMT-6c\" x=\"1877.107422\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"1899.324219\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"1921.541016\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"1949.324219\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"1971.541016\"/>\n     <use xlink:href=\"#ArialMT-73\" x=\"2027.15625\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"2077.15625\"/>\n     <use xlink:href=\"#ArialMT-66\" x=\"2104.939453\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"2132.722656\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"2188.337891\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"2221.638672\"/>\n     <use xlink:href=\"#ArialMT-64\" x=\"2249.421875\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"2305.037109\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"2338.337891\"/>\n     <use xlink:href=\"#ArialMT-70\" x=\"2393.953125\"/>\n     <use xlink:href=\"#ArialMT-2d\" x=\"2449.568359\"/>\n     <use xlink:href=\"#ArialMT-6f\" x=\"2482.869141\"/>\n     <use xlink:href=\"#ArialMT-75\" x=\"2538.484375\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"2594.099609\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 54.805 61.855312 \nL 114.651875 61.855312 \nQ 116.851875 61.855312 116.851875 59.655312 \nL 116.851875 29.635625 \nQ 116.851875 27.435625 114.651875 27.435625 \nL 54.805 27.435625 \nQ 52.605 27.435625 52.605 29.635625 \nL 52.605 59.655312 \nQ 52.605 61.855312 54.805 61.855312 \nz\n\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_14\">\n     <path d=\"M 57.005 35.859219 \nL 68.005 35.859219 \nL 79.005 35.859219 \n\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- Train -->\n     <g style=\"fill: #262626\" transform=\"translate(87.805 39.709219)scale(0.11 -0.11)\">\n      <defs>\n       <path id=\"ArialMT-54\" d=\"M 1659 0 \nL 1659 4041 \nL 150 4041 \nL 150 4581 \nL 3781 4581 \nL 3781 4041 \nL 2266 4041 \nL 2266 0 \nL 1659 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-54\"/>\n      <use xlink:href=\"#ArialMT-72\" x=\"57.333984\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"90.634766\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"146.25\"/>\n      <use xlink:href=\"#ArialMT-6e\" x=\"168.466797\"/>\n     </g>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 57.005 51.419063 \nL 68.005 51.419063 \nL 79.005 51.419063 \n\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- Test -->\n     <g style=\"fill: #262626\" transform=\"translate(87.805 55.269063)scale(0.11 -0.11)\">\n      <use xlink:href=\"#ArialMT-54\"/>\n      <use xlink:href=\"#ArialMT-65\" x=\"49.958984\"/>\n      <use xlink:href=\"#ArialMT-73\" x=\"105.574219\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"155.574219\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0838f13415\">\n   <rect x=\"47.105\" y=\"21.935625\" width=\"655.205\" height=\"286.48625\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.plot(probs, accs_train, label='Train')\n",
    "ax.plot(probs, accs_test, label='Test')\n",
    "\n",
    "ax.set_title(\"Deep neural network with different probabilities for drop-out\")\n",
    "ax.set_xlabel(\"probability\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "0.9765625\n"
     ]
    }
   ],
   "source": [
    "i = np.argmax(accs_test[:-1])\n",
    "print(i)\n",
    "print(probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = []\n",
    "accs_test = []\n",
    "network = make_network( \n",
    "        input_size, hidden_layers_size,\n",
    "        output_size, n_layers=6, activation_class=ReLU)\n",
    "\n",
    "cb = Callback(network, X_train, y_train, X_test, y_test, print=False)\n",
    "network_with_dropout = []\n",
    "for layer in network:\n",
    "    network_with_dropout.append(layer)\n",
    "    if isinstance(layer, ReLU):\n",
    "        network_with_dropout.append(DropOut(probs[i]))\n",
    "initialize_network(network_with_dropout, 'Kaiming')\n",
    "        \n",
    "res = minimize(\n",
    "    compute_loss_grad, get_weights(network_with_dropout),       \n",
    "    args=[network_with_dropout, X_train, y_train], \n",
    "    method=\"L-BFGS-B\",                \n",
    "    jac=True,\n",
    "    callback=cb.call)\n",
    "\n",
    "accs_train.append(cb.train_acc[-1])\n",
    "accs_test.append(cb.test_acc[-1])\n",
    "\n",
    "network = make_network( \n",
    "        input_size, hidden_layers_size,\n",
    "        output_size, n_layers=6, activation_class=ReLU)\n",
    "\n",
    "cb = Callback(network, X_train, y_train, X_test, y_test, print=False)\n",
    "initialize_network(network, 'Kaiming')\n",
    "        \n",
    "res = minimize(\n",
    "    compute_loss_grad, get_weights(network),       \n",
    "    args=[network, X_train, y_train], \n",
    "    method=\"L-BFGS-B\",                \n",
    "    jac=True,\n",
    "    callback=cb.call)\n",
    "accs_train.append(cb.train_acc[-1])\n",
    "accs_test.append(cb.test_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc train with dropout 0.9628804751299184 | acc test with dropout 0.9333333333333333\n",
      "acc train without dropout 1.0 | acc test without dropout 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc train with dropout {accs_train[0]} |\",\n",
    "      f\"acc test with dropout {accs_test[0]}\")\n",
    "print(f\"acc train without dropout {accs_train[1]} |\",\n",
    "      f\"acc test without dropout {accs_test[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что DropOut в нашем случае ничего не дал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### `BatchNormalization (1 балл)`\n",
    "\n",
    "Реализуйте слой `BatchNormalization`. Сравните обучение сети из большого числа слоёв при использовании `BatchNormalization` и без его использования. Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Spring.2018/www/slides/lec8.stochastic_gradient.pdf - формулы брал отсюда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1):\n",
    "        self.eval = False\n",
    "        self.gamma = np.ones(num_features)\n",
    "        self.beta = np.zeros(num_features)\n",
    "        self.params = [self.gamma, self.beta] \n",
    "        self.e_ = 0\n",
    "        self.var_ = 0\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        if not self.eval:\n",
    "            self.input = input\n",
    "            self.e = np.mean(input, axis=0)\n",
    "            self.var = np.var(input, axis=0)\n",
    "            self.e_ = self.momentum * self.e_ + (1 - self.momentum) * self.e\n",
    "            self.var_ = (\n",
    "                self.momentum * self.var_ + (1 - self.momentum) * self.var)\n",
    "            self.input_norm = (input - self.e) / np.sqrt(self.var + self.eps)\n",
    "            output = self.input_norm * self.gamma + self.beta\n",
    "            self.batch_size = X.shape[0]\n",
    "\n",
    "            return output\n",
    "        \n",
    "        input_norm = (input - self.e_) / np.sqrt(self.var_ + self.eps)\n",
    "        return input_norm * self.gamma + self.beta\n",
    "            \n",
    "    def backward(self, grad_output):\n",
    "        \n",
    "        grad_beta = np.sum(grad_output, axis=0)\n",
    "        grad_gamma = np.sum(grad_output * self.input_norm, axis=0)\n",
    "        \n",
    "        grad_input_norm = grad_output * self.gamma # b_ x n_out\n",
    "\n",
    "        grad_var = np.sum(grad_input_norm * (self.input - self.e), axis=0) \\\n",
    "            * (-1/2) * ((self.var + self.eps) ** (-3 / 2))\n",
    "\n",
    "        grad_e = np.sum(grad_input_norm * (-1 / np.sqrt(self.var \\\n",
    "            + self.eps)), axis=0) + grad_var / self.batch_size * np.sum(-2 * \\\n",
    "                (self.input - self.e), axis=0)\n",
    "\n",
    "        grad_x = grad_input_norm / np.sqrt(self.var + self.eps) + \\\n",
    "            grad_var * 2 * (self.input - self.e) / self.batch_size + \\\n",
    "            grad_e / self.batch_size\n",
    "        \n",
    "        return grad_x, np.r_[grad_beta, grad_gamma]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'BatchNormalization()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def __init__(self, network, X_train, y_train, X_test, y_test, print=False):\n",
    "        self.network = network\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.print = print\n",
    "        self.train_acc = []\n",
    "        self.test_acc = []\n",
    "        \n",
    "    def call(self, weights):\n",
    "        \"\"\"\n",
    "        Computes quality on train and test set with given weights\n",
    "        and saves to self.train_acc and self.test_acc.\n",
    "        If self.print is True, also prints these 2 values\n",
    "        \"\"\"\n",
    "        set_weights(weights, self.network)\n",
    "        for layer in self.network:\n",
    "            layer.eval = True\n",
    "        self.test_acc.append(np.mean(\n",
    "            predict(self.network, self.X_test) == self.y_test))\n",
    "        self.train_acc.append(np.mean(\n",
    "            predict(self.network, self.X_train) == self.y_train))\n",
    "        for layer in self.network:\n",
    "            layer.eval = False\n",
    "\n",
    "        if self.print:\n",
    "            print(f\"Accuracy on train {self.train_acc[-1]:.4f} ||\",\n",
    "                   f\"test {self.test_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_test = np.zeros((2, 5))\n",
    "accs_train = np.zeros((2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "        network = make_network( \n",
    "        input_size, hidden_layers_size,\n",
    "        output_size, n_layers=5, activation_class=ReLU)\n",
    "\n",
    "        network_batch_normalization = []\n",
    "        for j in range(len(network)):\n",
    "                network_batch_normalization.append(network[j])\n",
    "                if isinstance(network[j], ReLU):\n",
    "                        network_batch_normalization.append(BatchNormalization(\n",
    "                network[j - 1].weights.shape[1]))\n",
    "\n",
    "        initialize_network(network_batch_normalization, 'Kaiming')\n",
    "\n",
    "        train_acc, test_acc = sgd_momentum(network_batch_normalization, X_train, y_train, X_test, y_test, batch_size=300, lr=0.05, alpha=0.5, epoch=300, verbose=False)\n",
    "\n",
    "        accs_test[0, i] = test_acc[-1]\n",
    "        accs_train[0, i] = train_acc[-1]\n",
    "    \n",
    "\n",
    "for i in range(5):\n",
    "        network = make_network( \n",
    "                input_size, hidden_layers_size,\n",
    "                output_size, n_layers=4, activation_class=ReLU)\n",
    "\n",
    "        initialize_network(network, 'Kaiming')\n",
    "                \n",
    "        train_acc, test_acc = sgd_momentum(network, X_train, y_train, X_test, \n",
    "                                        y_test, batch_size=300, lr=0.05, alpha=0.5, epoch=300)\n",
    "        accs_test[1, i] = test_acc[-1]\n",
    "        accs_train[1, i] = train_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"709.447187pt\" height=\"350.056719pt\" viewBox=\"0 0 709.447187 350.056719\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-03-13T02:28:30.273992</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 350.056719 \nL 709.447187 350.056719 \nL 709.447187 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 59.339063 308.3225 \nL 702.247187 308.3225 \nL 702.247187 21.789375 \nL 59.339063 21.789375 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 220.066094 308.3225 \nL 220.066094 21.789375 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- batch norm -->\n      <g style=\"fill: #262626\" transform=\"translate(192.554922 325.696094)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-62\" d=\"M 941 0 \nL 419 0 \nL 419 4581 \nL 981 4581 \nL 981 2947 \nQ 1338 3394 1891 3394 \nQ 2197 3394 2470 3270 \nQ 2744 3147 2920 2923 \nQ 3097 2700 3197 2384 \nQ 3297 2069 3297 1709 \nQ 3297 856 2875 390 \nQ 2453 -75 1863 -75 \nQ 1275 -75 941 416 \nL 941 0 \nz\nM 934 1684 \nQ 934 1088 1097 822 \nQ 1363 388 1816 388 \nQ 2184 388 2453 708 \nQ 2722 1028 2722 1663 \nQ 2722 2313 2464 2622 \nQ 2206 2931 1841 2931 \nQ 1472 2931 1203 2611 \nQ 934 2291 934 1684 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-61\" d=\"M 2588 409 \nQ 2275 144 1986 34 \nQ 1697 -75 1366 -75 \nQ 819 -75 525 192 \nQ 231 459 231 875 \nQ 231 1119 342 1320 \nQ 453 1522 633 1644 \nQ 813 1766 1038 1828 \nQ 1203 1872 1538 1913 \nQ 2219 1994 2541 2106 \nQ 2544 2222 2544 2253 \nQ 2544 2597 2384 2738 \nQ 2169 2928 1744 2928 \nQ 1347 2928 1158 2789 \nQ 969 2650 878 2297 \nL 328 2372 \nQ 403 2725 575 2942 \nQ 747 3159 1072 3276 \nQ 1397 3394 1825 3394 \nQ 2250 3394 2515 3294 \nQ 2781 3194 2906 3042 \nQ 3031 2891 3081 2659 \nQ 3109 2516 3109 2141 \nL 3109 1391 \nQ 3109 606 3145 398 \nQ 3181 191 3288 0 \nL 2700 0 \nQ 2613 175 2588 409 \nz\nM 2541 1666 \nQ 2234 1541 1622 1453 \nQ 1275 1403 1131 1340 \nQ 988 1278 909 1158 \nQ 831 1038 831 891 \nQ 831 666 1001 516 \nQ 1172 366 1500 366 \nQ 1825 366 2078 508 \nQ 2331 650 2450 897 \nQ 2541 1088 2541 1459 \nL 2541 1666 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-74\" d=\"M 1650 503 \nL 1731 6 \nQ 1494 -44 1306 -44 \nQ 1000 -44 831 53 \nQ 663 150 594 308 \nQ 525 466 525 972 \nL 525 2881 \nL 113 2881 \nL 113 3319 \nL 525 3319 \nL 525 4141 \nL 1084 4478 \nL 1084 3319 \nL 1650 3319 \nL 1650 2881 \nL 1084 2881 \nL 1084 941 \nQ 1084 700 1114 631 \nQ 1144 563 1211 522 \nQ 1278 481 1403 481 \nQ 1497 481 1650 503 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-63\" d=\"M 2588 1216 \nL 3141 1144 \nQ 3050 572 2676 248 \nQ 2303 -75 1759 -75 \nQ 1078 -75 664 370 \nQ 250 816 250 1647 \nQ 250 2184 428 2587 \nQ 606 2991 970 3192 \nQ 1334 3394 1763 3394 \nQ 2303 3394 2647 3120 \nQ 2991 2847 3088 2344 \nL 2541 2259 \nQ 2463 2594 2264 2762 \nQ 2066 2931 1784 2931 \nQ 1359 2931 1093 2626 \nQ 828 2322 828 1663 \nQ 828 994 1084 691 \nQ 1341 388 1753 388 \nQ 2084 388 2306 591 \nQ 2528 794 2588 1216 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-68\" d=\"M 422 0 \nL 422 4581 \nL 984 4581 \nL 984 2938 \nQ 1378 3394 1978 3394 \nQ 2347 3394 2619 3248 \nQ 2891 3103 3008 2847 \nQ 3125 2591 3125 2103 \nL 3125 0 \nL 2563 0 \nL 2563 2103 \nQ 2563 2525 2380 2717 \nQ 2197 2909 1863 2909 \nQ 1613 2909 1392 2779 \nQ 1172 2650 1078 2428 \nQ 984 2206 984 1816 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-6e\" d=\"M 422 0 \nL 422 3319 \nL 928 3319 \nL 928 2847 \nQ 1294 3394 1984 3394 \nQ 2284 3394 2536 3286 \nQ 2788 3178 2913 3003 \nQ 3038 2828 3088 2588 \nQ 3119 2431 3119 2041 \nL 3119 0 \nL 2556 0 \nL 2556 2019 \nQ 2556 2363 2490 2533 \nQ 2425 2703 2258 2804 \nQ 2091 2906 1866 2906 \nQ 1506 2906 1245 2678 \nQ 984 2450 984 1813 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-6f\" d=\"M 213 1659 \nQ 213 2581 725 3025 \nQ 1153 3394 1769 3394 \nQ 2453 3394 2887 2945 \nQ 3322 2497 3322 1706 \nQ 3322 1066 3130 698 \nQ 2938 331 2570 128 \nQ 2203 -75 1769 -75 \nQ 1072 -75 642 372 \nQ 213 819 213 1659 \nz\nM 791 1659 \nQ 791 1022 1069 705 \nQ 1347 388 1769 388 \nQ 2188 388 2466 706 \nQ 2744 1025 2744 1678 \nQ 2744 2294 2464 2611 \nQ 2184 2928 1769 2928 \nQ 1347 2928 1069 2612 \nQ 791 2297 791 1659 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-72\" d=\"M 416 0 \nL 416 3319 \nL 922 3319 \nL 922 2816 \nQ 1116 3169 1280 3281 \nQ 1444 3394 1641 3394 \nQ 1925 3394 2219 3213 \nL 2025 2691 \nQ 1819 2813 1613 2813 \nQ 1428 2813 1281 2702 \nQ 1134 2591 1072 2394 \nQ 978 2094 978 1738 \nL 978 0 \nL 416 0 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-6d\" d=\"M 422 0 \nL 422 3319 \nL 925 3319 \nL 925 2853 \nQ 1081 3097 1340 3245 \nQ 1600 3394 1931 3394 \nQ 2300 3394 2536 3241 \nQ 2772 3088 2869 2813 \nQ 3263 3394 3894 3394 \nQ 4388 3394 4653 3120 \nQ 4919 2847 4919 2278 \nL 4919 0 \nL 4359 0 \nL 4359 2091 \nQ 4359 2428 4304 2576 \nQ 4250 2725 4106 2815 \nQ 3963 2906 3769 2906 \nQ 3419 2906 3187 2673 \nQ 2956 2441 2956 1928 \nL 2956 0 \nL 2394 0 \nL 2394 2156 \nQ 2394 2531 2256 2718 \nQ 2119 2906 1806 2906 \nQ 1569 2906 1367 2781 \nQ 1166 2656 1075 2415 \nQ 984 2175 984 1722 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-62\"/>\n       <use xlink:href=\"#ArialMT-61\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-74\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-63\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-68\" x=\"189.013672\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"244.628906\"/>\n       <use xlink:href=\"#ArialMT-6e\" x=\"272.412109\"/>\n       <use xlink:href=\"#ArialMT-6f\" x=\"328.027344\"/>\n       <use xlink:href=\"#ArialMT-72\" x=\"383.642578\"/>\n       <use xlink:href=\"#ArialMT-6d\" x=\"416.943359\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 541.520156 308.3225 \nL 541.520156 21.789375 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- no batch norm -->\n      <g style=\"fill: #262626\" transform=\"translate(506.363984 325.696094)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-6e\"/>\n       <use xlink:href=\"#ArialMT-6f\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-62\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-61\" x=\"194.628906\"/>\n       <use xlink:href=\"#ArialMT-74\" x=\"250.244141\"/>\n       <use xlink:href=\"#ArialMT-63\" x=\"278.027344\"/>\n       <use xlink:href=\"#ArialMT-68\" x=\"328.027344\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"383.642578\"/>\n       <use xlink:href=\"#ArialMT-6e\" x=\"411.425781\"/>\n       <use xlink:href=\"#ArialMT-6f\" x=\"467.041016\"/>\n       <use xlink:href=\"#ArialMT-72\" x=\"522.65625\"/>\n       <use xlink:href=\"#ArialMT-6d\" x=\"555.957031\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_3\">\n     <!-- Activation function -->\n     <g style=\"fill: #262626\" transform=\"translate(332.10125 340.471719)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"ArialMT-41\" d=\"M -9 0 \nL 1750 4581 \nL 2403 4581 \nL 4278 0 \nL 3588 0 \nL 3053 1388 \nL 1138 1388 \nL 634 0 \nL -9 0 \nz\nM 1313 1881 \nL 2866 1881 \nL 2388 3150 \nQ 2169 3728 2063 4100 \nQ 1975 3659 1816 3225 \nL 1313 1881 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-69\" d=\"M 425 3934 \nL 425 4581 \nL 988 4581 \nL 988 3934 \nL 425 3934 \nz\nM 425 0 \nL 425 3319 \nL 988 3319 \nL 988 0 \nL 425 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-76\" d=\"M 1344 0 \nL 81 3319 \nL 675 3319 \nL 1388 1331 \nQ 1503 1009 1600 663 \nQ 1675 925 1809 1294 \nL 2547 3319 \nL 3125 3319 \nL 1869 0 \nL 1344 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-66\" d=\"M 556 0 \nL 556 2881 \nL 59 2881 \nL 59 3319 \nL 556 3319 \nL 556 3672 \nQ 556 4006 616 4169 \nQ 697 4388 901 4523 \nQ 1106 4659 1475 4659 \nQ 1713 4659 2000 4603 \nL 1916 4113 \nQ 1741 4144 1584 4144 \nQ 1328 4144 1222 4034 \nQ 1116 3925 1116 3625 \nL 1116 3319 \nL 1763 3319 \nL 1763 2881 \nL 1116 2881 \nL 1116 0 \nL 556 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-75\" d=\"M 2597 0 \nL 2597 488 \nQ 2209 -75 1544 -75 \nQ 1250 -75 995 37 \nQ 741 150 617 320 \nQ 494 491 444 738 \nQ 409 903 409 1263 \nL 409 3319 \nL 972 3319 \nL 972 1478 \nQ 972 1038 1006 884 \nQ 1059 663 1231 536 \nQ 1403 409 1656 409 \nQ 1909 409 2131 539 \nQ 2353 669 2445 892 \nQ 2538 1116 2538 1541 \nL 2538 3319 \nL 3100 3319 \nL 3100 0 \nL 2597 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-41\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"66.699219\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"116.699219\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"144.482422\"/>\n      <use xlink:href=\"#ArialMT-76\" x=\"166.699219\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"216.699219\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"272.314453\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"300.097656\"/>\n      <use xlink:href=\"#ArialMT-6f\" x=\"322.314453\"/>\n      <use xlink:href=\"#ArialMT-6e\" x=\"377.929688\"/>\n      <use xlink:href=\"#ArialMT-20\" x=\"433.544922\"/>\n      <use xlink:href=\"#ArialMT-66\" x=\"461.328125\"/>\n      <use xlink:href=\"#ArialMT-75\" x=\"489.111328\"/>\n      <use xlink:href=\"#ArialMT-6e\" x=\"544.726562\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"600.341797\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"650.341797\"/>\n      <use xlink:href=\"#ArialMT-69\" x=\"678.125\"/>\n      <use xlink:href=\"#ArialMT-6f\" x=\"700.341797\"/>\n      <use xlink:href=\"#ArialMT-6e\" x=\"755.957031\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <path d=\"M 59.339063 299.639678 \nL 702.247187 299.639678 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.935 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 303.576475)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-39\" d=\"M 350 1059 \nL 891 1109 \nQ 959 728 1153 556 \nQ 1347 384 1650 384 \nQ 1909 384 2104 503 \nQ 2300 622 2425 820 \nQ 2550 1019 2634 1356 \nQ 2719 1694 2719 2044 \nQ 2719 2081 2716 2156 \nQ 2547 1888 2255 1720 \nQ 1963 1553 1622 1553 \nQ 1053 1553 659 1965 \nQ 266 2378 266 3053 \nQ 266 3750 677 4175 \nQ 1088 4600 1706 4600 \nQ 2153 4600 2523 4359 \nQ 2894 4119 3086 3673 \nQ 3278 3228 3278 2384 \nQ 3278 1506 3087 986 \nQ 2897 466 2520 194 \nQ 2144 -78 1638 -78 \nQ 1100 -78 759 220 \nQ 419 519 350 1059 \nz\nM 2653 3081 \nQ 2653 3566 2395 3850 \nQ 2138 4134 1775 4134 \nQ 1400 4134 1122 3828 \nQ 844 3522 844 3034 \nQ 844 2597 1108 2323 \nQ 1372 2050 1759 2050 \nQ 2150 2050 2401 2323 \nQ 2653 2597 2653 3081 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-33\" d=\"M 269 1209 \nL 831 1284 \nQ 928 806 1161 595 \nQ 1394 384 1728 384 \nQ 2125 384 2398 659 \nQ 2672 934 2672 1341 \nQ 2672 1728 2419 1979 \nQ 2166 2231 1775 2231 \nQ 1616 2231 1378 2169 \nL 1441 2663 \nQ 1497 2656 1531 2656 \nQ 1891 2656 2178 2843 \nQ 2466 3031 2466 3422 \nQ 2466 3731 2256 3934 \nQ 2047 4138 1716 4138 \nQ 1388 4138 1169 3931 \nQ 950 3725 888 3313 \nL 325 3413 \nQ 428 3978 793 4289 \nQ 1159 4600 1703 4600 \nQ 2078 4600 2393 4439 \nQ 2709 4278 2876 4000 \nQ 3044 3722 3044 3409 \nQ 3044 3113 2884 2869 \nQ 2725 2625 2413 2481 \nQ 2819 2388 3044 2092 \nQ 3269 1797 3269 1353 \nQ 3269 753 2831 336 \nQ 2394 -81 1725 -81 \nQ 1122 -81 723 278 \nQ 325 638 269 1209 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-35\" d=\"M 266 1200 \nL 856 1250 \nQ 922 819 1161 601 \nQ 1400 384 1738 384 \nQ 2144 384 2425 690 \nQ 2706 997 2706 1503 \nQ 2706 1984 2436 2262 \nQ 2166 2541 1728 2541 \nQ 1456 2541 1237 2417 \nQ 1019 2294 894 2097 \nL 366 2166 \nL 809 4519 \nL 3088 4519 \nL 3088 3981 \nL 1259 3981 \nL 1013 2750 \nQ 1425 3038 1878 3038 \nQ 2478 3038 2890 2622 \nQ 3303 2206 3303 1553 \nQ 3303 931 2941 478 \nQ 2500 -78 1738 -78 \nQ 1113 -78 717 272 \nQ 322 622 266 1200 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-33\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <path d=\"M 59.339063 260.566979 \nL 702.247187 260.566979 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.940 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 264.503776)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 59.339063 221.49428 \nL 702.247187 221.49428 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.945 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 225.431077)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_6\">\n      <path d=\"M 59.339063 182.421581 \nL 702.247187 182.421581 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.950 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 186.358378)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_7\">\n      <path d=\"M 59.339063 143.348883 \nL 702.247187 143.348883 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.955 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 147.285679)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_8\">\n      <path d=\"M 59.339063 104.276184 \nL 702.247187 104.276184 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.960 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 108.212981)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_9\">\n      <path d=\"M 59.339063 65.203485 \nL 702.247187 65.203485 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.965 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 69.140282)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_10\">\n      <path d=\"M 59.339063 26.130786 \nL 702.247187 26.130786 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.970 -->\n      <g style=\"fill: #262626\" transform=\"translate(22.315 30.067583)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-37\" d=\"M 303 3981 \nL 303 4522 \nL 3269 4522 \nL 3269 4084 \nQ 2831 3619 2401 2847 \nQ 1972 2075 1738 1259 \nQ 1569 684 1522 0 \nL 944 0 \nQ 953 541 1156 1306 \nQ 1359 2072 1739 2783 \nQ 2119 3494 2547 3981 \nL 303 3981 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-39\" x=\"83.398438\"/>\n       <use xlink:href=\"#ArialMT-37\" x=\"139.013672\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"194.628906\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- Test accuracy -->\n     <g style=\"fill: #262626\" transform=\"translate(15.789375 201.730937)rotate(-90)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"ArialMT-54\" d=\"M 1659 0 \nL 1659 4041 \nL 150 4041 \nL 150 4581 \nL 3781 4581 \nL 3781 4041 \nL 2266 4041 \nL 2266 0 \nL 1659 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-65\" d=\"M 2694 1069 \nL 3275 997 \nQ 3138 488 2766 206 \nQ 2394 -75 1816 -75 \nQ 1088 -75 661 373 \nQ 234 822 234 1631 \nQ 234 2469 665 2931 \nQ 1097 3394 1784 3394 \nQ 2450 3394 2872 2941 \nQ 3294 2488 3294 1666 \nQ 3294 1616 3291 1516 \nL 816 1516 \nQ 847 969 1125 678 \nQ 1403 388 1819 388 \nQ 2128 388 2347 550 \nQ 2566 713 2694 1069 \nz\nM 847 1978 \nL 2700 1978 \nQ 2663 2397 2488 2606 \nQ 2219 2931 1791 2931 \nQ 1403 2931 1139 2672 \nQ 875 2413 847 1978 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-73\" d=\"M 197 991 \nL 753 1078 \nQ 800 744 1014 566 \nQ 1228 388 1613 388 \nQ 2000 388 2187 545 \nQ 2375 703 2375 916 \nQ 2375 1106 2209 1216 \nQ 2094 1291 1634 1406 \nQ 1016 1563 777 1677 \nQ 538 1791 414 1992 \nQ 291 2194 291 2438 \nQ 291 2659 392 2848 \nQ 494 3038 669 3163 \nQ 800 3259 1026 3326 \nQ 1253 3394 1513 3394 \nQ 1903 3394 2198 3281 \nQ 2494 3169 2634 2976 \nQ 2775 2784 2828 2463 \nL 2278 2388 \nQ 2241 2644 2061 2787 \nQ 1881 2931 1553 2931 \nQ 1166 2931 1000 2803 \nQ 834 2675 834 2503 \nQ 834 2394 903 2306 \nQ 972 2216 1119 2156 \nQ 1203 2125 1616 2013 \nQ 2213 1853 2448 1751 \nQ 2684 1650 2818 1456 \nQ 2953 1263 2953 975 \nQ 2953 694 2789 445 \nQ 2625 197 2315 61 \nQ 2006 -75 1616 -75 \nQ 969 -75 630 194 \nQ 291 463 197 991 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-79\" d=\"M 397 -1278 \nL 334 -750 \nQ 519 -800 656 -800 \nQ 844 -800 956 -737 \nQ 1069 -675 1141 -563 \nQ 1194 -478 1313 -144 \nQ 1328 -97 1363 -6 \nL 103 3319 \nL 709 3319 \nL 1400 1397 \nQ 1534 1031 1641 628 \nQ 1738 1016 1872 1384 \nL 2581 3319 \nL 3144 3319 \nL 1881 -56 \nQ 1678 -603 1566 -809 \nQ 1416 -1088 1222 -1217 \nQ 1028 -1347 759 -1347 \nQ 597 -1347 397 -1278 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-54\"/>\n      <use xlink:href=\"#ArialMT-65\" x=\"49.958984\"/>\n      <use xlink:href=\"#ArialMT-73\" x=\"105.574219\"/>\n      <use xlink:href=\"#ArialMT-74\" x=\"155.574219\"/>\n      <use xlink:href=\"#ArialMT-20\" x=\"183.357422\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"211.140625\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"266.755859\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"316.755859\"/>\n      <use xlink:href=\"#ArialMT-75\" x=\"366.755859\"/>\n      <use xlink:href=\"#ArialMT-72\" x=\"422.371094\"/>\n      <use xlink:href=\"#ArialMT-61\" x=\"455.671875\"/>\n      <use xlink:href=\"#ArialMT-63\" x=\"511.287109\"/>\n      <use xlink:href=\"#ArialMT-79\" x=\"561.287109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 195.957039 191.104403 \nL 244.175148 191.104403 \nL 244.175148 69.544896 \nL 195.957039 69.544896 \nL 195.957039 191.104403 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 220.066094 191.104403 \nL 220.066094 225.835691 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 220.066094 69.544896 \nL 220.066094 34.813608 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 208.011566 225.835691 \nL 232.120621 225.835691 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 208.011566 34.813608 \nL 232.120621 34.813608 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 517.411102 295.298267 \nL 565.629211 295.298267 \nL 565.629211 139.007472 \nL 517.411102 139.007472 \nL 517.411102 295.298267 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 541.520156 295.298267 \nL 541.520156 295.298267 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 541.520156 139.007472 \nL 541.520156 104.276184 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 529.465629 295.298267 \nL 553.574684 295.298267 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 529.465629 104.276184 \nL 553.574684 104.276184 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 195.957039 86.91054 \nL 244.175148 86.91054 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #dd8452; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 517.411102 173.738759 \nL 565.629211 173.738759 \n\" clip-path=\"url(#p7c92eb4235)\" style=\"fill: none; stroke: #dd8452; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 59.339063 308.3225 \nL 59.339063 21.789375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 702.247187 308.3225 \nL 702.247187 21.789375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 59.339063 308.3225 \nL 702.247187 308.3225 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 59.339063 21.789375 \nL 702.247187 21.789375 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_13\">\n    <!-- Test quality in 5 runs -->\n    <g style=\"fill: #262626\" transform=\"translate(326.105 15.789375)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"ArialMT-71\" d=\"M 2538 -1272 \nL 2538 353 \nQ 2406 169 2170 47 \nQ 1934 -75 1669 -75 \nQ 1078 -75 651 397 \nQ 225 869 225 1691 \nQ 225 2191 398 2587 \nQ 572 2984 901 3189 \nQ 1231 3394 1625 3394 \nQ 2241 3394 2594 2875 \nL 2594 3319 \nL 3100 3319 \nL 3100 -1272 \nL 2538 -1272 \nz\nM 803 1669 \nQ 803 1028 1072 708 \nQ 1341 388 1716 388 \nQ 2075 388 2334 692 \nQ 2594 997 2594 1619 \nQ 2594 2281 2320 2615 \nQ 2047 2950 1678 2950 \nQ 1313 2950 1058 2639 \nQ 803 2328 803 1669 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"ArialMT-6c\" d=\"M 409 0 \nL 409 4581 \nL 972 4581 \nL 972 0 \nL 409 0 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#ArialMT-54\"/>\n     <use xlink:href=\"#ArialMT-65\" x=\"49.958984\"/>\n     <use xlink:href=\"#ArialMT-73\" x=\"105.574219\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"155.574219\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"183.357422\"/>\n     <use xlink:href=\"#ArialMT-71\" x=\"211.140625\"/>\n     <use xlink:href=\"#ArialMT-75\" x=\"266.755859\"/>\n     <use xlink:href=\"#ArialMT-61\" x=\"322.371094\"/>\n     <use xlink:href=\"#ArialMT-6c\" x=\"377.986328\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"400.203125\"/>\n     <use xlink:href=\"#ArialMT-74\" x=\"422.419922\"/>\n     <use xlink:href=\"#ArialMT-79\" x=\"450.203125\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"500.203125\"/>\n     <use xlink:href=\"#ArialMT-69\" x=\"527.986328\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"550.203125\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"605.818359\"/>\n     <use xlink:href=\"#ArialMT-35\" x=\"633.601562\"/>\n     <use xlink:href=\"#ArialMT-20\" x=\"689.216797\"/>\n     <use xlink:href=\"#ArialMT-72\" x=\"717\"/>\n     <use xlink:href=\"#ArialMT-75\" x=\"750.300781\"/>\n     <use xlink:href=\"#ArialMT-6e\" x=\"805.916016\"/>\n     <use xlink:href=\"#ArialMT-73\" x=\"861.53125\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7c92eb4235\">\n   <rect x=\"59.339063\" y=\"21.789375\" width=\"642.908125\" height=\"286.533125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "ax.boxplot(accs_test.T, labels=['batch norm', 'no batch norm'], showfliers=False)\n",
    "\n",
    "ax.set_title(\"Test quality in 5 runs\")\n",
    "ax.set_xlabel(\"Activation function\")\n",
    "ax.set_ylabel(\"Test accuracy\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что для глубокой сети(5 слоев) лучше работает модель с батч нормализацией после каждого слоя активации. Разброс примерно одниковый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a95a3159dfda2c08b5d712b28a556d6374f5200b4d9ef1616fa04e7e784ad12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
